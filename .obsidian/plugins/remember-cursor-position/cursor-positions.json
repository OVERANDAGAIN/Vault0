{"Problems/Packages/importlib.md":{"scroll":30.0139,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/no GPU.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/no pth.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/HOP初运行.md":{"scroll":41.4475,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/OOM.md":{"scroll":77.1918,"cursor":{"from":{"ch":54,"line":90},"to":{"ch":0,"line":89}}},"Templates/Papers/paper QAs.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":4},"to":{"ch":0,"line":4}}},"Templates/Problems/package problems.md":{"scroll":0,"cursor":{"from":{"ch":9,"line":2},"to":{"ch":9,"line":2}}},"Templates/Problems/run problems.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Templates/Logbook/log git.md":{"scroll":5.6449,"cursor":{"from":{"ch":0,"line":19},"to":{"ch":0,"line":11}}},"Logbook/Git/Termux Bash.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Logbook/Git/Connect Failure_to be solved.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":29},"to":{"ch":0,"line":29}}},"Papers/MCTS/MCTS search.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/MCTS/MCTS.md":{"scroll":0,"cursor":{"from":{"ch":15,"line":0},"to":{"ch":15,"line":0}}},"Papers/MCTS/MCTS与MC的区别.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/cheap talk.md":{"scroll":0,"cursor":{"from":{"ch":51,"line":1},"to":{"ch":0,"line":1}}},"Papers/A Review of Cooperation in Multi-agent Learning/aligned=pure common interest.md":{"scroll":0,"cursor":{"from":{"ch":51,"line":0},"to":{"ch":51,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/Zipf ’s law.md":{"scroll":0,"cursor":{"from":{"ch":51,"line":0},"to":{"ch":51,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/Hanabi.md":{"scroll":0,"cursor":{"from":{"ch":51,"line":0},"to":{"ch":51,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/Arrow’s Theorem.md":{"scroll":0,"cursor":{"from":{"ch":7,"line":8},"to":{"ch":7,"line":8}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/图解释.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":0,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/Backpropagation.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/SCG-repara-SF.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/Score Function.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/Surrogate loss function.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/公式推导Higher Order Derivatives.md":{"scroll":0.734,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/Learning to Balance Altruism and Self-interest Bas/w-o.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/Proximal Learning With Opponent-Learning Awareness/Euclidean (L2) norm.md":{"scroll":0,"cursor":{"from":{"ch":50,"line":9},"to":{"ch":50,"line":9}}},"Templates/Papers/paper Summary.md":{"scroll":0,"cursor":{"from":{"ch":14,"line":14},"to":{"ch":0,"line":14}}},"Papers/A Review of Cooperation in Multi-agent Learning/A Review of Cooperation in Multi-agent Learning.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":1},"to":{"ch":0,"line":1}}},"Papers/Advantage Alignment Algorithm/Advantage Alignment Algorithm.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":5},"to":{"ch":0,"line":5}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/DiCE.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":5},"to":{"ch":0,"line":5}}},"Papers/Learning to Balance Altruism and Self-interest Bas/LASE.md":{"scroll":0,"cursor":{"from":{"ch":14,"line":30},"to":{"ch":14,"line":30}}},"Papers/Proximal Learning With Opponent-Learning Awareness/PPO.md":{"scroll":0,"cursor":{"from":{"ch":14,"line":30},"to":{"ch":14,"line":30}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/HOP.md":{"scroll":7.2708,"cursor":{"from":{"ch":0,"line":21},"to":{"ch":0,"line":21}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/未命名.md":{"scroll":5.6449,"cursor":{"from":{"ch":0,"line":9},"to":{"ch":0,"line":9}}}}