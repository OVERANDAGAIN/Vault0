{"Problems/Packages/importlib.md":{"scroll":30.0139,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/no GPU.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/no pth.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/HOP初运行.md":{"scroll":41.4475,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Problems/Run/OOM.md":{"scroll":77.1918,"cursor":{"from":{"ch":54,"line":90},"to":{"ch":0,"line":89}}},"Templates/Papers/paper QAs.md":{"scroll":0,"cursor":{"from":{"ch":9,"line":5},"to":{"ch":9,"line":5}}},"Templates/Problems/package problems.md":{"scroll":0,"cursor":{"from":{"ch":9,"line":2},"to":{"ch":9,"line":2}}},"Templates/Problems/run problems.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Templates/Logbook/log git.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":3},"to":{"ch":0,"line":3}}},"Logbook/Git/Termux Bash.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Logbook/Git/Connect Failure_to be solved.md":{"scroll":0,"cursor":{"from":{"ch":13,"line":1},"to":{"ch":13,"line":1}}},"Papers/MCTS/MCTS search.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/MCTS/MCTS.md":{"scroll":14.3537,"cursor":{"from":{"ch":15,"line":0},"to":{"ch":15,"line":0}}},"Papers/MCTS/MCTS与MC的区别.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/cheap talk.md":{"scroll":76.0917,"cursor":{"from":{"ch":51,"line":1},"to":{"ch":0,"line":1}}},"Papers/A Review of Cooperation in Multi-agent Learning/aligned=pure common interest.md":{"scroll":0.7192,"cursor":{"from":{"ch":51,"line":0},"to":{"ch":51,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/Zipf ’s law.md":{"scroll":46.6178,"cursor":{"from":{"ch":22,"line":21},"to":{"ch":22,"line":21}}},"Papers/A Review of Cooperation in Multi-agent Learning/Hanabi.md":{"scroll":27.1032,"cursor":{"from":{"ch":51,"line":0},"to":{"ch":51,"line":0}}},"Papers/A Review of Cooperation in Multi-agent Learning/Arrow’s Theorem.md":{"scroll":68.6429,"cursor":{"from":{"ch":7,"line":8},"to":{"ch":7,"line":8}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/图解释.md":{"scroll":30.2988,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":0,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/Backpropagation.md":{"scroll":4.8417,"cursor":{"from":{"ch":0,"line":5},"to":{"ch":0,"line":5}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/SCG-repara-SF.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":2},"to":{"ch":0,"line":2}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/Score Function.md":{"scroll":7.1683,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/Surrogate loss function.md":{"scroll":4,"cursor":{"from":{"ch":11,"line":10},"to":{"ch":11,"line":10}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/公式推导Higher Order Derivatives.md":{"scroll":0.7192,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/Learning to Balance Altruism and Self-interest Bas/w-o.md":{"scroll":0,"cursor":{"from":{"ch":8,"line":0},"to":{"ch":8,"line":0}}},"Papers/Proximal Learning With Opponent-Learning Awareness/Euclidean (L2) norm.md":{"scroll":0,"cursor":{"from":{"ch":50,"line":9},"to":{"ch":50,"line":9}}},"Templates/Papers/paper Summary.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":17},"to":{"ch":0,"line":17}}},"Papers/A Review of Cooperation in Multi-agent Learning/A Review of Cooperation in Multi-agent Learning.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":1},"to":{"ch":0,"line":1}}},"Papers/Advantage Alignment Algorithm/Advantage Alignment Algorithm.md":{"scroll":4.8583,"cursor":{"from":{"ch":0,"line":5},"to":{"ch":0,"line":5}}},"Papers/DiCE-The Infinitely Differentiable Monte Carlo Es/DiCE.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":5},"to":{"ch":0,"line":5}}},"Papers/Learning to Balance Altruism and Self-interest Bas/LASE.md":{"scroll":7.075,"cursor":{"from":{"ch":14,"line":30},"to":{"ch":14,"line":30}}},"Papers/Proximal Learning With Opponent-Learning Awareness/PPO.md":{"scroll":0,"cursor":{"from":{"ch":0,"line":16},"to":{"ch":0,"line":16}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/HOP.md":{"scroll":64.6254,"cursor":{"from":{"ch":0,"line":0},"to":{"ch":0,"line":0}}},"Meeting/Advantage Alignment Algorithm.md":{"scroll":4,"cursor":{"from":{"ch":0,"line":8},"to":{"ch":0,"line":8}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/Indicator Function.md":{"scroll":16.625,"cursor":{"from":{"ch":0,"line":45},"to":{"ch":0,"line":45}}},"Papers/Mastering the game of Go with deep  neural networks and tree search/AlphaGo.md":{"scroll":614.4434,"cursor":{"from":{"ch":0,"line":583},"to":{"ch":0,"line":583}}},"2024-12-12.md":{"scroll":4,"cursor":{"from":{"ch":88,"line":9},"to":{"ch":0,"line":5}}},"Papers/Mastering the game of Go with deep  neural networks and tree search/ASGD.md":{"scroll":20.9555,"cursor":{"from":{"ch":1,"line":4},"to":{"ch":1,"line":4}}},"Papers/Mastering the game of Go with deep  neural networks and tree search/RL vs SL.md":{"scroll":6.2778,"cursor":{"from":{"ch":0,"line":8},"to":{"ch":0,"line":8}}},"Meeting/科研心路历程与坚持长期主义科研.md":{"scroll":5.7906,"cursor":{"from":{"ch":9,"line":13},"to":{"ch":9,"line":13}}},"Templates/Papers/paper codes.md":{"scroll":0,"cursor":{"from":{"ch":17,"line":4},"to":{"ch":7,"line":4}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/config and moa.md":{"scroll":4,"cursor":{"from":{"ch":0,"line":12},"to":{"ch":0,"line":12}}},"Templates/Meeting/Meeting Template.md":{"scroll":0,"cursor":{"from":{"ch":6,"line":13},"to":{"ch":6,"line":13}}},"Meeting/GPU集群最佳实践.md":{"scroll":4,"cursor":{"from":{"ch":0,"line":8},"to":{"ch":0,"line":8}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/HOP_Overall.md":{"scroll":405.7063,"cursor":{"from":{"ch":0,"line":7},"to":{"ch":0,"line":7}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/env.py.md":{"scroll":4,"cursor":{"from":{"ch":11,"line":336},"to":{"ch":11,"line":336}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/model.py.md":{"scroll":124.5333,"cursor":{"from":{"ch":38,"line":141},"to":{"ch":38,"line":141}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/KaiMing Normalization.md":{"scroll":4,"cursor":{"from":{"ch":0,"line":4},"to":{"ch":0,"line":4}}},"Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/when Gaussian or uniform_to_be_solved.md":{"scroll":4,"cursor":{"from":{"ch":0,"line":10},"to":{"ch":0,"line":10}}},"2024-12-16.md":{"scroll":4,"cursor":{"from":{"ch":0,"line":6},"to":{"ch":0,"line":6}}}}