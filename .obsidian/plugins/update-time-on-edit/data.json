{
  "dateFormat": "yyyy-MM-dd-HH.",
  "enableCreateTime": true,
  "headerUpdated": "updated",
  "headerCreated": "created",
  "minMinutesBetweenSaves": 1,
  "ignoreGlobalFolder": [],
  "ignoreCreatedFolder": [],
  "enableExperimentalHash": false,
  "fileHashMap": {
    "2025/02/2025-02-13.md": "e3942169a550ed88b94ab19c5a224f7d9ad0cb36cb05b71c880c9ad882ff803a",
    "Foundations/安装双系统/双系统.md": "dc405db71aadee609831b57a2570d90746d99b7a390094c20fb5e5dd2ec093c6",
    "MyExperiments/HOP+/HOP代码细节.md": "5ab8c6441160be6e366f6e8460c8f9ea9023e6e6befe02f1a569a9940da9980d",
    "MyExperiments/HOP+/逻辑梳理.md": "a46530d1eb33f21f2aba21e10d77e6c963ebf32ab0571adf759893705c9b095c",
    "Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/config and moa.md": "8312d7ce8a25b88268b8989b86c3a006028e85b0e73a4f65c911dd5b034acbca",
    "MyExperiments/HOP+/OMG运行问题.md": "c33ac41143f4c7d280880737d0988a33575472b4e45a1d5696b2519846cb12b7",
    "Foundations/安装双系统/预前迁移准备.md": "c72944eedfebe8873c0d7a572476454c52b9576a5c5c4931b0a82eed56e465bc",
    "Foundations/安装双系统/安装过程.md": "2bea47a8f7fe7bb999d58b8b7cd1b02200673f59a452c358d83783f2ffc64f7c",
    "2024/12/2024-12-12.md": "66a7ab299704390143591bd8852cf4086130bebd38bf0ca2d753f5de70f8e398",
    "2025/02/2025-02-17.md": "1ce95f13bda5bab74920349ed718871f61c1c2c029c259066ebcd5902ccdeb13",
    "2025/02/2025-W07.md": "e3328831c430dc6388220d4b091f31e95ca65647630b1b5ad9dfe5564f65ea6a",
    "Encounters/Efficiencies.md": "e5f0d7b1024dddd03f38397cc850b5d5adc0d4485ccfcda69a9c4012dfe320cc",
    "Encounters/Encounters.md": "e6ecc27d1ff3d69ba45869e3b3d8ef7aff963a222b20f2eb5b91ba9f081a8e54",
    "Foundations/Python/Python.md": "a0ef3d39f01a1ad6ae82e55c763c03960e5a385a3b86d0aab5c38598e6dfcb66",
    "Foundations/Python/enumerate_to_be_solved.md": "19975f46a8f0c9b5bba1f3ad62610440401912054e0fb09e6987a49923511f42",
    "Foundations/Python/super.init().md": "6f722463fb7f3dfd0a094e4140e4581b1c650b8654aaba711803ca38c71c05f4",
    "Foundations/Python/关于vshape的1，.md": "d515729b998c0f6da0fbf881ef154fe645b52ff45e388b6045a5f95ac15fcc37",
    "Foundations/Python/前向传播.md": "d10a73acf9a054e5669419c6c3b46702f87ac4ac66d18af94cf79b44b3ed90ca",
    "Foundations/Python/维度拼接.md": "d90b69a421b39bf05e30d245afecbed23912b9da03bf170de38619cac613b042",
    "Logbook/UML/依赖关系.md": "8c5e0b718835ba077cdcb44f2f8858e5489c7563c37392defca85c8c52c7e182",
    "Logbook/Zotero/Zotero.md": "72b20be26c0eda615c1814d54f49333d839167185edd2a9e6db8ce6a15f2707a",
    "Logbook/Zotero/plugins.md": "46b0420de4b54701231a1a027a993d6008b656abdd29384c08dc549ad0d347cf",
    "Logbook/Zotero/同步附件_Zotero7.md": "c876d0c4d540cc7704cdc49aeadfd42796540c3b7f198e51208569ff8360996f",
    "Meeting/Advantage Alignment Algorithm.md": "0d679de69dc65b02ccf3681579571f7e87c33b64764db7d7cb00b8792ae085f5",
    "Meeting/Beyond Dialogue.md": "7b56c7c22c8e080ac0a5fdbe64a0c954a501a01a4d0bf043b64b689ab438f215",
    "Meeting/Chaos in Multiagent System and Human Brain.md": "d0eede5bf8bcc9642d13f275f80a264b3e6b885ee27cb68e1d5fee23903d2e93",
    "Meeting/Episodic Future Thinking Mechanism for Multi-agent Reinforcement Learning.md": "b46566cae546b79b37deab8dc7a35468f8f52d79625a61f941c318c5977a2fa1",
    "Meeting/Finding the scaling laws of Agents.md": "833f76d9cbb43be2b7e676833e5b2a33bfb594b54c97cec4e9198b104096d2fb",
    "Meeting/GPU集群最佳实践.md": "11f8aa06e6ce0abb60c40df20092a3118a95abb701ecd8459d5ccc1a71e2b0bf",
    "Meeting/LOLA相关opponennt_shaping.md": "7c6cf0061666244268a5a02a2fc160acbb421afcf855e7d73534e4551dbb61c2",
    "Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/HOP_Overall.md": "4e7b8f9956f182db1b612d33be54dff9588f6249085f953b15b98a7db642d962",
    "Papers/Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning/codes/algorithm/Alpha_zero_moa_relative.md": "3dca23b122799d99b644deb3ee73171dabbc9bae45218ce7e65b43e372e39972",
    "Papers/Learning to Balance Altruism and Self-interest Bas/LASE.md": "18fdc7590ee3f3deec40232fc68071d9aa6f72fde1b036c3da79be2838496580",
    "Papers/Learning to Balance Altruism and Self-interest Bas/V函数中的联合分布.md": "ab06c6236111173acdb89379b92e4f78a849365348c91240c628b0053c72fceb",
    "Papers/Learning to Balance Altruism and Self-interest Bas/marginalize边缘化.md": "ab717799600200f04aed241298b00ccac0fcd43df1f62680cbf49ac290ffb671",
    "Papers/Learning to Balance Altruism and Self-interest Bas/w-o.md": "ad10528103269e95036cc2bd8a1bbdb8d7170db8ec864c7bb11bf893109233c7",
    "Papers/Learning to Balance Altruism and Self-interest Bas/双层优化问题.md": "08ea468b3408b92478fba55b30317bbeb100f79223e3654c2f79bf3d583b3ceb",
    "Papers/Learning with Opponent-Learning Awareness/LOLA.md": "8e8a26a0c9601a1c75f3f5bfd7aedf6a9f1c02c69d746e1b33af8a8bf2110a91",
    "Papers/MCTS/MCTS search.md": "f347ef5fc6daf454198b892e9c0d7dd33aeeab31cd654d38a44688988dff3c99",
    "Papers/MCTS/MCTS.md": "195988a5530b809d6572877fbd196cdb0ecaca4324a8fa94dbb9734d2f446eae",
    "Papers/MCTS/MCTS与MC的区别.md": "6de209d920bb434ad3b437b61363974fe16427f3e2f5ed2e118cb9217fc2140f",
    "Papers/Opponent Modeling based on Subgoal Inference/Subgoal Hit Ratio 理解.md": "33b8a9bf5df4a80d273900941cb6f6a0608a7b7806d08fcd1783bd961769fc2e",
    "Papers/Opponent Modeling based on Subgoal Inference/Whats_Oracle.md": "40919de075d381c8021e640a29d24c62988ee47a33f09a3071d84e9423676e4e",
    "Papers/Opponent Modeling based on Subgoal Inference/codes/controller的init.md": "1ca81c2b69d29a794c4663955d2b607cdc1d8ce7b0a2698143c2a5e734aa4ab5",
    "Papers/Opponent Modeling based on Subgoal Inference/codes/controller的init的config阶段.md": "6ac81c681748210da19d3bbb4b6f77c8053db10ecc774e6ae8cdee2c18a8103f",
    "Papers/Opponent Modeling based on Subgoal Inference/codes/eval与test.md": "bf8af685c6f1c4088b2fc29c23d5240e84eb9a4916dc06aec5a3fc02e0931857",
    "Papers/Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning/长难句.md": "810da22df68cebca0ba942c1f8db52ec13b270ba4634c097325da5e5b9605721",
    "Papers/Proximal Learning With Opponent-Learning Awareness/Euclidean (L2) norm.md": "324fc8c081e44c3387f093295f904e70a78d830dcf75c41b772f9196bc6dabbc",
    "Papers/Proximal Learning With Opponent-Learning Awareness/PPO.md": "354bfa851c4365bdbe231d2124e1d56b8fed911d65ea8ef5f4359ad4d0614db4",
    "Papers/Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning/Social Influence as Intrinstic Motivation.md": "456f7deca3103cbbc339ffa4f91a9b4e7584dfa3a2b3e759445ef3ff15919f80",
    "Papers/Social Influence as Intrinsic Motivation for Multi-Agent Deep Reinforcement Learning/counterfactual reasoning.md": "f60c7e28ac33caab9f08cef47e51707adb2ba778dd24c562b85653c65623fc37",
    "Problems/Run/OOM.md": "426aeed26b765c18b23fbdb959c8482ab5ae4ed6478d83462a9a982d544a1243",
    "Problems/Run/no GPU.md": "e08353a8fad5d3185bde222b678e942e2898100783a840c15528c90eb1c9f59b",
    "Problems/Run/no pth.md": "0e051eba4a0bb18acdd1dad7dc04a2c70dcaa3a37d6194e4e0ac733a1383ad0b",
    "Templates/Papers/paper Summary.md": "2ccff59b45153321de46b587d36038f73d284cf7a36b00b7d59541ce0dcfcc77",
    "Templates/Papers/paper codes.md": "ab832f80058f35002c5ac82b66612116fe6a467f085b25a08d733f13b16e61b1",
    "Templates/Problems/problem templates.md": "7749c806e21b5c7d6d0e41bc1aeeb3cb0529bc64927f9b7984c2bf414c76a3f4",
    "Templates/Problems/problems summary.md": "16b6dee2c105b365c7b9a3fbd5cbdb37127e886c06a3258fbb429868ca9eb166",
    "Templates/Tools/tool summary.md": "059a8ff0e793c9c193b55b655ab7830bb89bf6ac2773b82af779726f492d2d40",
    "Templates/Tools/tool templates.md": "a1c1a2edd0b2616f872ce5f73141bd9b834135fd9f13ee74fc0fc92911683e30"
  }
}