lola:
在一群持续学习的、追求自我利益最大化的智能体中如何使其涌现互利行为一直是一个难题。博弈论研究在包含协作与竞争因素的博弈中的学习结果历史悠久。一个经典的博弈问题就是重复囚徒困境（iterated prisoners' dilemma，IPD）。在这个博弈问题中，只追求自我利益的最大化将导致一个对于所有参与者都很差的结果，而合作则可以实现整体利益最大化（评价指标是所有智能体的奖励之和）。

文章发现，对于目前的深度强化学习算法（这里指2017年及以前的算法），在 IPD 问题及类似问题中最后收敛到的策略都是只追求自我利益最大化，即拒绝合作。这表明目前的算法即使在很简单的博弈问题中也会引导智能体朝着自私行为的方向进行学习。而造成这种现象的一个很重要的原因便是目前的算法在学习的过程中很少去考虑其余智能体的学习过程的影响，仅仅是将它们当作环境中一个静态的组成部分。

为了显式地在 social setting 中考虑其余智能体的学习行为，文章提出了 Learning with Opponent Learning Awareness (LOLA) 算法。LOLA 算法在参数更新过程中通过引入额外的修正项，来考量智能体的策略对于其余智能体学习过程的影响。文章表明，引入该项后，智能体在 IPD 及类似问题中能够产生互利及协作行为