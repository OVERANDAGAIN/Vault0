---
创建时间: 2025-一月-15日  星期三, 10:29:34 上午
---
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia



以下是图片中关于两个 Q 函数的叙述内容的文字描述：

---

1. **Independent Q-learning (公式 2)：**
   > If an agent treats other agents as part of the environment and ignores the non-stationarity posed by the change of other agents' policies as independent Q-learning [43, 44]. Its Q-function $Q(s_t, a_t)$ is updated by:
   >
   > $$> Q(s_t, a_t) = \mathbb{E}_{\mathcal{P}(s_{t+1} | s_t, a_t^{-i}, a_i)} \left[ r + \gamma \max_a Q(s_{t+1}, a) \right].
   >$$

   在这种情况下，智能体将其他智能体的策略变化视为环境的一部分，完全忽略了由此引起的非平稳性问题。

2. **Opponent Modeling (公式 3)：**
   > Opponent modeling typically predicts the actions of other agents to address the non-stationary problem. The opponent model uses historical trajectory as input to predict $\tilde{a}^{-i} \sim \pi(\cdot | \tau)$, where $\tilde{a}^{-i}$ is the estimate of $a^{-i}$. Then, its Q-function is updated as:
   >
   > $$> Q(s_t, \tilde{a}^{-i}, a_t) = \mathbb{E}_{\mathcal{P}(s_{t+1} | s_t, \tilde{a}^{-i}, a_t)} \left[ r + \gamma \max_a Q(s_{t+1}, a) \right].
   >$$

   在这种情况下，通过对历史轨迹进行建模，智能体能够预测其他智能体的行为策略（$\tilde{a}^{-i}$），从而解决非平稳性问题。

以下是图片中关于两个 Q 函数的叙述内容转为文字的描述：

---

**Independent Q-learning (公式 2)：**

If an agent treats other agents as part of the environment and ignores the non-stationarity posed by the change of other agents' policies as independent Q-learning [43, 44]. Its Q-function $Q(s_t, a_t)$ is updated by:

$$Q(s_t, a_t) = \mathbb{E}_{\mathcal{P}(s_{t+1} | s_t, a_t^{-i}, a_i)} \left[ r + \gamma \max_a Q(s_{t+1}, a) \right].$$

在这种情况下，智能体将其他智能体的策略变化视为环境的一部分，完全忽略了由此引起的非平稳性问题。

---

**Opponent Modeling (公式 3)：**

Opponent modeling typically predicts the actions of other agents to address the non-stationary problem. The opponent model uses historical trajectory as input to predict $\tilde{a}^{-i} \sim \pi(\cdot | \tau)$, where $\tilde{a}^{-i}$ is the estimate of $a^{-i}$. Then, its Q-function is updated as:

$$Q(s_t, \tilde{a}^{-i}, a_t) = \mathbb{E}_{\mathcal{P}(s_{t+1} | s_t, \tilde{a}^{-i}, a_t)} \left[ r + \gamma \max_a Q(s_{t+1}, a) \right].$$

在这种情况下，通过对历史轨迹进行建模，智能体能够预测其他智能体的行为策略（$\tilde{a}^{-i}$），从而解决非平稳性问题。

---

**总结：**
公式 (2) 表示传统的 stationary Q-learning，即假设其他智能体的策略固定不变。  
公式 (3) 表示通过 opponent modeling 解决 non-stationarity 的 Q 函数。




以下是带有详细注释的 VAE 和 CVAE 代码，帮助你更清晰地理解代码的逻辑和实现细节。

---

### **1. VAE 代码**

#### **模型定义**
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class VAE(nn.Module):
    def __init__(self, input_dim, latent_dim):
        super(VAE, self).__init__()
        # Encoder部分：从输入数据中提取特征并映射到隐变量空间
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 128),  # 输入 -> 隐藏层 1
            nn.ReLU(),
            nn.Linear(128, 64),        # 隐藏层 1 -> 隐藏层 2
            nn.ReLU(),
        )
        # 隐变量的均值和方差网络
        self.mu_layer = nn.Linear(64, latent_dim)        # 输出均值 μ
        self.logvar_layer = nn.Linear(64, latent_dim)    # 输出对数方差 log(σ^2)

        # Decoder部分：从隐变量空间解码重构输入数据
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 64),  # 隐变量 -> 隐藏层 1
            nn.ReLU(),
            nn.Linear(64, 128),         # 隐藏层 1 -> 隐藏层 2
            nn.ReLU(),
            nn.Linear(128, input_dim),  # 隐藏层 2 -> 重构数据
            nn.Sigmoid(),  # 归一化输出，用于生成范围在[0,1]的数据
        )

    def encode(self, x):
        # 编码阶段：获取隐变量的均值和对数方差
        h = self.encoder(x)
        mu = self.mu_layer(h)
        logvar = self.logvar_layer(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        # 重参数化技巧：使用均值和方差生成隐变量 z
        std = torch.exp(0.5 * logvar)  # 计算标准差 σ = exp(0.5 * log(σ^2))
        eps = torch.randn_like(std)    # 生成与标准差形状一致的随机噪声
        return mu + eps * std          # 生成隐变量 z = μ + ε * σ

    def decode(self, z):
        # 解码阶段：将隐变量映射回输入数据
        return self.decoder(z)

    def forward(self, x):
        # 前向传播：从输入到输出
        mu, logvar = self.encode(x)    # 编码获取均值和对数方差
        z = self.reparameterize(mu, logvar)  # 使用重参数化技巧生成隐变量
        recon_x = self.decode(z)       # 解码重构输入
        return recon_x, mu, logvar
```

---

#### **损失函数**
```python
def vae_loss(recon_x, x, mu, logvar, beta=1):
    # 重构损失：衡量重构数据 recon_x 与原始数据 x 的相似性
    recon_loss = F.mse_loss(recon_x, x, reduction='sum')  # 或 F.binary_cross_entropy
    # KL 散度损失：强制隐变量 z 的分布接近标准正态分布
    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    # 总损失：重构损失 + KL 散度（权重由 beta 调节）
    return recon_loss + beta * kl_divergence
```

---

#### **训练代码**
```python
# 超参数
input_dim = 784  # 输入维度（以 MNIST 数据为例，每张图像为28x28像素）
latent_dim = 20  # 隐变量维度
lr = 1e-3        # 学习率
epochs = 10      # 训练轮数

# 数据加载和预处理
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# 将数据归一化并展平成一维
transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])
dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

# 初始化模型和优化器
vae = VAE(input_dim, latent_dim).to("cuda")  # 使用 GPU
optimizer = torch.optim.Adam(vae.parameters(), lr=lr)  # Adam 优化器

# 开始训练
vae.train()  # 设置为训练模式
for epoch in range(epochs):
    total_loss = 0
    for x, _ in dataloader:  # 遍历训练数据
        x = x.to("cuda")  # 将数据传输到 GPU
        recon_x, mu, logvar = vae(x)  # 前向传播
        loss = vae_loss(recon_x, x, mu, logvar)  # 计算损失

        optimizer.zero_grad()  # 清空梯度
        loss.backward()        # 反向传播
        optimizer.step()       # 更新参数

        total_loss += loss.item()  # 累加损失
    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader.dataset)}")
```

---

### **2. CVAE 代码**

#### **模型定义**
```python
class CVAE(nn.Module):
    def __init__(self, input_dim, latent_dim, condition_dim):
        super(CVAE, self).__init__()
        # Encoder部分：结合输入和条件生成隐变量的均值和方差
        self.encoder = nn.Sequential(
            nn.Linear(input_dim + condition_dim, 128),  # 输入数据 + 条件
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
        )
        self.mu_layer = nn.Linear(64, latent_dim)        # 均值 μ
        self.logvar_layer = nn.Linear(64, latent_dim)    # 对数方差 log(σ^2)

        # Decoder部分：结合隐变量和条件生成数据
        self.decoder = nn.Sequential(
            nn.Linear(latent_dim + condition_dim, 64),  # 隐变量 + 条件
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, input_dim),
            nn.Sigmoid(),  # 归一化输出
        )

    def encode(self, x, y):
        # 编码阶段：将输入和条件拼接后获取隐变量分布
        h = self.encoder(torch.cat([x, y], dim=-1))
        mu = self.mu_layer(h)
        logvar = self.logvar_layer(h)
        return mu, logvar

    def reparameterize(self, mu, logvar):
        # 重参数化技巧
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def decode(self, z, y):
        # 解码阶段：结合隐变量和条件生成重构数据
        return self.decoder(torch.cat([z, y], dim=-1))

    def forward(self, x, y):
        # 前向传播
        mu, logvar = self.encode(x, y)  # 编码
        z = self.reparameterize(mu, logvar)  # 重参数化
        recon_x = self.decode(z, y)  # 解码
        return recon_x, mu, logvar
```

---

#### **损失函数**
```python
def cvae_loss(recon_x, x, mu, logvar, beta=1):
    # CVAE 损失：重构损失 + KL 散度
    recon_loss = F.mse_loss(recon_x, x, reduction='sum')  # 重构误差
    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  # KL 散度
    return recon_loss + beta * kl_divergence
```

---

#### **训练代码**
```python
# 条件维度（MNIST 的数字类别）
condition_dim = 10  # 条件是数字 0-9 的 one-hot 编码

# 初始化 CVAE
cvae = CVAE(input_dim, latent_dim, condition_dim).to("cuda")
optimizer = torch.optim.Adam(cvae.parameters(), lr=lr)

# 训练 CVAE
cvae.train()
for epoch in range(epochs):
    total_loss = 0
    for x, labels in dataloader:
        x, labels = x.to("cuda"), labels.to("cuda")
        y = F.one_hot(labels, num_classes=10).float()  # 将标签转为 one-hot 编码

        recon_x, mu, logvar = cvae(x, y)  # 前向传播
        loss = cvae_loss(recon_x, x, mu, logvar)  # 计算损失

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader.dataset)}")
```

---

### **注释总结**
代码注释涵盖了每个部分的功能和设计思路，方便理解：
1. **Encoder 和 Decoder 的功能**：分别负责特征提取和数据生成。
2. **重参数化技巧**：实现从隐变量分布中采样。
3. **损失函数**：平衡生成能力（

重构误差）和分布约束（KL 散度）的 trade-off。
4. **训练循环**：包含前向传播、损失计算、反向传播以及参数更新的流程。

通过这些注释，代码结构更加清晰，便于理解和复现。



```bash
Traceback (most recent call last):
  File "F:\HOP\msg_code\train.py", line 269, in <module>
    torch.save(tom_trainer.get_policy(f'ToM{i+1}').get_weights(),f'./state_dict/ToM/ToM{i+1}.pth')
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\tune\trainable.py", line 314, in train
    result = self.step()
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\rllib\agents\trainer.py", line 880, in step
    raise e
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\rllib\agents\trainer.py", line 867, in step
    result = self.step_attempt()
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\rllib\agents\trainer.py", line 920, in step_attempt
    step_results = next(self.train_exec_impl)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 756, in __next__
    return next(self.built_iterator)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 783, in apply_foreach
    for item in it:
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 843, in apply_filter
    for item in it:
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 843, in apply_filter
    for item in it:
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 783, in apply_foreach
    for item in it:
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 828, in add_wait_hooks
    item = next(it)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 783, in apply_foreach
    for item in it:
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\util\iter.py", line 551, in base_iterator
    batch = ray.get(obj_ref)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\_private\client_mode_hook.py", line 105, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\worker.py", line 1713, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(MemoryError): ray::RolloutWorker.par_iter_next_batch() (pid=38588, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001A5D34BC288>)
  File "python\ray\_raylet.pyx", line 688, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 689, in ray._raylet.execute_task
  File "python\ray\_raylet.pyx", line 1854, in ray._raylet.CoreWorker.store_task_outputs
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\serialization.py", line 361, in serialize
    return self._serialize_to_msgpack(value)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\serialization.py", line 341, in _serialize_to_msgpack
    self._serialize_to_pickle5(metadata, python_objects)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\serialization.py", line 301, in _serialize_to_pickle5
    raise e
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\serialization.py", line 298, in _serialize_to_pickle5
    value, protocol=5, buffer_callback=writer.buffer_callback)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\cloudpickle\cloudpickle_fast.py", line 73, in dumps
    cp.dump(obj)
  File "C:\Users\admin\AppData\Roaming\Python\Python37\site-packages\ray\cloudpickle\cloudpickle_fast.py", line 620, in dump
    return Pickler.dump(self, obj)
MemoryError
```