以下是你提供图像中内容的**完整文字转写（英文原文 + 正确公式）**，并附上**专业中文翻译版**，确保保留所有关键术语与数学公式的准确性。

---

## 📄 原文（英文）转写（含公式）

**4.2 Opponent Modeling Based on Subgoal Inference**

Our opponent modeling consists of two components: *subgoal inference model* and *subgoal selector*. The subgoal inference model employs the historical trajectory to predict the opponent’s subgoal, serving as input for the policy during the interaction phase. The subgoal selector scrutinizes the entire historical trajectory using a value-based heuristic to choose the appropriate subgoal for training the inference model during the update phase.

**Subgoal inference model.** The subgoal $g$ represents a feature embedding of a future state. Specifically, for a trajectory  
$$\{s_0, a_0, a_0^{-i}, \ldots, s_t, a_t, a_t^{-i}, \ldots, s_T\},$$  
the state corresponding to subgoal $g_t$ at $s_t$ is one of future states $\mathcal{N}_t = \{s_{t+1}, s_{t+2}, \ldots, s_T\}$, denoted as $s_t^g$ and determined by the subgoal selector.

The objective of the subgoal inference model is to infer $g_t$ from the historical trajectory  
$$\tau_t = \{s_0, a_0, a_0^{-i}, \ldots, s_{t-1}, a_{t-1}, a_{t-1}^{-i}\}.$$  
This aligns with the intuitive hypothesis that the opponent’s intention can often be inferred after just a few initial actions.

Here, we introduce variational inference and employ a conditional variational auto-encoder (CVAE) as the subgoal inference model. In this model, we represent the subgoal posterior probability as $q_\phi(\hat{g}_t | \tau_t, s_t)$ and the likelihood estimate as $p_\theta(s_t | \hat{g}_t, \tau_t)$ with $\phi$ and $\theta$ respectively denoting the network parameters. The subgoal prior model, denoted as $p_\psi$, is a pre-trained variational autoencoder (VAE) using the states previously collected in the environment, and produces the subgoal prior $p_\psi(\bar{g}_t | s_t^g)$ given the subgoal state $s_t^g$ chosen by the subgoal selector.

Further details about the network architecture are provided in Figure 2. The optimization objective of the subgoal inference model is:

$$\langle \hat{\theta}, \hat{\phi} \rangle = \arg\max_{\theta, \phi} \mathbb{E}_{q_\phi(\hat{g}_t|\tau_t,s_t)} \left[ \log p_\theta(s_t|\hat{g}_t, \tau_t) \right] - \text{KL}\left( q_\phi(\hat{g}_t|\tau_t, s_t) \parallel p_\psi(\bar{g}_t | s_t^g) \right)
\tag{5}$$

---

## 📘 中文专业翻译（含公式）

**4.2 基于子目标推断的对手建模**

本研究的对手建模模块包括两个主要组成部分：**子目标推断模型**（subgoal inference model）与**子目标选择器**（subgoal selector）。子目标推断模型通过分析对手的历史轨迹，预测其可能的子目标，用作交互阶段策略的输入。而子目标选择器在模型更新阶段，则基于整段历史轨迹利用价值启发式方法，选择合适的子目标，用于监督推断模块的训练。

**子目标推断模型。** 子目标 $g$ 表示一个未来状态的特征嵌入表示。具体来说，对于一条轨迹  
$$\{s_0, a_0, a_0^{-i}, \ldots, s_t, a_t, a_t^{-i}, \ldots, s_T\},$$  
在时刻 $s_t$ 上对应的子目标状态 $g_t$ 是将来某个状态，即未来状态集合  
$$\mathcal{N}_t = \{s_{t+1}, s_{t+2}, \ldots, s_T\}$$  
中的某一项，记作 $s_t^g$，该状态由子目标选择器选择确定。

子目标推断模型的目标是基于历史轨迹  
$$\tau_t = \{s_0, a_0, a_0^{-i}, \ldots, s_{t-1}, a_{t-1}, a_{t-1}^{-i}\}$$  
推断出当前时刻的子目标 $g_t$。这一建模方式符合“对手意图往往可以通过早期行为进行推断”的直觉假设。

在模型实现上，我们引入了变分推断方法，并采用**条件变分自编码器（CVAE）**来作为子目标推断模型。其中，子目标后验分布表示为  
$$q_\phi(\hat{g}_t | \tau_t, s_t)，$$  
似然项为  
$$p_\theta(s_t | \hat{g}_t, \tau_t)，$$  
其中 $\phi$、$\theta$ 分别表示网络的参数。子目标先验模型表示为 $p_\psi$，由在环境中预先采集的状态数据训练得到，是一个预训练的变分自编码器模型。它在给定由子目标选择器选出的目标状态 $s_t^g$ 时，生成先验分布  
$$p_\psi(\bar{g}_t | s_t^g)。$$

子目标推断模型的优化目标如下所示：

$$\langle \hat{\theta}, \hat{\phi} \rangle = \arg\max_{\theta, \phi} \mathbb{E}_{q_\phi(\hat{g}_t|\tau_t,s_t)} \left[ \log p_\theta(s_t|\hat{g}_t, \tau_t) \right] - \text{KL}\left( q_\phi(\hat{g}_t|\tau_t, s_t) \parallel p_\psi(\bar{g}_t | s_t^g) \right)
\tag{5}$$

---

是否继续为你写“算法部分正文”或将这部分融合进你的**方法论章节**？我可以直接用论文格式起草第4章对应小节，让我们继续推动你论文的主干章节～



![[2e09d6e0149dd34c73093d51b1a36a8.png]]