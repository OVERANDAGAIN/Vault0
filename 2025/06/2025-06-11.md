---
创建时间: 2025-六月-11日  星期三, 5:35:03 下午
---

# HOP+
```bash
agent_timesteps_total: 2621
custom_metrics: {}
date: 2025-06-11_16-44-03
done: false
episode_len_mean: 29.884615384615383
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 3.826923076923077
episode_reward_min: 2.0
episodes_this_iter: 52
episodes_total: 52
experiment_id: 66485f60c22847cd8be1e230b0d667fa
hostname: DESKTOP-80GEA2G
info:
  learner:
    ToM1:
      learner_stats:
        action_compute_count: 0.0
        mcts_backup_time_s: 0.0
        mcts_expand_time_s: 0.0
        mcts_final_time_s: 0.0
        mcts_select_time_s: 0.0
        mcts_total_time_s: 0.0
        policy_loss: 1.3033888339996338
        t1_prepare_time_s: 0.0
        t2_subgoal_time_s: 0.0
        t3_mcts_time_s: 0.0
        total_compute_action_time_s: 0.0
        total_loss: 0.7816367745399475
        value_loss: 0.25988462567329407
    ToM2:
      learner_stats:
        action_compute_count: 0.0
        mcts_backup_time_s: 0.0
        mcts_expand_time_s: 0.0
        mcts_final_time_s: 0.0
        mcts_select_time_s: 0.0
        mcts_total_time_s: 0.0
        policy_loss: 1.3284956216812134
        t1_prepare_time_s: 0.0
        t2_subgoal_time_s: 0.0
        t3_mcts_time_s: 0.0
        total_compute_action_time_s: 0.0
        total_loss: 0.9056902527809143
        value_loss: 0.48288488388061523
    ToM3:
      learner_stats:
        action_compute_count: 0.0
        mcts_backup_time_s: 0.0
        mcts_expand_time_s: 0.0
        mcts_final_time_s: 0.0
        mcts_select_time_s: 0.0
        mcts_total_time_s: 0.0
        policy_loss: 1.3053172826766968
        t1_prepare_time_s: 0.0
        t2_subgoal_time_s: 0.0
        t3_mcts_time_s: 0.0
        total_compute_action_time_s: 0.0
        total_loss: 0.9421072602272034
        value_loss: 0.5788972973823547
    ToM4:
      learner_stats:
        action_compute_count: 0.0
        mcts_backup_time_s: 0.0
        mcts_expand_time_s: 0.0
        mcts_final_time_s: 0.0
        mcts_select_time_s: 0.0
        mcts_total_time_s: 0.0
        policy_loss: 1.2703763246536255
        t1_prepare_time_s: 0.0
        t2_subgoal_time_s: 0.0
        t3_mcts_time_s: 0.0
        total_compute_action_time_s: 0.0
        total_loss: 0.8160179257392883
        value_loss: 0.36165937781333923
  num_agent_steps_sampled: 2621
  num_agent_steps_trained: 2621
  num_steps_sampled: 1554
  num_steps_trained: 1554
iterations_since_restore: 1
node_ip: 127.0.0.1
num_healthy_workers: 3
off_policy_estimator: {}
perf:
  cpu_util_percent: 3.1114555256064693
  gpu_util_percent0: 0.9062264150943395
  ram_util_percent: 46.261275831087154
  vram_util_percent0: 0.2320052734971945
pid: 19440
policy_reward_max:
  ToM1: 5.0
  ToM2: 5.0
  ToM3: 5.0
  ToM4: 5.0
policy_reward_mean:
  ToM1: 0.8653846153846154
  ToM2: 1.016025641025641
  ToM3: 0.9391025641025641
  ToM4: 1.0064102564102564
policy_reward_min:
  ToM1: 0.0
  ToM2: 0.0
  ToM3: 0.0
  ToM4: 0.0
sampler_perf:
  mean_action_processing_ms: 0.10780447380721575
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0951609592479843
  mean_inference_ms: 3020.550360722292
  mean_raw_obs_processing_ms: 0.550332738009303
time_since_restore: 1679.5527710914612
time_this_iter_s: 1679.5527710914612
time_total_s: 1679.5527710914612
timers:
  learn_throughput: 4321.955
  learn_time_ms: 359.56
  sample_throughput: 0.925
  sample_time_ms: 1679153.625
  update_time_ms: 7.001
timestamp: 1749631443
timesteps_since_restore: 0
timesteps_this_iter: 0
timesteps_total: 1554
training_iteration: 1
trial_id: default

```


```
 pid=9964) [Timer] MCTS Total: 397.9170s | select: 272.7855s | expand: 121.8405s | backup: 3.2377s | final: 0.0532s 
 pid=9964) 1[Timer] Total: 0.1188s | T1: 0.0000s | T2: 0.0010s | T3: 0.1178s | Sum: 0.1188s 
 pid=9964) 1[Timer] Total Total: 399.1039s | self.timer_t1_total: 0.0110s | self.timer_t2_total: 0.9672s | self.timer_t3_total: 398.1257s 
```

```
pid=9964) [Timer] MCTS Total: 370.8085s | select: 237.2113s | expand: 130.1363s | backup: 3.4197s | final: 0.0412s 
 pid=9964) 2[Timer] Total: 0.1198s | T1: 0.0000s | T2: 0.0020s | T3: 0.1178s | Sum: 0.1198s 
 pid=9964) 2[Timer] Total Total: 371.4923s | self.timer_t1_total: 0.0140s | self.timer_t2_total: 0.3702s | self.timer_t3_total: 371.1081s 
```

```
 pid=9964) [Timer] MCTS Total: 506.2037s | select: 335.0818s | expand: 167.0879s | backup: 3.9805s | final: 0.0535s 
 pid=9964) 3[Timer] Total: 0.1526s | T1: 0.0000s | T2: 0.0010s | T3: 0.1516s | Sum: 0.1526s 
 pid=9964) 3[Timer] Total Total: 506.8729s | self.timer_t1_total: 0.0150s | self.timer_t2_total: 0.3822s | self.timer_t3_total: 506.4757s 
```

```bash
 pid=9964) [Timer] MCTS Total: 399.3196s | select: 254.2065s | expand: 141.8615s | backup: 3.2021s | final: 0.0495s 
 pid=9964) 4[Timer] Total: 0.0370s | T1: 0.0000s | T2: 0.0010s | T3: 0.0360s | Sum: 0.0370s 
 pid=9964) 4[Timer] Total Total: 399.9435s | self.timer_t1_total: 0.0120s | self.timer_t2_total: 0.3391s | self.timer_t3_total: 399.5924s 
```



```bash
 pid=9964) [Learn step 0] Triggering OMG_AM training...
 pid=9964) ReplayBuffer. 18/200 episodes. Keys:dict_keys(['state', 'obs', 'actions', 'avail_actions', 'reward', 'time', 'terminated', 'agent_idx', 'actions_onehot', 'filled', 'infer_mu', 'infer_log_var']) Groups:dict_keys(['agents', 'n_actions'])
 pid=9964) OMG_AM buffer not ready to sample
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 17/200
 pid=9964) Buffer size for model 4: 17/200
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 18/200
 pid=9964) Buffer size for model 4: 17/200
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 18/200
 pid=9964) Buffer size for model 4: 18/200
 pid=9964) [Train] progress time  耗时: 0.0020 秒
 pid=9964) EpisodeBatch. Batch Size:1 Max_seq_len:36 Keys:dict_keys(['state', 'obs', 'actions', 'avail_actions', 'reward', 'time', 'terminated', 'agent_idx', 'actions_onehot', 'filled', 'infer_mu', 'infer_log_var']) Groups:dict_keys(['agents', 'n_actions'])
 pid=9964) [Learn step 0] Triggering OMG_AM training...
 pid=9964) ReplayBuffer. 18/200 episodes. Keys:dict_keys(['state', 'obs', 'actions', 'avail_actions', 'reward', 'time', 'terminated', 'agent_idx', 'actions_onehot', 'filled', 'infer_mu', 'infer_log_var']) Groups:dict_keys(['agents', 'n_actions'])
 pid=9964) OMG_AM buffer not ready to sample
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 17/200
 pid=9964) Buffer size for model 3: 17/200
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 18/200
 pid=9964) Buffer size for model 3: 17/200
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 18/200
 pid=9964) Buffer size for model 3: 18/200
```


# DOM
```bash
agent_timesteps_total: 2840
custom_metrics: {}
date: 2025-06-11_18-07-31
done: false
episode_len_mean: 32.520833333333336
episode_media: {}
episode_reward_max: 11.000000000000002
episode_reward_mean: 3.0416666666666665
episode_reward_min: 2.0
episodes_this_iter: 48
episodes_total: 48
experiment_id: a5ef4d3be35d48e19451a24a6ee709cf
hostname: DESKTOP-80GEA2G
info:
  learner:
    ToM1:
      learner_stats:
        policy_loss: 1.3340363502502441
        total_loss: 0.7366928458213806
        train_duration_sec: 0.007649914423624674
        value_loss: 0.13934928178787231
    ToM2:
      learner_stats:
        policy_loss: 1.3280129432678223
        total_loss: 0.7576085925102234
        train_duration_sec: 0.003600597381591797
        value_loss: 0.18720407783985138
    ToM3:
      learner_stats:
        policy_loss: 1.227567434310913
        total_loss: 0.7894496917724609
        train_duration_sec: 0.00326685905456543
        value_loss: 0.3513321876525879
    ToM4:
      learner_stats:
        policy_loss: 1.320270299911499
        total_loss: 0.7830553650856018
        train_duration_sec: 0.003745746612548828
        value_loss: 0.2458404153585434
  num_agent_steps_sampled: 2840
  num_agent_steps_trained: 2840
  num_steps_sampled: 1561
  num_steps_trained: 1561
iterations_since_restore: 1
node_ip: 127.0.0.1
num_healthy_workers: 3
off_policy_estimator: {}
perf:
  cpu_util_percent: 2.7258426966292135
  gpu_util_percent0: 0.7115056179775281
  ram_util_percent: 48.440000000000005
  vram_util_percent0: 0.1973490483012502
pid: 16488
policy_reward_max:
  ToM1: 3.3333333333333335
  ToM2: 1.0
  ToM3: 3.3333333333333335
  ToM4: 3.3333333333333335
policy_reward_mean:
  ToM1: 0.7361111111111112
  ToM2: 0.7395833333333334
  ToM3: 0.9027777777777778
  ToM4: 0.6631944444444445
policy_reward_min:
  ToM1: 0.0
  ToM2: 0.0
  ToM3: 0.0
  ToM4: 0.0
sampler_perf:
  mean_action_processing_ms: 0.10220404753163163
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0869153986153619
  mean_inference_ms: 1139.7875024059947
  mean_raw_obs_processing_ms: 3.849286424856192
time_since_restore: 671.5017113685608
time_this_iter_s: 671.5017113685608
time_total_s: 671.5017113685608
timers:
  learn_throughput: 4784.037
  learn_time_ms: 326.293
  sample_throughput: 2.326
  sample_time_ms: 671140.478
  update_time_ms: 7.0
timestamp: 1749636451
timesteps_since_restore: 0
timesteps_this_iter: 0
timesteps_total: 1561
training_iteration: 1
trial_id: default
```


```bash
 pid=17488) [Timer] MCTS Total: 196.7622s | select: 56.6199s | expand: 135.6800s | backup: 4.4034s | final: 0.0590s 
 pid=17488) 1[Timer] Total: 0.0600s | T1: 0.0000s | T2: 0.0000s | T3: 0.0600s | Sum: 0.0600s 
 pid=17488) 1[Timer] Total Total: 197.0559s | self.timer_t1_total: 0.0050s | self.timer_t2_total: 0.0060s | self.timer_t3_total: 197.0449s 
```

```bash
 pid=17488) [Timer] MCTS Total: 163.5176s | select: 54.4255s | expand: 105.9431s | backup: 3.1121s | final: 0.0370s 
 pid=17488) 2[Timer] Total: 0.0790s | T1: 0.0000s | T2: 0.0000s | T3: 0.0790s | Sum: 0.0790s 
 pid=17488) 2[Timer] Total Total: 163.7434s | self.timer_t1_total: 0.0010s | self.timer_t2_total: 0.0040s | self.timer_t3_total: 163.7384s 
```

```bash
 pid=17488) [Timer] MCTS Total: 68.3561s | select: 20.1044s | expand: 46.5216s | backup: 1.6977s | final: 0.0324s 
 pid=17488) 3[Timer] Total: 0.0180s | T1: 0.0000s | T2: 0.0000s | T3: 0.0180s | Sum: 0.0180s 
 pid=17488) 3[Timer] Total Total: 68.4770s | self.timer_t1_total: 0.0040s | self.timer_t2_total: 0.0020s | self.timer_t3_total: 68.4710s 
```

```bash
 pid=17488) [Timer] MCTS Total: 237.7415s | select: 71.1078s | expand: 161.7920s | backup: 4.7821s | final: 0.0596s 
 pid=17488) 4[Timer] Total: 0.0090s | T1: 0.0000s | T2: 0.0000s | T3: 0.0090s | Sum: 0.0090s 
 pid=17488) 4[Timer] Total Total: 238.0720s | self.timer_t1_total: 0.0065s | self.timer_t2_total: 0.0080s | self.timer_t3_total: 238.0575s 
```