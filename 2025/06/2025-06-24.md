---
创建时间: 2025-六月-24日  星期二, 4:51:21 下午
---

deadline 前三week


---


### **Slide Title: HOP+ 模型训练耗时明显偏高**

---

#### 问题描述

* 在相同环境和参数设置下，**HOP+ 模型的每轮训练迭代耗时远高于 Direct-OM**。
* **HOP+ 平均每轮耗时约 1676 秒**，而 Direct-OM 仅为 **约 667 秒**，**总耗时提升超过 60%**。
* 多轮实验中，该现象持续稳定。

---

####  对比示意

| 模型        | 每轮总耗时（秒） | 相对提升  |
| --------- | -------- | ----- |
| HOP+      | 1676     | –     |
| Direct-OM | 667      | +151% |

---

```bash
RLlib.train_one_iteration()
├── compute_actions() ──────────────────────────────── [核心耗时阶段，≈ 99%]
│    ├── prepare() ──────────────────────────────── (观测处理 + 状态编码)
│    ├── subgoal_inference() ───────────────────── (预测 goal)
│    └── MCTS() ─────────────────────────────────── [最耗时部分]
│         └── for _ in num_simulations:
│              ├── select() ──────────────────────── (搜索路径: O(depth))
│              │    ├── best_action() ─────────────── (遍历所有可选动作)
│              │    └── get_child() ──────────────── (调用环境 + NN 推理)
│              │         ├── env.set_state()
│              │         ├── get_obs()
│              │         ├── model.get_action() × 多 agent
│              │         └── model_goal.cal_subgoal() ← *HOP+额外开销*
│              ├── expand() ─────────────────────── (新增树节点)
│              ├── backup() ─────────────────────── (值回传)
│              └── final() ──────────────────────── (最终动作选择)
│
├── postprocess_trajectory() ─────────────────────── [少量开销]
│
└── learn_on_batch() ──────────────────────────────── [训练]
     └── 利用采样数据计算 loss，进行梯度下降更新

```



---

# 分析MCTS的select阶段

### 调用：
* 每次调用 `select`，都需要不断调用：
  * `best_action()` → `child_Q()` + `child_U()` → 多次数组操作
  * `get_child()` → 访问 `children` 字典

---


fenye
fenye
fenye
fenye
fenye
fenye
fenye
fenye
fenye
fenye
fenye
fenye
fenye

---



修改细节：
- 在`sample_batch`里加入`other_agent_action`和`recurrent_state`
- 在`episode_batch`里加入`recurrent_state`
- 输入`MOA`的`obs`视角转换

存在问题：
- `seq_lens`和`lstm_state_size`的设置

