---
创建时间: 2025-六月-24日  星期二, 4:51:21 下午
---

### **Slide Title: HOP+ 模型训练耗时明显偏高**

---

#### 问题描述

* 在相同环境和参数设置下，**HOP+ 模型的每轮训练迭代耗时远高于 Direct-OM**。
* **HOP+ 平均每轮耗时约 1676 秒**，而 Direct-OM 仅为 **约 667 秒**，**总耗时提升超过 60%**。
* 多轮实验中，该现象持续稳定。

---

####  对比示意

| 模型        | 每轮总耗时（秒） | 相对提升  |
| --------- | -------- | ----- |
| HOP+      | 1676     | –     |
| Direct-OM | 667      | +151% |

---

```bash
RLlib.train_one_iteration()
├── compute_actions() ──────────────────────────────── [核心耗时阶段，≈ 99%]
│    ├── prepare() ──────────────────────────────── (观测处理 + 状态编码)
│    ├── subgoal_inference() ───────────────────── (预测 goal)
│    └── MCTS() ─────────────────────────────────── [最耗时部分]
│         └── for _ in num_simulations:
│              ├── select() ──────────────────────── (搜索路径: O(depth))
│              │    ├── best_action() ─────────────── (遍历所有可选动作)
│              │    └── get_child() ──────────────── (调用环境 + NN 推理)
│              │         ├── env.set_state()
│              │         ├── get_obs()
│              │         ├── model.get_action() × 多 agent
│              │         └── model_goal.cal_subgoal() ← *HOP+额外开销*
│              ├── expand() ─────────────────────── (新增树节点)
│              ├── backup() ─────────────────────── (值回传)
│              └── final() ──────────────────────── (最终动作选择)
│
├── postprocess_trajectory() ─────────────────────── [少量开销]
│
└── learn_on_batch() ──────────────────────────────── [训练]
     └── 利用采样数据计算 loss，进行梯度下降更新

```

