引入行为经济学中的“风险厌恶”与“有限理性”建模，提出了一种新的多智能体博弈均衡解概念——风险厌恶量化响应均衡（RQE），在矩阵博弈和有限时间马尔可夫博弈中均具备可计算性，并通过无悔学习实现。相比经典的纳什均衡或CCE等解概念，RQE更能模拟人类行为，具备可计算性和行为解释性。

。、具有建立新型MARL算法的潜力

将行为经济学中的“风险规避”与“有限理性”引入多智能体博弈中，提出风险规避量化响应均衡（RQE）这一新解概念，首次证明其在矩阵博弈与有限时域Markov博弈中具备普适的可计算性。该解概念不仅契合实验经济学中人类博弈行为的统计特征，还可通过去中心化的无悔学习算法高效求解，兼顾建模解释性与算法可行性，对多智能体系统中的均衡求解和策略建模具有重要启发意义。


3	引入行为经济学中的“风险厌恶”与“有限理性”建模，提出了一种新的多智能体博弈均衡解概念——风险厌恶量化响应均衡（RQE），在矩阵博弈和有限时间马尔可夫博弈中均具备可计算性，并通过无悔学习实现。相比经典的纳什均衡或CCE等解概念，RQE更能模拟人类行为，具备可计算性和行为解释性，具有建立新型MARL算法的潜力。	Tractable Multi-Agent Reinforcement Learning Through Behavioral Economics	Eric Mazumdar, Kishan Panaganti, Laixi Shi (Caltech)	ICLR 2025	We propose a new class of equilibria for multi-agent reinforcement learning (MARL) by incorporating two key aspects of human decision-making—risk aversion and bounded rationality—into agents. We define the resulting equilibrium as the Risk-Averse Quantal Response Equilibrium (RQE), which is shown to be computationally tractable in all matrix games and finite-horizon Markov games under certain parameter conditions. We demonstrate that RQE generalizes human behavioral patterns better than classical NE or QRE and provide both theoretical analysis and experimental results, including sample complexity bounds under generative models. This opens the door to principled MARL algorithms based on human-inspired equilibrium concepts.	[Tractable Multi-Agent Reinforcement Learning through Behavioral Economics \| OpenReview](https://openreview.net/forum?id=stUKwWBuBm)	***	2025/7/6
