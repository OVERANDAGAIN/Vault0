```python
            next_obs_batch, reward_batch, done_batch, _ = envs.step(step_action_dicts)
            # (4,5,,,,) (4,5,) (5,5)
            # 处理每个 env
            for i in range(args.num_envs):

                for aid in list(env_alive_agents[i]):
                    # 如果该 agent 已完成
                    # if aid not in next_obs_batch[i] or (aid in done_batch[i] and done_batch[i][aid]):
                    #     env_alive_agents[i].remove(aid)
                    if aid not in next_obs_batch or i >= len(next_obs_batch[aid]):
                        env_alive_agents[i].remove(aid)
                    elif aid in done_batch and i < len(done_batch[aid]) and done_batch[aid][i]:
                        env_alive_agents[i].remove(aid)

                    print(aid , " " , i )
                    # agent_trajectories[aid].append(
                    #     Transition(
                    #         obs_dict,
                    #         torch.tensor(action_batch[i][aid]),
                    #         logprob_batch[i][aid],
                    #         torch.tensor(reward_batch[aid][i], dtype=torch.float32),
                    #         value_batch[i][aid]
                    #     )
                    # )
```


![[Pasted image 20250711110849.png]]



![[Pasted image 20250711110936.png]]

![[Pasted image 20250711110948.png]]

## envs.step()

![[Pasted image 20250711111159.png]]

![[Pasted image 20250711111219.png]]


![[Pasted image 20250711111238.png]]

