## å•æ™ºèƒ½ä½“
- åŸºäºä»·å€¼çš„æ–¹æ³•
    - åŠ¨æœºï¼šåœ¨é«˜ç»´/è¿ç»­çŠ¶æ€ä¸‹é€¼è¿‘Qå€¼å‡½æ•°
        - [DQN](https://arxiv.org/abs/1312.5602) ; Mnih et al., 2013
            - æ”¹è¿›æ–¹å‘ï¼šæå‡ç¨³å®šæ€§
                - [Double DQN](https://arxiv.org/abs/1509.06461) ; van Hasselt et al., 2015
                - [Dueling DQN](https://arxiv.org/abs/1511.06581) ; Wang et al., 2016
            - æ”¹è¿›æ–¹å‘ï¼šæå‡æ•°æ®æ•ˆç‡
                - [Prioritized Replay](https://arxiv.org/abs/1511.05952) ; Schaul et al., 2015
- åŸºäºç­–ç•¥çš„æ–¹æ³•
    - åŠ¨æœºï¼šç›´æ¥å­¦ä¹ å‚æ•°åŒ–ç­–ç•¥è€Œéå€¼å‡½æ•°
        - [REINFORCE](https://link.springer.com/article/10.1007/BF00992696) ; Williams, 1992
            - æ”¹è¿›æ–¹å‘ï¼šé™ä½æ–¹å·®ã€æå‡æ”¶æ•›æ€§
                - [Actorâ€“Critic](https://papers.nips.cc/paper_files/paper/2000/hash/091d584fced301b442654dd8c23b3fc9-Abstract.html) ; Konda & Tsitsiklis, 2000
            - æ”¹è¿›æ–¹å‘ï¼šç¨³å®šæ›´æ–°è¿‡ç¨‹
                - [TRPO](https://arxiv.org/abs/1502.05477) ; Schulman et al., 2015
                - [PPO](https://arxiv.org/abs/1707.06347) ; Schulman et al., 2017
- è¿ç»­åŠ¨ä½œæ§åˆ¶
    - åŠ¨æœºï¼šå¤„ç†æ— é™åŠ¨ä½œç©ºé—´ã€æå‡é‡‡æ ·æ•ˆç‡
        - [DDPG](https://arxiv.org/abs/1509.02971) ; Lillicrap et al., 2015
            - æ”¹è¿›æ–¹å‘ï¼šæå‡ç¨³å®šæ€§ä¸é²æ£’æ€§
                - [SAC](https://arxiv.org/abs/1801.01290) ; Haarnoja et al., 2018
- æ¨¡ä»¿å­¦ä¹ 
    - åŠ¨æœºï¼šå¥–åŠ±ä¿¡å·ç¼ºå¤±æˆ–éš¾ä»¥è®¾è®¡
        - [Behavior Cloning](https://dl.acm.org/doi/10.1145/97243.97245) ; Pomerleau, 1989
        - [GAIL](https://arxiv.org/abs/1606.03476) ; Ho & Ermon, 2016
- åŸºäºæ¨¡å‹çš„æ–¹æ³•
    - åŠ¨æœºï¼šé€šè¿‡ç¯å¢ƒæ¨¡å‹é™ä½çœŸå®äº¤äº’éœ€æ±‚
        - [MPC](https://www.sciencedirect.com/science/article/pii/S0005109804002766) ; Mayne, 2005
        - [PETS](https://arxiv.org/abs/1805.12114) ; Chua et al., 2018
        - [MBPO](https://arxiv.org/abs/1906.08253) ; Janner et al., 2019
- ç¦»çº¿å¼ºåŒ–å­¦ä¹ 
    - åŠ¨æœºï¼šæ— äº¤äº’æˆ–å±é™©åœºæ™¯ä¸‹åˆ©ç”¨å›ºå®šæ•°æ®
        - [BCQ](https://arxiv.org/abs/1812.02900) ; Fujimoto et al., 2019
        - [CQL](https://arxiv.org/abs/2006.04779) ; Kumar et al., 2020
        - [IQL](https://arxiv.org/abs/2110.06169) ; Kostrikov et al., 2021
- ç›®æ ‡æ¡ä»¶ä¸æ³›åŒ–
    - åŠ¨æœºï¼šè§£å†³å¤šä»»åŠ¡ã€å¤åˆç›®æ ‡çš„æ³›åŒ–èƒ½åŠ›
        - [UVFA](https://arxiv.org/abs/1802.09464) ; Schaul et al., 2015
        - [HER](https://arxiv.org/abs/1707.01495) ; Andrychowicz et al., 2017
        - [Meta-RL (MAML)](https://arxiv.org/abs/1703.03400) ; Finn et al., 2017








å¾ˆå¥½ï¼Œä½ è´´å‡ºçš„è¿™éƒ¨åˆ†å…¶å®å°±æ˜¯è¿™ç¯‡ç»¼è¿°è®ºæ–‡ï¼ˆDu et al. 2023ï¼‰çš„ **èƒŒæ™¯ç« èŠ‚ (Section 2)**ã€‚å¦‚æœæˆ‘ä»¬è¦æŠŠå®ƒè½¬åŒ–æˆæ€ç»´å¯¼å›¾æ ¼å¼ï¼Œå¯ä»¥åšå¾—æ¯”åŸæ–‡æ›´ç»“æ„åŒ–ï¼šä¸Šå±‚èŠ‚ç‚¹æ˜¯ **ç†è®ºæ¡†æ¶ï¼ˆMDP, POMDP, Markov Games, POMGï¼‰**ï¼Œä¸­å±‚èŠ‚ç‚¹æ˜¯ **å­¦ä¹ èŒƒå¼ï¼ˆvalue-based, policy-based, actor-criticï¼‰**ï¼Œå†å¾€ä¸‹æŒ‚ä¸Š**ä»£è¡¨æ€§æ–¹æ³•+è®ºæ–‡**ã€‚è¿™æ ·å’Œæˆ‘ä»¬ä¹‹å‰åšçš„â€œæ–¹æ³•ç»¼è¿°å‹å¯¼å›¾â€èƒ½å¤Ÿå¾ˆå¥½ç»“åˆã€‚

æˆ‘ç»™ä½ ä¸€ä¸ªæ•´ç†å¥½çš„ç‰ˆæœ¬ï¼ˆè®ºæ–‡å¯¼å‘ã€å±‚æ¬¡æ¸…æ™°ï¼‰ï¼š

---

# èƒŒæ™¯ï¼šå•æ™ºèƒ½ä½“ä¸å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ 

## å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ 

### ç†è®ºæ¡†æ¶

#### [MDP](https://link.springer.com/article/10.1007/BF00992696) ; Sutton, 1988



#### [POMDP](https://www.sciencedirect.com/science/article/pii/S000437029800023X) ; Cassandra, 1998



### ä»·å€¼å‡½æ•°æ–¹æ³•

#### [Q-Learning](https://link.springer.com/article/10.1007/BF00992698) ; Watkins & Dayan, 1992

* 

#### [SARSA](https://dl.acm.org/doi/10.5555/645529.657617) ; Singh et al., 2000


#### [Deep Q-Network (DQN)](https://arxiv.org/abs/1312.5602) ; Mnih et al., 2013/2015

* äººç±»æ°´å¹³ Atari è¡¨ç°

### ç­–ç•¥ä¼˜åŒ–æ–¹æ³•

#### [Policy Gradient / REINFORCE](https://dl.acm.org/doi/10.1145/138243.138273) ; Williams, 1992

* ç›´æ¥ä¼˜åŒ–å‚æ•°åŒ–ç­–ç•¥
* é«˜æ–¹å·®ï¼Œéœ€è¦æ”¹è¿›

#### [Actorâ€“Critic](https://papers.nips.cc/paper/1786-convergence-properties-of-policy-iteration) ; Konda & Tsitsiklis, 1999

* ç­–ç•¥+ä»·å€¼å¹¶è¡Œå­¦ä¹ ï¼Œé™ä½æ–¹å·®

#### [Deterministic Policy Gradient](https://arxiv.org/abs/1509.02971) ; Silver et al., 2014


#### [TRPO](https://arxiv.org/abs/1502.05477) ; Schulman et al., 2015

* ä¿¡ä»»åŸŸä¿è¯ç­–ç•¥æ›´æ–°å•è°ƒæ”¹è¿›

#### [PPO](https://arxiv.org/abs/1707.06347) ; Schulman et al., 2017



#### [SAC](https://arxiv.org/abs/1801.01290) ; Haarnoja et al., 2018

* 

---

## å¤šæ™ºèƒ½ä½“å­¦ä¹ 

### ç†è®ºæ¡†æ¶

#### [Markov Game](https://www.jmlr.org/papers/volume4/littman03a/littman03a.pdf) ; Littman, 1994

* æ‰©å±• MDP åˆ°å¤šä¸»ä½“äº¤äº’
* åŒ…å« Cooperative / Competitive / Mixed

#### \[Partially Observable Markov Game (POMG)]

* å¤šæ™ºèƒ½ä½“éƒ¨åˆ†å¯è§‚æµ‹åœºæ™¯

### è®¾ç½®åˆ†ç±»

#### Cooperative

* [Team MDP](https://link.springer.com/chapter/10.1007/3-540-61380-2_18) ; Boutilier, 1996
* [Independent Q-learning](https://link.springer.com/chapter/10.1007/3-540-45545-0_14) ; Lauer & Riedmiller, 2000

#### Competitiveï¼ˆé›¶å’Œï¼‰

* [Minimax-Q](https://www.jmlr.org/papers/volume4/littman03a/littman03a.pdf) ; Littman, 1994
* [AlphaGo Zero](https://www.nature.com/articles/nature24270) ; Silver et al., 2016
* [OpenAI Five](https://arxiv.org/abs/1912.06680) ; OpenAI, 2019

#### Mixed-motiveï¼ˆä¸€èˆ¬å’Œï¼‰

* [Nash Q-learning](https://dl.acm.org/doi/10.1145/502512.502549) ; Hu & Wellman, 2003
* [Policy Hill-Climbing](https://www.sciencedirect.com/science/article/pii/S0004370201001250) ; Littman, 2001
* å›¢é˜Ÿå†…éƒ¨åä½œ + å›¢é˜Ÿé—´å¯¹æŠ—ï¼ˆå¦‚ AlphaStar, Jaderberg et al., 2019ï¼‰

---

ğŸ“Œ è¿™æ ·ç»„ç»‡çš„å¥½å¤„ï¼š

* **èƒŒæ™¯ç†è®º**ï¼ˆMDP, POMDP, Markov Game, POMGï¼‰ä½œä¸ºâ€œæ ¹èŠ‚ç‚¹â€
* **å­¦ä¹ èŒƒå¼**ï¼ˆvalue-based, policy-based, actor-criticï¼‰å¯¹é½å•æ™ºèƒ½ä½“
* **è®¾ç½®åˆ†ç±»**ï¼ˆcooperative, competitive, mixedï¼‰å¯¹é½å¤šæ™ºèƒ½ä½“
* æ‰€æœ‰å¶å­éƒ½è½åˆ°å…·ä½“è®ºæ–‡ï¼ˆå¯ç›´æ¥æŸ¥é˜…ï¼‰ã€‚

---

è¦ä¸è¦æˆ‘æŠŠè¿™ä¸€ä»½â€œèƒŒæ™¯â€ç›´æ¥å’Œä¹‹å‰æ•´ç†çš„ **å•æ™ºèƒ½ä½“ç®—æ³•æ ‘**ã€**å¤šæ™ºèƒ½ä½“åˆä½œç»¼è¿°æ ‘**æ‹¼åœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä»½â€œå¤§ä¸€ç»Ÿå¯¼å›¾â€ï¼Ÿè¿™æ ·å°±æœ‰ï¼š

1. èƒŒæ™¯ç†è®ºæ¡†æ¶
2. å•æ™ºèƒ½ä½“æ–¹æ³•ï¼ˆç»å…¸+æ·±åº¦+å‰æ²¿ï¼‰
3. å¤šæ™ºèƒ½ä½“æ–¹æ³•ï¼ˆåˆä½œç»¼è¿°ï¼‰
