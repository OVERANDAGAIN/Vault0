好的 ✅ 我明白你的格式要求了。公式要统一成你给出的这种 **加粗 + LaTeX 数学公式** 的 Markdown 风格。我来帮你把 **“正则化最小二乘解 (Ridge Regression)”** 那一节重新整理成符合你要求的格式：

---

## 📑 Regularizing the Least-Squares Solution

### 1. **问题背景**

* 最小二乘的闭式解为：

  $$
  w^{\ast} = (X^{\top}X)^{-1}X^{\top}y
  $$

* 但如果 $X^{\top}X$ **接近奇异矩阵**（almost singular），就会导致数值不稳定，难以计算逆矩阵。

---

### 2. **正则化的思路**

为了解决这个问题，可以在矩阵 $X^{\top}X$ 上加一个小的扰动项，使其更稳定：

$$
w^{\ast} = (X^{\top}X + \lambda I)^{-1}X^{\top}y
$$

其中：

* **$\lambda > 0$** 是正则化系数。
* **$I$** 是单位矩阵。

👉 这样做的效果：

* 让矩阵更接近对角阵，提升条件数；
* 保证矩阵是可逆的，计算更稳定。

---

### 3. **对应的优化目标**

这个解对应于以下优化问题（正则化的最小二乘）：

$$
\text{LS-Reg}(w) = \frac{2}{n}|y - Xw|^2 + \frac{\lambda}{2}|w|^2
$$

---

### 4. **意义**

* 这个方法称为 **Ridge Regression（岭回归）** 或 **$\ell_2$ 正则化的最小二乘**。
* 它的作用不是依赖数据本身，而是**加入了对解的偏好**：希望参数 $w$ 不要太大。
* 超参数 **$\lambda$** 控制这种偏好的强度。

---

### 5. **从贝叶斯视角**

如果我们在权重上加入一个零均值的高斯先验：

$$
p(w) = \mathcal{N}(w \mid 0, \sigma^2 I)
$$

那么求解最大后验（MAP）时，就会自然得到这个正则化形式。

---

📌 **总结**：

* 正则化最小二乘（岭回归） = 在最小二乘中加入 $\ell_2$ 惩罚项；
* 提升数值稳定性，避免过拟合；
* 从贝叶斯角度看，相当于给参数加了一个高斯先验。

---

要不要我帮你把之前 **普通最小二乘** 那一小节（未正则化的闭式解）也用这种格式整理一下？这样你的笔记会非常统一。
