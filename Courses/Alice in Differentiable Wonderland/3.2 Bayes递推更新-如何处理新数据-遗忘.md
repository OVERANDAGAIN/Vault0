[[Alice in Differentiable Wonderland]]
p49

如何理解？
>Second, the full Bayesian treatment provides a simple way to incorporate new data, e.g., ==a new dataset== $S′_{n}$ from the same distribution. To do that, we ==replace the prior function in (E.3.7) with the posterior distribution== that we computed on the first portion of the dataset, which now represents the starting assumption on the possible values of f which gets updated by looking at new data.7 This can mitigate issues when training models online, most notably the so-called catastrophic forgetting of old information





很好 👍，这段话其实是在讲 **贝叶斯推断的“递推更新”特性**，以及为什么它能天然解决 **在线学习 / 增量学习**中的“遗忘问题”。我们拆开来理解：

---

### 1. 回顾贝叶斯公式

$$
p(f \mid \mathcal{S}_n) = \frac{p(\mathcal{S}_n \mid f)\,p(f)}{p(\mathcal{S}_n)}.
$$

* **先验 $p(f)$**：在没有看到数据前对 $f$ 的假设。
* **似然 $p(\mathcal{S}_n \mid f)$**：数据 $\mathcal{S}_n$ 对 $f$ 的支持。
* **后验 $p(f \mid \mathcal{S}_n)$**：结合数据更新后的信念。

---

### 2. 新数据到来时

假设你后来又得到一个新数据集 $\mathcal{S}'_n$，仍然来自相同分布。
那么贝叶斯的做法就是：

* 把之前的后验 $p(f \mid \mathcal{S}_n)$ 当作新的先验。
* 用新的数据 $\mathcal{S}'_n$ 更新它。

即：

$$
p(f \mid \mathcal{S}_n, \mathcal{S}'_n) \;\propto\; p(\mathcal{S}'_n \mid f)\,p(f \mid \mathcal{S}_n).
$$

👉 这意味着：你不需要重新训练从头开始，只要不断更新后验即可。

---

### 3. 直观理解 🌰

可以类比“学习知识”：

* **先验**：你上课前的直觉（比如“圆周率大概等于 3”）。
* **后验**：看完第一部分教材后的结论（$\pi \approx 3.14$）。
* 当你读到第二部分教材时，你不会回到“$\pi=3$”的原始假设，而是基于“$\pi \approx 3.14$”继续修正。

这就是 **先验→后验→新先验** 的循环。

---

### 4. 为什么能避免遗忘？

在深度学习里，**catastrophic forgetting（灾难性遗忘）** 指的是：

* 模型在新任务上训练时，会覆盖掉旧任务学到的信息。

而在贝叶斯更新中：

* 旧信息通过 $p(f \mid \mathcal{S}_n)$ 变成新的先验，永远被“记忆”在概率分布里。
* 新数据只是在这个分布上进行更新，而不是完全替代。

所以贝叶斯方法天生就有“记忆历史”的机制，不会彻底丢掉旧知识。

---

✅ **总结**：
这句话强调：

* **贝叶斯更新**的最大优势是能自然处理“新数据到来”的情况。
* 后验可以递推地变成新先验，保证了历史信息不会丢失。
* 这在 **在线学习** 和 **避免灾难性遗忘** 中非常重要。

---
