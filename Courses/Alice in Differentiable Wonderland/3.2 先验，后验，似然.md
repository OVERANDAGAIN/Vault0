---
创建时间: 2025-九月-25日  星期四, 12:07:24 凌晨
---
[[Alice in Differentiable Wonderland]]
p48

# 问题：如何理解这个公式
The likelihood, and the update is given by **Bayes’ theorem**:

$$
p(f \mid \mathcal{S}_n) = \frac{p(\mathcal{S}_n \mid f)\,p(f)}{p(\mathcal{S}_n)} \tag{E.3.7}
$$

* **Prior** (before observing the dataset)
* **Posterior** (after observing the dataset)

The term $p(f \mid \mathcal{S}_n)$ is called the **posterior distribution function**, while the term $p(\mathcal{S}_n)$ in the denominator is called the **evidence** and it is needed to ensure that the posterior is properly normalized.

Assume for now that we have access to the posterior. Differently from before, **the distribution can encode preference for more than a single function $f$, which may provide better predictive power.**

Given an input $x$, we can make a prediction by averaging all possible models based on their posterior’s weight:

$$
p(y \mid x) = \int_f p(y \mid f(x)) \, p(f \mid \mathcal{S}_n) \, df 
\;\;\;\; \approx \;\;\;\; \frac{1}{k} \sum_{i=1}^k p(y \mid f_i(x)) \, p(f_i \mid \mathcal{S}_n) \tag{E.3.8}
$$
![[Pasted image 20250925000837.png]]



## 回答

好，这个问题非常关键，其实就是 **Bayesian prediction** 和 **加权平均** 的思想。我们来逐步拆开：

---

### 1. 目标是什么？

我们想要预测 $p(y \mid x)$，但是 **我们并不知道哪个函数 $f$ 才是正确的模型**。

* 在频率学派（MLE）里：直接选择一个最优的 $f^*$，然后用它预测：

  $$
  p(y \mid x) \approx p(y \mid f^*(x)).
  $$
* 在贝叶斯学派里：不选择单个 $f$，而是认为 **所有可能的 $f$** 都有一定的可信度（posterior weight），因此预测应该是它们的加权平均。

---

### 2. 为什么会有乘 $p(f \mid \mathcal{S}_n)$？

公式是：

$$
p(y \mid x) = \int p(y \mid f(x)) \, p(f \mid \mathcal{S}_n) \, df
$$

* **$p(y \mid f(x))$**：如果我只相信某个函数 $f$，它会给出预测分布。
* **$p(f \mid \mathcal{S}_n)$**：这个函数 $f$ 在观测数据 $\mathcal{S}_n$ 下的可信度（posterior 权重）。
* 乘起来就是：**给每个函数的预测打上权重**，最后把它们积分起来。

直观理解：

* 就像投票，每个函数 $f$ 给出一个预测，但它的“发言权”取决于它的 posterior 概率。
* 如果某个 $f$ 很可能（posterior 大），它对结果的贡献就大；如果它几乎不可能（posterior 小），它对结果的贡献就小。

---

### 3. 会不会改变预测？

不会。反而更合理：

* 如果你只用一个 $f^*$，预测可能会偏（过拟合风险）。
* 用所有 $f$ 的 posterior 加权平均，可以自然地引入 **模型不确定性**：

  * posterior 集中在一个 $f^*$ 附近 → 结果接近频率派预测。
  * posterior 分布比较分散 → 结果会融合多个可能模型，表达出不确定性。

---

### 4. Monte Carlo 近似

实际积分 $\int p(y \mid f(x)) p(f \mid \mathcal{S}_n) df$ 很难算，所以用采样近似：

$$
p(y \mid x) \approx \frac{1}{k} \sum_{i=1}^k p(y \mid f_i(x)) \, p(f_i \mid \mathcal{S}_n)
$$

这就是式子 (E.3.8)。

---

✅ **总结**

* 乘 $p(f \mid \mathcal{S}_n)$ 是因为我们要“加权所有可能的函数”。
* 它不会破坏预测，反而让预测更合理：把不确定性纳入考虑。
* 本质上：**单一模型预测** → **加权集成预测**，就是贝叶斯预测的核心优势。



# 问题：先验和后验的关系

## 回答
你理解得已经很接近了 👍，我帮你把 **“后验”“先验”** 的关系再直观地梳理一下：

---

### 1. 你说的理解对不对？

* **后验分布 $p(f \mid \mathcal{S}_n)$**
  👉 可以理解为：在看过数据集 $\mathcal{S}_n$ 之后，我们对“哪个函数 $f$”更可信的 **衡量**。
  它告诉我们：**给定数据，函数 $f$ 拟合得好坏的“概率”是多少**。

  * 如果某个 $f$ 在数据上表现好，后验就大。
  * 如果某个 $f$ 跟数据完全不符，后验就小。

所以，你说的“后验是对 $f$ 的好坏衡量”是对的 ✅。

---

### 2. 那么先验是什么？

* **先验分布 $p(f)$**
  👉 表示的是在还没看到任何数据之前，你对“什么样的函数更可能”有的 **先验信念**。

  * 比如：在没有数据之前，你可能觉得“平滑的函数比剧烈震荡的函数更合理”（这就可以通过一个先验 $p(f)$ 表达）。
  * 或者在机器学习里常见的“较小参数值更可信”，于是就用一个正态分布作为先验（比如 $w \sim \mathcal{N}(0, \sigma^2)$）。

---

### 3. 先验 vs. 后验 ——是不是对立？

不是对立，而是 **两个阶段的认知更新**：

* **先验 (prior)** = 你在 **看到数据之前** 的主观信念
* **似然 (likelihood)** = 数据给你的信息（某个 $f$ 对数据的解释能力）
* **后验 (posterior)** = 在结合数据之后，修正过的信念

用公式说就是：

$$
\text{后验} \;\; \propto \;\; \text{似然} \times \text{先验}
$$

所以，先验和后验不是对立，而是“**先验 → （结合数据） → 后验**”的演化关系。

---

### 4. 一个生活类比 🌰

假设你要判断一个人是不是靠谱程序员：

* **先验**：你原本的看法，比如“会写 Python 的人更可能靠谱”
* **似然**：你观察到的数据，比如“他在 1 小时内 debug 掉了一个 tricky 的 bug”
* **后验**：结合你的原本印象和新观察，你对他是否靠谱的新的判断

---

要不要我帮你画一张 **先验-似然-后验三者关系**的小流程图？这样比文字更直观。
