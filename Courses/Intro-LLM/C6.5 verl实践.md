---
创建时间: 2025-八月-5日  星期二, 4:18:51 下午
---
[[Intro-LLM]]


RL框架verl(HybridFlow)
1.  混合编程模型 $\Longrightarrow$ 控制流和计算流解耦
2. 封装模块，便于维护和扩展
3. 资源池灵活分配GPU资源
4. 通用数据传输协议
5. 单控制器架构实现控制流
6. 3D - HybridEngine







**VeRL：灵活高效的大型语言模型强化学习框架**

VeRL 框架。它是一个基于大型语言模型（LLM）的强化学习（RL）框架，特点是兼顾了复杂任务的灵活性与高效性。


 **社区与生态**

   * VeRL 已有 8000+ Stars、1000+ Forks、约 200 位贡献者。
   * 许多流行项目基于 VeRL 构建，其中不乏拥有数千 Star 的开源仓库。

![[Pasted image 20250808110008.png]]



### 一、动机与背景

一个好的框架必然是为了解决重要且困难的问题。我们要解决的问题是：大型语言模型的强化学习。

#### 为什么重要
why is large scale RL important

强化学习已经是当前最为流行的技术之一。大规模的 RL 有独特优势，比如可以让模型学会推理能力。与没有使用大规模 RL 的旗舰模型（如 GPT-4o）相比，使用了大规模 RL 的 O1、R1 等模型在数学、科学、代码等高难度基准测试中表现显著提升。
![[Pasted image 20250808110939.png]]


我帮你把图片中的表格内容提取出来，整理如下：

| Model                 | Large-Scale RL? | AIME 2024 | MATH 500 | GPQA Diamond | Code Forces |
| --------------------- | --------------- | --------- | -------- | ------------ | ----------- |
| GPT-4o (OpenAI 2024)  | ✗               | 44.6      | 60.3     | 50.6         | >11.0%      |
| o1 (OpenAI 2024)      | ✓               | 74.4      | 94.8     | 77.3         | >89.0%      |
| R1 (DeepSeek-AI 2025) | ✓               | 79.8      | 97.3     | 71.5         | >96.3%      |



RL 还能让模型学习如何成为一个智能体，与环境和工具进行交互。例如，OpenAI 推出的 Deep Research 能够在现实任务中使用浏览器、Python 等工具进行深度探索与交互，其核心技术同样基于大规模 RL。

因此，大规模 RL 是迫切需要解决的问题。
![[Pasted image 20250808111010.png]]
![[Pasted image 20250808114104.png]]


#### 为什么困难

基于 LLM 的 RL 复杂度主要来自两个方面：

1. **RL 本身的复杂度**

   * RL 通常可以建模为复杂的数据流图（Data Flow Graph），涉及多个模型（Actor、Critic、Reference、Reward 等）和多个阶段（数据生成、经验准备、训练更新）。
   * 同一模型在不同阶段的负载可能不同（如 Actor 既有生成阶段，又有训练阶段），实现方式也需优化。

![[Pasted image 20250808111045.png]]



1. **LLM 的分布式训练复杂度**

   * LLM 训练本身是大规模分布式负载，涉及数十到上千 GPU，以及数据并行（DP）、流水线并行（PP）、张量并行（TP）等复杂策略。
   * 基于 LLM 的 RL 数据流图中，每个 Operator 都可能是一个大规模分布式任务，既有 RL 的调度复杂度，又有 LLM 分布式实现的复杂度。
   * 
![[Pasted image 20250808111430.png]]

![[Pasted image 20250808111509.png]]


这会带来资源与数据依赖的多重约束，例如：

* 有依赖的计算必须串行执行。
* 同一设备上的多个模型不能同时运行。
* 只有无依赖且分布在不同设备上的任务才能并行。

![[Pasted image 20250808111548.png]]




### 二、VeRL 的设计理念

VeRL 的目标是：

* **对外**：暴露一个灵活的编程接口，让用户便捷实现任务逻辑。
* **对内**：隐藏分布式实现的复杂性，并保证运行高效。

#### 灵活性：Single Controller 范式

VeRL 采用 Single Controller 范式，可用少量代码描述复杂数据流。例如，复杂的 RL 算法（PPO、GRPO、RPO、DPO 等）都能简洁实现，用户也可在此基础上进行任务定制。
![[Pasted image 20250808111632.png]]
#### 高效性：多层优化

1. **Operator 内优化**

   * 支持多种并行方式（DP、TP、PP、上下文并行、序列并行）。
   * 支持多种训练后端（如 FSDP、Megatron）和高效 Kernel（Flash Attention、Lego Kernel、Torch Compile 等）。
   * 支持多种生成后端（vLLM、Xiang 等）。

2. **Operator 间优化：Hybrid Engine**

   * **Offloading / Reloading**：不使用的模型自动 Offload 到 CPU，需要时再 Reload，提高 GPU 利用率。
   * **Resharding**：不同阶段切换分布式策略（如从 DP 切换到 TP），实现各自最优性能。
![[Pasted image 20250808111845.png]]


### 三、核心训练范式：Hybrid Flow

传统分布式实现常面临 Single Controller（集中控制）与 Multi-Controller（对称通信）之间的权衡。

* Single Controller 灵活，但通信集中，开销大。
* Multi-Controller 高效，但编程复杂、缺乏全局信息。
![[Pasted image 20250808112009.png]]

![[Pasted image 20250808112446.png]]
![[Pasted image 20250808112455.png]]


**Hybrid Flow** 的解决方案是结合二者：


* 由 Single Controller 统一调度数据流（Prompt、Response、Experience）。
* 每个 Operator 内部由 Multi-Controller 实现大规模分布式计算。

这样既保持了调度灵活性，又获得了计算高效性。


![[Pasted image 20250808112037.png]]![[Pasted image 20250808112150.png]]![[Pasted image 20250808113018.png]]