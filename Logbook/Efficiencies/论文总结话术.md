---
created: 2024-12-20T16
updated: ...
---
[[Logbook/Efficiencies/Efficiencies|Efficiencies]]

# Questions




```text
简要总结这篇论文所讲的内容，以供我写在笔记里，后来一看就知道讲的是什么，而且不要泛泛而谈，你知道的。最好以表格形式等一目了然的形式
```


```text
从以下几个方面，帮我总结论文的以下信息，其中如果你不知道的部分，比如（Journal/Conference）可以空着。
| Title | Year | Journal/Conference | Author(s) | Take-away message | Inspiration for us |

```


| Title                                                                  | Year | Journal/Conference | Author(s)                               | Take-away message                                                                        | Inspiration for us                                                                                |
| ---------------------------------------------------------------------- | ---- | ------------------ | --------------------------------------- | ---------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------- |
| Do as We Do, Not as You Think: The Conformity of Large Language Models | 2025 | ICLR 2025          | Zhiyuan Weng, Guikun Chen, Wenguan Wang | LLMs在多智能体系统中表现出显著的“从众行为”，尤其在长期交互和多数意见引导下，容易偏离原始正确判断；提出BENCHFORM基准系统系统性评估并量化从众效应，并探讨缓解方法。 | ① 设计多智能体测试框架时应考虑“社会认知偏差”如从众性；② 我们可以借鉴其协议设计方法（如Trust/Doubt）来测试模型鲁棒性；③ 可考虑在系统中引入“反思机制”增强模型独立性与可解释性。 |


# Answers

## GPT_Answers


## DS_Answers


## Other_Answers


# Codes

```python

```


# FootNotes
