#meeting 

**Reporter:**  
报告人：黄奕喆
主题：Discovering state-of-the-art reinforcement learning algorithms
时间：2025年11月12日（周三）19：00～20:00
地点：4502
腾讯会议号：371-174-195
参考论文：https://www.nature.com/articles/s41586-025-09761-x
摘要：Humans and other animals use powerful reinforcement learning (RL) mechanisms that have been discovered by evolution over many generations of trial and error. By contrast, artificial agents typically learn using hand-crafted learning rules. Despite decades of interest, the goal of autonomously discovering powerful RL algorithms has proven elusive7-12. In this work, we show that it is possible for machines to discover a state-of-the-art RL rule that outperforms manually-designed rules. This was achieved by meta-learning from the cumulative experiences of a population of agents across a large number of complex environments. Specifically, our method discovers the RL rule by which the agent's policy and predictions are updated. In our large-scale experiments, the discovered rule surpassed all existing rules on the well-established Atari benchmark and outperformed a number of state-of-the-art RL algorithms on challenging benchmarks that it had not seen during discovery. Our findings suggest that the RL algorithms required for advanced artificial intelligence may soon be automatically discovered from the experiences of agents, rather than manually designed.
# Inspiration
# Probelms or Thinkings 
## 可能不可微分
这里的 $\theta$ 可能是不可微分的：
1. 大部分环境是不可微分的

>这里的 $\eta$ 关于 $\theta$ 是可微分的
![[Pasted image 20251112194047.png]]
# Context
# Innovation
# Background
# Related Work
# Theroy
# Methodology
# Evaluation
# Results
# Limitations
# FootNotes
