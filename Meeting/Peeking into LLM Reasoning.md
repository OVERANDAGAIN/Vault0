---
创建时间: 2025-一月-6日  星期一, 4:02:57 下午
created: 2025-01-06T17:59
updated: 2025-01-06T18:13
---
#meeting 
推理工作
reporter:张弛
# Inspiration


# Context

encoder(less)- decoder (main)
Chain of thought ; Rationale
MCTS
MoE
DeepSeek: not as good as GPT-4o-mini in experience $\Longrightarrow$ best performing in benchmark

MoE vs Dense
Dataset more important, other than model/algorithm？？？

---

 physics of language models Part 1  —— Allen-Zhu

# Innovation



# Background



# Related Work



# Theroy



# Methodology



# Evaluation



# Results



# Limitations



# FootNotes
