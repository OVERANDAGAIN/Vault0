---
创建时间: 2025-十一月-11日  星期二, 7:10:14 晚上
---
[[25-11-13-MLA汇报meeting]]

明白，我们会 **分段清理**。
我会做到：

* 去除口语、重复、语气词
* 根据论文与 PPT **恢复专业表达**
* 保留讲座口吻，不改原意
* 中英夹杂内容统一润色并自然翻译
* 每段都可直接用于 PPT 文稿或解说

---

### **现在开始输出第 1 部分（已优化整理）**

> 涵盖从开场 → 案例事故 → 为什么需要自动检测
> **你只需要把这段收下，不用回复，我会继续发第 2 部分**

---

#### **【讲座内容 第 1 部分】**

各位下午好，非常感谢大家的到来，也感谢韩教授的邀请，很荣幸今天能在这里分享我们的工作。本次报告的主题与**煤矿行业安全管理**相关，这是一个场景真实、问题具体且影响重大的研究方向。

本工作的第一作者是我的博士生，她完成了绝大部分研究和实验工作；第二作者来自中国矿业大学，为我们提供了真实的矿井应用场景与问题来源；其他合作伙伴也在数据采集与现场理解上给予了关键帮助。我本人作为通讯作者，主要负责模型设计、理论分析和报告呈现。

---

我们先从一个直观的例子开始看起。视频中，矿工乘坐的是一种叫做 **“猴车（monkey car）”** 的巷道运输装置。它的结构和姿态很像一个人悬挂在轨道下移动，因此得名。

如果是在游乐场，这种装置可能会让你觉得轻松、愉快。但**在矿井中，它是狭窄、嘈杂、长距离且非常疲劳的。** 一次乘坐往往持续 30 分钟到一个多小时。

---

重点是：**乘坐猴车本身并不危险，但违规操作却非常危险。**
我们看一段真实事故叙述：

在某矿井，工人需要将一个重达 50 公斤的耦合器运入工作面。按照安全规定，乘坐猴车时**禁止携带超过 10 公斤物品**，而且必须双手抓牢扶手、双脚悬空。但是工人为了省力，将装备抱在怀里乘车，其他人虽多次劝阻也未制止。途中，由于轨道倾斜、速度变化、姿态不稳定，耦合器突然滑落，从高处滚落并**击中另一名无辜矿工，导致死亡**。

事故调查报告的结论只有一句话：

> **事故原因：违规操作。**

在煤矿行业，大家常说：“**所有事故，99% 都是因为没按规程来。**”
而我们要做的，就是减少这些能够提前发现、可以预防的人祸。

---

目前的监控方式是：
矿井出口和巷道都安装了摄像头，管理人员实时盯着这些画面，判断矿工是否操作违规。
但**人类注意力无法长时间高强度集中**——尤其是面对 **6 小时完全相同背景** 的监控画面。

因此，我们的目标非常直接：

> **开发一套自动监测系统：自动找人 → 自动判断动作 → 自动报警。**

---

不过，这里面有两个具体子任务：

1. **定位（Localization）**
   找到画面中矿工所处的位置，即“框出人”。

2. **分类（Classification）**
   判断该矿工此刻的行为是否安全。

而难点在于：
**定位需要标注大量 bounding box（框人）数据，极其耗时、昂贵、且难以大规模进行。**
相比之下，判断“安全 / 不安全”只需专家打 **Yes / No**，成本要低很多。

因此我们思考的问题是：

> **能否完全不做框人标注，就实现自动定位？**
> 如果能做到这一步，我们就能将整个系统从昂贵、不可复制 → 变成可规模推广的工业方案。

---

好的，继续整理第 **2 部分**。
本部分从 **“为什么直接用 YOLO 不行 → 为什么必须做无监督定位”** 开始，内容已根据论文逻辑和讲座语气重新梳理并精准表述。
（本段内容源自你提供的讲座转写稿 ）

---

#### **【讲座内容 第 2 部分】**

在完成问题定义之后，我们首先尝试使用现有的成熟目标检测模型。例如，**YOLO 系列模型**已经在大型通用数据集上进行了良好的预训练，尤其擅长**检测“人”这个类别**。因此，我们最自然的想法是：

> **直接把预训练的 YOLO 拿来用，看看能否识别人。**

我们把 YOLO 模型直接应用在我们的矿井监控数据上，结果如下：

* 在某些清晰、近距离、姿态较标准的情形下，YOLO 的确能够检测到矿工；
* 但是模型往往**无法正确识别“这是一个人”**，而会将其误判为“瓶子”、“设备”甚至其他奇怪的类别；
* 更严重的是，当矿工在画面中**尺寸较小**时（例如远处乘坐猴车时），YOLO **直接漏检**。

这一点其实完全可以理解。因为 YOLO 的语义特征是基于自然图像训练的，而矿井场景中：

* 环境光照极差；
* 人体姿态固定且扭曲（悬挂式）；
* 视角单一且有透视压缩；
* 人的可见轮廓与背景设备形状高度耦合。

换句话说：

> **YOLO 并不知道“这里的人长这样”。**

---

那我们能不能对 YOLO 进行**微调（fine-tuning）**呢？

我们尝试标注了 **3000 张图像**，为每个矿工绘制了 **bounding box** 再去训练 YOLO。
微调后的模型相比预训练模型确实有明显提升，尤其是**可以更准确地区分“人”与设备**。

但是问题依然存在：

* 当目标 **较小、模糊、重影** 时，YOLO **仍然漏检**；
* 如果要进一步提升效果，必须 **继续增加标注量**；
* 而大规模标注 bounding box 的工作 **成本巨大、效率极低**。

因此我们得出一个非常明确的现实结论：

> **在这个应用场景中，靠监督学习做定位是不现实的。**
> 因为标注 bounding box 的成本太高，不可规模推广。

---

于是，我们提出了一个新的研究目标：

> **能否完全不标 bounding box，就实现自动定位？**
> → 即 **无监督定位（Unsupervised Localization）**

这在一般计算机视觉问题中其实几乎是不可能的，因为：

* 模型不知道你想找的是什么；
* 它无法理解“什么是 foreground / 什么是 background”。

但我们这里有一个 **非常关键的场景优势**：

> **摄像头是固定的，视角是固定的，背景永远不变。**

也就是说：

* 图像中 **每一个像素** 都有**稳定的物理含义**；
* 当画面中没有人时，该位置像素的值**高度稳定**；
* 当有人经过时，该像素会**异常变化**。

因此我们可以利用**像素时间序列统计特性**来直接推断出：

> 哪些区域是“稳定背景”，哪些区域是“变化前景”。
> → **而不需要任何人工标注。**

这一点，是整个工作中最关键的**工程与统计洞察**。

---

好的，理解。
从现在开始，我会**保留更多解释性语句、逻辑衔接和讲述口吻**，不再过度压缩内容，保证你在最终汇报时：

* **讲得顺**
* **内容有展开**
* **逻辑自然**
* **听众能够跟上**

下面进入 **第 3 部分**（从“为什么像素统计可以用来自动定位” → 引入双重平滑密度估计 DS）。

---

#### **【讲座内容 第 3 部分】**

之所以在这个场景中可以做**无监督定位**，核心原因在于：

> **摄像头位置固定 → 背景是静态的 → 每个像素点都有稳定含义。**

我们可以把图像看成一个二维函数，每个像素的位置是固定的，而它在不同时间点的取值（亮度或灰度）**构成一个时间序列**。

例如：
假设有一个像素位于隧道侧壁，那么在绝大多数时间里，这个像素的值就是**“墙的颜色”**；
只有当有人经过时，这个像素的值会突然**跳变**。

所以我们做了一个非常简单但非常有启发性的实验：

* 对每个像素位置，统计它在所有视频帧中的 **平均值**
* 将这些平均值重新绘制成一幅图

我们得到了一张 **“背景均值图”**。
在这张图中，非常神奇的事情出现了：

* **猴车消失了**
* **人也完全消失了**

只剩下**纯净的固定背景结构**。

原因非常简单：

* 大部分时间里，画面中 **没有人**；
* 同样，大部分时间里，猴车也并不处于同一位置；
* **平均操作自然抹去了所有“偶然出现的对象”**。

这就告诉我们：

> **我们可以以“背景均值图”作为背景参考模板，不需要任何标注。**

接下来，我们进一步考虑：

如果背景均值能作为参照，那我们就可以用：

[
\text{偏差} = \text{当前帧像素} - \text{背景均值}
]

来衡量**该像素此刻是否异常**。

那么：

* 偏差小 → 属于背景
* 偏差大 → 很可能属于前景（人、工具、违规物）

进一步，我们可以再对每个像素位置统计其 **标准差 σ**。
如果我们对偏差进行简单的“三倍标准差”异常检测（3σ-rule），就可以粗略地检测出前景区域。

并且，我们真的这么做了，效果相当不错：

* **矿工、人影、脚、手挥动、携带物体** 都被自然显现了出来。
* 而背景、墙体、轨道、灯光等固定设施仍然被良好地忽略。

这说明一点：

> **基于单像素统计的基本差异检测，在这个场景中是可行的并且具有非常强的可解释性。**

然而——它还不够好。

因为：

1. 简单的均值和方差只能描述数据的大致分布形状；
2. 但像素值的真实概率分布**往往不是对称的，也不是高斯的**；
3. 同一位置在不同时间的波动中，**噪声、反光、局部阴影**会影响判断；
4. 同一前景目标具有**空间连续性**，而单像素方法完全没有利用这一点。

换句话说：

> **我们需要的不只是“是否异常”，而是“异常发生的概率有多大”。**

这就引出了下一步——**密度估计**。

---

在统计学中，如果我们要判断某个数值是否异常，一个自然的办法是：

> **估计该位置像素值的概率密度函数（PDF）。**

形式化地说，对于每个像素位置 ( s )，我们有：

[
X_t(s) = \text{第 } t \text{ 帧中位置 } s \text{ 的像素值}
]

如果我们能够估计出它的密度函数 ( f(x, s) )，那么：

* 当 ( X_t(s) ) 处在密度很高的区域 → 说明它是“正常背景”
* 当 ( X_t(s) ) 落在密度很低的区域 → 我们就可以把它视为“可能前景 / 异常对象”

因此，**整个定位问题就转化为了一个纯粹的概率密度估计问题。**

如果能把密度估计做得好：

> **前景区域就会自动显现，不需要任何人工标注。**

---

然而，这里有两个挑战：

1. 我们要对 **每一个像素位置** 都估计一个概率密度函数。
   而一张图像往往有 **几十万甚至上百万个像素**。

2. 单独对每个像素做密度估计会非常不稳定，因为：

   * 数据有限（每个像素只有 T 次取值）
   * 噪声不均匀
   * 像素间存在明显的空间相关性，但经典密度估计不利用这一点

所以如果直接使用经典 KDE（Kernel Density Estimation，核密度估计）：

* **效果不够平滑**（噪点多）
* **方差很大**（容易误检）
* **对每个像素独立计算成本会非常高**

这就是我们提出新方法的动机。

---

于是我们提出：

### ✅ **双重平滑密度估计（Doubly Smoothed Density Estimation, DS）**

其核心思想是：

> **不仅在像素值域上做核平滑（第一次平滑），还在空间域对像素位置之间做第二次平滑。**

换句话说：

* **相邻像素的密度分布结构是相似的**，我们应该利用这一点；
* **再在空间上对密度估计本身做平滑**，就可以显著降低方差、提升鲁棒性。

而这一点，正好能解决我们之前提到的两个核心难点：

| 问题                    | DS 的解决思路            |
| --------------------- | ------------------- |
| 单像素 KDE 过于噪声 → 分布估计不稳 | **空间平滑**利用邻域信息，减少方差 |
| 每个像素独立估计 → 计算量过大      | **邻域共享结构**允许减少重复估计  |

到这一步，我们就基本找到了通往无监督定位的统计建模路径。

---

收到，我将继续，并**保持高细节、讲述感与可直接用于汇报的表达**。
本部分进入**方法核心：双重平滑（Doubly Smoothed）密度估计 DS**，会讲**直觉 → 数学表达 → 为什么它比经典 KDE 好**，不过仍然保持听众能理解的节奏。

---

#### **【讲座内容 第 4 部分】**

我们现在正式进入方法本身的构建。

我们希望能够估计每个像素位置 (s) 的像素值分布：

[
X_t(s), \quad t = 1,2,\dots,N
]

其中 (N) 是视频帧数（比如数十万帧）。
如果直接对单个像素序列做核密度估计（KDE），形式上是：

[
\hat{f}*{CD}(x, s) = \frac{1}{Nh} \sum*{t=1}^{N} K!\left( \frac{X_t(s) - x}{h} \right)
]

这就是经典 KDE（我们称之为 **CD**，classical density estimator）。
它对像素值域进行平滑——这对应我们前面说的**“第一次平滑”**。

---

##### **但是，单像素 KDE 有两个核心问题：**

1. **方差大**：因为它只使用了该像素点自身的时间序列样本；
2. **无法利用空间结构**：而在图像中，**相邻像素的真实分布往往高度相似**。

比如，一面墙的所有相邻像素分布几乎一样，而人的轮廓区域变化却一致且联动。但经典 KDE 把每个像素当成一个孤立点来看，完全没有利用这些宝贵的信息。

因此，我们提出：

> **不仅要在像素值维度做平滑，还要在空间维度（位置 (s)）做平滑。**

也就是说，对每个像素位置 (s)，我们不仅使用它自己的密度估计，还使用它**邻域内像素位置的密度估计**进行再平滑：

[
\hat{f}*{DS}(x, s) = \sum*{m=1}^{M} \hat{f}_{CD}(x, s_m), \omega_m(s)
]

其中：

* ( { s_m : m=1,\dots,M } ) 是位置 (s) 周围的一个邻域网格；
* ( \omega_m(s) ) 是空间平滑权重（例如二维空间上的高斯核）；
* ( \hat{f}_{CD}(x, s_m) ) 是这些邻域像素的原始 KDE 结果。

这一步就是**“第二次平滑”**，即在的位置维度上进行估计融合。

---

#### **为什么这一步很关键？**

因为图像是空间结构化数据，空间邻域天然具有高度的**相似性与连续性**：

* 墙的分布 → 连续稳定
* 静止设备 → 连续稳定
* 人、手、脚、工具等前景 → 连续异常

也就是说：

> **前景的“变化”不是单像素的，而是成片出现的。**

而双重平滑恰好捕捉并强化了这一点。

---

#### **那么它带来了什么数学收益？**

对于经典 KDE，我们知道其方差大致是：

[
\operatorname{Var}\big(\hat{f}_{CD}(x, s)\big) \asymp \frac{1}{Nh}
]

而对于双重平滑 DS：

[
\operatorname{Var}\big(\hat{f}_{DS}(x, s)\big) \asymp \frac{1}{NMh}
]

这里的 (M) 是空间邻域大小。

所以——**方差下降了 ( \mathbf{M} ) 倍。**

如果邻域规模取例如 25、49、81 —— 那就是几十倍的稳健性提升。

用一句白话解释：

> **双重平滑把“每个像素的孤立估计”变成了“邻域像素的集体投票”。**
> 当大量像素同时支持同一种分布形状，它就更可信、更稳定。

而这一步恰恰是我们想要的：

* **背景** → 分布稳定 → 密度估计稳定
* **前景** → 分布跳变 → 密度骤降（概率很低）→ 很容易被检测为异常

---

#### **到目前为止，我们解决了“准确性”的问题。**

但新的麻烦来了：

> **双重平滑非常耗时！**

想象一下：

* 图像 ~ 100 万像素
* 每个像素要做一次 KDE（几十万样本）
* 对每个像素再做一次空间平滑（邻域 M 次融合）

这显然**无法满足实时监控**。

也就是说：

* **DS 在准确性上远优于传统 KDE**
* 但 **计算成本极高 → 无法直接用于监控系统**

这里我们遇到了一个典型的现实困境：

> **方法好，但是算不动。**

于是我们问：

> 能不能保留双重平滑的统计优越性，但让它“算得起”？
> ——也就是 **在不损失密度估计质量的前提下，大幅降低计算量**？

这就是下一部分引出的关键点：

### ✅ **网格点近似（Grid Point Approximation, GPA）**

它是让 DS **从理论方法 → 变成真正可部署系统**的关键一步。

---

好的，进入**第 5 部分：网格点近似（Grid Point Approximation, GPA）**。
我会保持讲解丰满、有逻辑、有口语节奏，能够直接放进汇报稿里朗读。

---

#### **【讲座内容 第 5 部分】**

我们刚才讲到，双重平滑（DS）在统计上是非常漂亮的：
它利用了像素值方向和空间方向的双重信息，显著降低了方差，让前景目标在密度图上自然“凸显”出来。

但是问题是：

> **DS 算得太慢了，慢到根本无法用于实时监控。**

原因很直接：

* 图像中有 **几十万甚至上百万像素**
* 对每个像素都要进行 **核密度估计**
* 并且要再做空间邻域融合（也就是第二次平滑）

换句话说，如果 DS 原样运行，它就是：

[
\text{高质量，低速度 → 理论上完美，工程上不可用}
]

---

所以我们的目标是：

> **在几乎不损失估计质量的前提下，让计算速度提高几十倍乃至上百倍。**

我们怎么做到的呢？

---

### ✅ 核心思路：**把“连续求值”变成“有限查表”**

密度估计本质上是求：

[
f(x, s) = \text{位置 } s \text{ 的像素值 } x \text{ 的概率密度}
]

那么问题来了：

* ( x ) 是连续的
* 为了得到精确密度，我们必须对任意可能出现的 ( x ) 做计算
* 而这一点导致计算量巨大

但是，请注意：

> **图像像素值其实不是连续无限的，它有界并且变化范围有限。**

以灰度图为例：

* 像素值的取值范围是 ( [0,1] )（或 0 到 255）
* 我们并不需要在这个范围内 **对每个可能值重新做密度估计**
* 我们完全可以只在这个区间上选取 **有限数量的代表值（网格点）**

例如：

[
x \in {0, 0.01, 0.02, \dots, 1.00}
]

即选取 **100 个网格点**。

---

### ✅ GPA 方法做了什么？

1. **训练阶段（离线，慢没关系）：**

对每个像素位置 ( s )，只在 chosen grid points ( x_g ) 上计算 **双重平滑密度估计**：

[
\hat{f}_{DS}(x_g, s), \quad g = 1, \dots, G
]

然后把这些数 **存起来**。

这就形成了一个三维张量：

[
\text{Tensor size: } (H \times W \times G)
]

（高度 × 宽度 × 网格点数量）

这就是我们所谓的 **密度查找表（Density Look-up Table）**。

---

2. **实时监控阶段（在线，必须快）：**

对于当前帧中任意一个像素值 ( X(s) )，我们只需要：

* 找到它在网格点中的相邻区间
* 做一次简单的插值

就可以得到：

[
\hat{f}_{GPA}(X(s), s)
]

整个过程只需要：

* **几次数组访问**
* **一次或两次线性插值**

也就是说：

> **我们把原本 O(NM) 的密度计算，变成了 O(1) 的查表操作。**

---

### ✅ 为什么这样做不会损失精度？

关键点在于：

* 空间平滑已经让密度函数 **足够平滑**
* 平滑函数可以被 **低分辨率网格非常精确地逼近**
* 也就是说，我们不是在近似原始信号，而是在近似已经被平滑过的信号

因此我们可以证明：

[
\hat{f}*{GPA}(x, s) \approx \hat{f}*{DS}(x, s) \quad \text{且二者收敛速度相同}
]

也就是说：

> **只要网格点数量 (G) 选得合理（通常几十到一百），GPA 的估计质量几乎与 DS 完全一致。**

但它的速度——

* 从原来的 **每帧 1.5 秒**
* 提升到 **每帧 0.03 秒**

换句话说：

[
\boxed{\textbf{50 倍提速，几乎无精度损失}}
]

这使得：

> **双重平滑从“理论好但算不起”，变成“真正可用于工业级实时监控”。**

---

### ✅ 这一步的意义

如果说 **双重平滑（DS）** 解决的是：

> **如何找到前景，而无需任何标注**

那么 **网格点近似（GPA）** 解决的是：

> **如何把这个方法变成真实可部署的系统**

两者结合之后：

* 我们可以**无监督自动定位矿工**
* 不需要做 bounding box 标注
* 不依赖昂贵的深度目标检测训练
* 能达到与 YOLO fine-tune 类似甚至更好的效果

并且——这是关键：

> **方法具有可解释性、可复核性、可调节性**

而深度检测模型不具备这一点。

---
好的，我们进入 **第 6 部分：实验结果与对比**。
这一部分在实际汇报中往往是**信息密度最高、最能说服听众的部分**，所以我会：

* **分场景 → 分任务** 地讲
* **强调公平可比性**
* **用对照表、例子、现象来支撑论点**
* 保留**讲述风格**，确保你说出来**通顺、有逻辑、有说服力**

---

#### **【讲座内容 第 6 部分】**

我们现在来看真实实验结果。

我们在真实矿井环境中采集了大约两小时的监控视频，包含：

* 不同时间段
* 不同人员状态
* 不同车速、不同姿态
* 实际发生的**多种违规行为**

我们的方法分成两步：

1. **无监督定位（GPA-DS）**
2. **小模型分类（MobileNet 迁移学习）**

下面我们逐步看性能与可解释性。

---

### **(1) 定位效果可视化**

在定位阶段，我们使用 GPA-DS 得到每帧的**前景概率图**。
我们会看到一个非常自然的现象：

* **背景区域**的概率密度**高、稳定、成片一致**
* **人员/物体区域**的概率密度**突然下降、局部聚集、形状完整**

也就是说：

> **人是自己从背景中“浮现”出来的，不需要框。**

我们将结果叠加回原图，可以观察到：

* 矿工的**轮廓被清晰勾勒出**
* 即便在光线昏暗、分辨率低、远距离区域，也能显现
* **即使人很小（不足图像 1% 面积），也不会漏检**

这是 YOLO 在这个场景中很难做到的，因为：

* YOLO 的特征是语义级别
* 而我们的检测是 **统计差异级别**，对尺寸不敏感

---

### **(2) 为什么这点非常关键？**

因为在矿井中：

* 有些违规动作（比如**拖脚**）只体现在脚尖区域，信号非常微弱；
* YOLO 常常认为“脚不是一个目标”，从而**完全忽略它**；
* 而我们的定位基于像素级统计，因此会**自然捕捉到脚尖区域的像素变化**。

举个例子：

| 行为     | YOLO fine-tune | GPA-DS      |
| ------ | -------------- | ----------- |
| 正常乘坐   | 能检测出人，但框不准     | 能完整勾勒人形轮廓   |
| 手持超长物体 | 经常误识别为设备       | 物体形状清晰显现    |
| 脚触地拖行  | 几乎无法识别         | 脚部轮廓立刻被显著突出 |

因此我们可以说一句非常关键的话：

[
\boxed{\textbf{GPA-DS 对违规行为高度敏感，而 YOLO 对违规行为高度迟钝。}}
]

---

### **(3) 定量对比实验**

我们和以下方法进行了公平对比：

| 方法                 | 是否需要 bounding box 标注 | F1 Score  | IoU       | 平均耗时（秒/帧） |
| ------------------ | -------------------- | --------- | --------- | --------- |
| **GPA-DS（我们的方法）**  | **不需要**              | **0.955** | **0.770** | **0.033** |
| YOLOv8 Fine-tune   | 需要                   | 0.941     | 0.747     | 0.031     |
| YOLOv8 Pre-trained | 不适用（不能直接检测矿工）        | ×         | ×         | ×         |
| RPCA 系列            | 不需要                  | 0.64~0.77 | 0.53~0.60 | 0.20~1.0  |

非常值得强调的是：

* **我们的模型和 YOLOv8 Fine-tune 在定位精度上几乎同级**
* 但是：

  * YOLO 需要大量 bounding box 标注
  * **我们不需要任何 bounding box**

所以可以总结为：

> **我们用无监督方法做到了接近甚至超过有监督方法的效果。**

这是方法价值的关键落点。

---

### **(4) 再对动作进行分类**

定位之后，我们只需要裁剪出矿工区域，让一个轻量级模型（如 MobileNet）做**二分类（安全 / 非安全）**。
这部分成本很低，因为：

* 对图像做 “安全 / 不安全” 标签只需要经验判断
* **不需要框、不需要动作分解、不需要关键点**

分类精度达到了：

[
\boxed{99.4%}
]

换句话说：

> **定位做得好 → 分类会变得非常简单。**

这也是为什么我们始终强调 **定位是核心，分类是顺带解决**。

---

### **(5) 速度表现**

| 方法            | 实时部署可行性     | 平均处理速度      | 性能瓶颈       |
| ------------- | ----------- | ----------- | ---------- |
| GPA-DS（我们的方法） | **可直接部署**   | **≈30 FPS** | 无需 GPU     |
| YOLOv8        | 可部署，但需预训练模型 | ≈32 FPS     | 模型推理算力需求更高 |
| RPCA          | 几乎不可部署      | 0.5~5 FPS   | SVD 过慢     |

也就是说：

> **我们的方法可以直接部署在矿井调度中心的普通工作站上，不需要 GPU。**

这在工业应用中意义极大。

---

### **这一部分的总起一句话**

$$\boxed{\textbf{GPA-DS = 无监督 + 高精度 + 可解释 + 可部署 + 低成本}}$$

而这是深度方法在工业场景中经常做不到的。

---

如果你准备好了，我们就开始 **第 7 部分（总结与可视化结构化 PPT 大纲）**，这将直接对应你最终的 PPT 分页结构，让你可以**直接复制粘贴成 PPT**。

只需回复：

> **继续（进入 PPT 大纲）**
