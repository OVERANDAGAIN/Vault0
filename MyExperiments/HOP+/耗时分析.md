---
created: 2025-01-15T12
updated: ...
创建时间: 2025-六月-11日  星期三, 5:41:36 下午
---
[[HOP+]]


# Objectives
分析模型训练过程中耗时较长的原因

# 耗时分析

## Problem1: 分析HOP+总体时间

---

### 关键耗时统计

| Agent ID    | MCTS 累计耗时（秒）  | 最新一次 `compute_action()` 耗时（秒） | `compute_action()` 累计总耗时（秒）           |
| ----------- | ------------- | ----------------------------- | ------------------------------------- |
| Agent 1     | 397.9170      | 0.1188                        | 399.1039                              |
| Agent 2     | 370.8085      | 0.1198                        | 371.4923                              |
| Agent 3     | 506.2037      | 0.1526                        | 506.8729                              |
| Agent 4     | 399.3196      | 0.0370                        | 399.9435                              |
| **总计**      | **1674.2488** | –                             | **1676.4126**                         |
| **训练迭代总时间** | –             | –                             | **1679.5528** *(来自日志 `time_total_s`)* |
|             |               |                               |                                       |

#### 说明：

1. 四个 Agent 的 compute_action 累计总耗时为 1676.41 秒

2. 与训练迭代总时间 1679.55 秒（即一次迭代全部时间）高度吻合

3. 说明：系统总时间几乎全部消耗在 action 计算过程，其中 MCTS 占比最大，且各 Agent 时间分布较均匀


---


### 详细耗时说明（以一个为例）
Agent 1 的耗时：
```
 pid=9964) [Timer] MCTS Total: 397.9170s | select: 272.7855s | expand: 121.8405s | backup: 3.2377s | final: 0.0532s 
 pid=9964) 1[Timer] Total: 0.1188s | T1: 0.0000s | T2: 0.0010s | T3: 0.1178s | Sum: 0.1188s 
 pid=9964) 1[Timer] Total Total: 399.1039s | self.timer_t1_total: 0.0110s | self.timer_t2_total: 0.9672s | self.timer_t3_total: 398.1257s 
```

| 阶段代号     | 全称                 | 功能描述                                  |
| -------- | ------------------ | ------------------------------------- |
| **T1**   | `prepare`          | 预处理阶段：提取观测、构造初始状态（如 obs 预处理、RNN 状态管理） |
| **T2**   | `subgoal planning` | 子目标预测阶段：调用子目标生成网络（如 CVAE）产生下一步的goal   |
| **T3**   | `MCTS 调用阶段`        | 执行 MCTS 搜索过程，通常为最耗时阶段，调度整个搜索逻辑        |
| `select` | 搜索树节点选择            | 遍历现有树结构找到最优节点（基于 UCB 等策略）             |
| `expand` | 节点扩展阶段             | 在选定节点后新增节点，用于扩展搜索空间                   |
| `backup` | 回传更新阶段             | 将模拟结果回传并更新树中路径的节点信息（值/访问次数等）          |
| `final`  | 最终动作决策             | 从 MCTS 搜索结果中选出最终动作（多数投票或最大值策略）        |

---

### 综合分析

| 分析维度                     | 说明                                                                                       |
| ------------------------ | ---------------------------------------------------------------------------------------- |
| **MCTS 占比极高**            | 各 agent 中，`T3` 几乎占据 `compute_action` 总耗时的 99% 以上。比如 Agent 3 中，T3 为 506.48s，占比 ≈ 99.9%。   |
| **prepare、subgoal 占比极低** | 多数在 0.01–0.3s 之间，可忽略，说明状态预处理与子目标预测效率较高，不构成性能瓶颈。                                          |
| **MCTS 内部阶段中**           | `select` 与 `expand` 为主耗时部分（一般合计占比约 95%），表明优化搜索结构或减少节点扩展可能带来显著提速；`backup` 与 `final` 相对轻量。 |





## Problem2: 比较HOP+与Direct-OM
- [?] 


### Direct-OM一个iteration耗时如下

| Agent ID    | MCTS 累计耗时（秒） | 最新一次 `compute_action()` 耗时（秒） | `compute_action()` 累计总耗时（秒）          |
| ----------- | ------------ | ----------------------------- | ------------------------------------ |
| Agent 1     | 196.7622     | 0.0600                        | 197.0559                             |
| Agent 2     | 163.5176     | 0.0790                        | 163.7434                             |
| Agent 3     | 68.3561      | 0.0180                        | 68.4770                              |
| Agent 4     | 237.7415     | 0.0090                        | 238.0720                             |
| **总计**      | **666.3774** | –                             | **667.3483**                         |
| **训练迭代总时间** | –            | –                             | **671.5017** *(来自日志 `time_total_s`)* |


好的，以下是**DOM 与 HOP+ 在 MCTS 总耗时与分阶段耗时**方面的**统一对比表格**与综合分析：

---

###  DOM vs HOP+：耗时对比（单位：秒）

| 阶段                      | HOP+ 总耗时 | DOM 总耗时 | 缩减时间        | 缩减比例        | 说明                         |
| ----------------------- | -------- | ------- | ----------- | ----------- | -------------------------- |
| **compute\_action 总耗时** | 1676.41  | 667.35  | **1009.06** | **↓ 60.2%** | 主要由 MCTS 阶段优化贡献            |
| **MCTS 总耗时**            | 1674.25  | 666.38  | 1007.87     | ↓ 60.2%     | 占比几乎为 compute\_action 全部时间 |
| -                       | -        | -       | -           | -           | -                          |
| **- select**            | 1097.19  | 202.26  | **894.93**  | **↓ 81.6%** | 遍历搜索树阶段，相差较大的阶段            |
| - expand                | 551.79   | 449.94  | 101.85      | ——          | 节点展开                       |
| - backup                | 15.86    | 13.60   | 2.26        | ——          | 相对轻量                       |
| - final                 | 9.42     | 0.19    | 9.23        | ——          | 最终动作选择阶段                   |


---

###  综合分析

| 结论点                       | 内容说明                                            |
| ------------------------- | ----------------------------------------------- |
| **总体差距显著**                | DOM 将单次迭代总耗时从 **1676s 降至 667s**，整体缩短 **超过60%**。 |
| **MCTS 是主要瓶颈**            | 两个算法中 MCTS 占据 compute\_action 几乎全部耗时。           |
|  **差距集中在MCTS的 select 阶段** | `select` 阶段耗时减少了近 **900s**                      |

---


# 合并MOA与VAE
模型重用代码已完成，仍在训练中，以对比效果

# HOP+与DOM的总体Reward比较

![[reward_comparison_iteration_toplabels_fixed13.png]]

![[reward_comparison_time_toplabels.png]]

# Buffer收集情况
以Agent4的MOA为例：一个iteration每个buffer约收集20条数据，预计10个iteration可以填满Buffer,训练一次MOA模型。
```bash
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 17/200
 pid=9964) Buffer size for model 3: 17/200
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 18/200
 pid=9964) Buffer size for model 3: 17/200
 pid=9964) [Learn step 0] Attempting MOA update...
 pid=9964) Buffer size for model 1: 18/200
 pid=9964) Buffer size for model 2: 18/200
 pid=9964) Buffer size for model 3: 18/200
```

# 分析MCTS的select阶段

```python
def select(self):
    current_node = self
    while current_node.is_expanded:
        best_action = current_node.best_action()
        current_node = current_node.get_child(best_action)
    return current_node

```
### 调用：

* 每次调用 `select`，都需要不断调用：

  * `best_action()` → `child_Q()` + `child_U()` → 多次数组操作
  * `get_child()` → 访问 `children` 字典

### 相较于DOM，HOP+在`get_child()`阶段需要计算一次孩子节点的`subgoal`的值，是两者的主要差别
```python
 def get_child(self, action):
    target_prey_next = self.model_goal.cal_subgoal(obs['actions'], torch.from_numpy(self.state['state']).unsqueeze(0),
```

# Future Work
1. 在 MOA的预加载数据跑完之后后，整理相关实验数据，绘制对比图。
2. 在已有时间分析基础上，主要是分析交互步骤的耗时；在MOA的buffer存储满之后，训练阶段的耗时可以进一步比较（目前看来MCTS阶段的耗时差距是主要）。
3.  设计控制变量实验，对比是否在 `select` 阶段重复计算 `subgoal`，量化其对整体搜索耗时的影响，明确重计算带来的时间开销与收益。
4. 为减少重复计算，可探索在 MCTS 过程中将 `subgoal` 在短期（如固定 Horizon 步长）或一次完整模拟中保持不变，以此在效率与决策精度之间寻求平衡。

# FootNotes