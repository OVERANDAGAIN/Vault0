---
created: 2024-12-20T16
updated: ...
创建时间: 2025-二月-20日  星期四, 2:30:24 下午
---
[[HOP+]]

# Objectives
- 理解OMG中关于subgoal的实现机制
- 了解subgoal如何运用在pymarl框架里面的 $\Longrightarrow$ 抽离出来
- HOP中用到goal的地方
- 如何把subgoal结合到HOP

![[Pasted image 20250121145807.png|1050]]

![[Pasted image 20250121145733.png|1100]]


# Results
# Insights
# Setup
# Methodology
# Issues & Debugging

## Problem1 关于预训练相关问题
- [?] 
- [x] 
1. 先训练opponent:  
 ```bash
python main.py --config=iql  --env-config=sc2 with env_args.map_name=8m
```
   
2. 再加载 `agent.th` 进行预训练 
```bash
   python main.py --config=iql  --env-config=sc2 with env_args.map_name=8m --mac=basic_mac --am_model=omg_am --learner=am_learner --obs_is_state=True --init_param_path=SMAC/sacred/models/qmix__2025-02-11_13-42-21/33
   ```
   or 创建 op_model 文件夹统一管理（下再创建 8m 地图名） ==obs_is_state的值前后应该一致，都为true or false==
```bash
python main.py --config=iql  --env-config=sc2 with env_args.map_name=8m --mac=basic_mac --am_model=omg_am --learner=am_learner --obs_is_state=True --init_param_path=SMAC/sacred/op_model
```
3.   训练CVAE: `vae.th` 存放在 `iql_omg` 中
```bash
 python main.py --config=7iql1iql_omg --multi_algs --env-config=sc2 with env_args.map_name=8m --mac=multi_module_mac --train_alg=iql_omg --learner=omg_learner --is_agent_shift=True --init_param_path=SMAC/sacred/op_model --subgoal_mode=True
```


| 所属类别        |                  | save_models()                                                                   | 备注                                                           |
| ----------- | ---------------- | ------------------------------------------------------------------------------- | ------------------------------------------------------------ |
| **learner** | am_learner       | am_model.save_models()                                                          | args.am_model                                                |
|             | omg_learner      | mac.save_models()<br>mac.agents_model[main_alg_idx].omg_save_models()<br>opt.th | 使用的是om_controller <br>$\Longrightarrow$ 因为使用了 `main_alg_idx` |
|             | q_learner        | mac.save_models()<br>mixer.th<br>opt.th                                         |                                                              |
|             | q_learner_4am    | mac.save_models()<br>mixer.th<br>opt.th                                         |                                                              |
|             |                  |                                                                                 |                                                              |
| **mac**     | basic_controller | agent.th                                                                        |                                                              |
|             | om_controller    | agent.th<br>am.save_model()/agents_model.save_models()                          |                                                              |
|             |                  |                                                                                 |                                                              |
| **am**      | base_am          | base_am.th                                                                      |                                                              |
|             | none_am          | pass                                                                            |                                                              |
|             | omg_am           | vae.th                                                                          |                                                              |
|             | omg_am           | cvae.th<br>cond_rnn.th<br>fc.th                                                 | omg_save_models()方法                                          |


### 1_Answers `loss_func` 调用逻辑
[[how_OMG_codes]]
#### 关于am_model的注册
1. `args.am_model` 只会在 `am_leaner` 中使用
2. `alg_args.am_model` 在 `om_controller` 中使用

`loss_func` 
3. 只 `base_am` 和 `omg_am` 中被定义
4. 只在 `am_learner` 中被调用
5.  `omg_learner` 中使用的是 `omg_loss_func` 


- `omg_am` 中的 `loss_func` 才是关于 `VAE` 的逻辑
- `base_am` 中则不是


>关于预训练：
>设置 `am_model` 为 `omg_am` 。以使用它的 `loss_func` 
>使用 `am_leaner` 以调用 `loss_func`

#### 关于learner的注册
使用 `args.leaner` 去选择


### 2_Answers 关于 `om_controller` 中的几个 `forward` 函数

```ad-tip
- `forward` 在 `controller, am, agent` 中都被定义
- `main_alg_forward` 在 `omg_controller` 被定义，在 `omg_learner` 中被调用
```


##### **1. 两个 `forward` 的调用场景不同**：
- **`forward()`**：
  - 在环境交互阶段（如 `select_actions()`）调用。
  - 遍历所有 `agents`，返回 `agent_shift` 后的输出。
  - 用于选择动作，不更新参数。

- **`main_alg_forward()`**：
  - 在训练阶段（如 `train()`）调用。
  - 只计算主算法对应的 agent 输出，用于损失计算和优化。
  - **只有主算法的参数会被更新**。

##### **2. 更新时只针对主算法**：
- 训练时，调用 `main_alg_forward()`，只更新 `train_alg` 对应的主算法参数。
- 其他算法的参数不会被更新，但在动作选择阶段依然会被调用，确保多算法环境下正常运行。

##### **3. 进一步验证**：
- 优化器只包含主算法的参数，训练时仅优化 `main_alg_idx` 对应的模型。


##### 代码上的一个区别：==`forward()` 支持处理 `agent_shift`操作== 
````ad-tip

---

### **1. 返回结果的本质一致性**

- **Basic Controller**：
  ```python
  return agent_outs.view(ep_batch.batch_size, self.n_agents, -1)
  ```
  - 直接使用单一策略模型的输出。

- **OM Controller**：
  ```python
  agent_outs = th.cat(agent_outs, dim=-2).view(ep_batch.batch_size, -1, self.args.n_actions)
  agent_outs = agent_outs[:, self.agent_alg_idx, :]
  return agent_outs.view(ep_batch.batch_size, self.n_agents, -1)
  ```
  - 遍历所有策略模型后，根据 `agent_alg_idx` 重新排列 `agent_outs`

````

### 3_Answer 关于 `load_model()` 
6. 在 `learners` 中被调用: `mac.load_model()`
7. 在 `am` 中被定义：`load_state_dict` 
	1. `vae(omg_am)`
	2. `base_am`
8. 在 `controller` 中定义（即1中的调用）：
	1. `agent - agent.th`
	2. `am load...()`


  "checkpoint_path": "",
  "eval_model_path": "",
  "evaluate_path": "",
  "init_param_path": "",



### 4_Answer 关于 `obs_is_state`
### **关于 `obs_is_state` 的完整总结**

#### **1. `om_controller` 类中的 `obs_is_state` 相关处理**

##### **1.1 `_build_inputs` 方法**

- **代码片段：**
```python
if self.args.obs_is_state:
    state = batch["state"]
    if len(state.shape) == 3:  # 没有 n_agents 维度
        state = state.unsqueeze(2).repeat(1, 1, self.n_agents, 1)  # 扩展 n_agents 维度
    elif len(state.shape) != 4:
        raise IndexError

obs_inputs = []
if self.args.obs_is_state:
    obs_inputs.append(state[:, t])  # 取当前时间步的状态
else:
    obs_inputs.append(batch["obs"][:, t])
```

- **维度情况：**
  - `obs_is_state=True`：
    - `batch["state"]` 原始维度：`[batch_size, seq_len, state_dim]`
    - 若 `state` 没有 n_agents 维度，扩展为：`[batch_size, seq_len, n_agents, state_dim]`
    - 最终在时间步 `t` 时为：`[batch_size, n_agents, state_dim]`
  
  - `obs_is_state=False`：
    - `batch["obs"]` 原始维度：`[batch_size, seq_len, n_agents, obs_dim]`
    - 在时间步 `t` 时为：`[batch_size, n_agents, obs_dim]`

---

#### **2. `omg_am` 类中的 `obs_is_state` 相关处理**

##### **2.1 `_build_inputs` 方法**

- **代码片段：**
```python
if self.args.obs_is_state:
    state = batch["state"]
    if len(state.shape) == 3:  # 没有 n_agents 维度
        state = state.unsqueeze(2).repeat(1, 1, self.n_agents, 1)

if self.args.obs_is_state:
    fc_inputs.append(state[:, ts])
else:
    fc_inputs.append(batch["obs"][:, ts])
```

- **维度情况：**
  - `obs_is_state=True`：
    - `batch["state"]` 原始维度：`[batch_size, seq_len, state_dim]`
    - 若 `state` 没有 n_agents 维度，扩展为：`[batch_size, seq_len, n_agents, state_dim]`
    - 在时间步 `t` 取值后为：`[batch_size, n_agents, state_dim]`
  
  - `obs_is_state=False`：
    - `batch["obs"]` 原始维度：`[batch_size, seq_len, n_agents, obs_dim]`
    - 在时间步 `t` 取值后为：`[batch_size, n_agents, obs_dim]`

---

##### **2.2 `_build_vae_inputs` 方法** 有维度差异

- **代码片段：**
```python
if self.args.obs_is_state:
    obs = batch["state"][:, :-1]
else:
    obs = batch["obs"][:, :-1]

reshaped_obs = obs.reshape(-1, obs.shape[-1])
reshaped_mask = mask.unsqueeze(2).repeat(1, 1, self.n_agents, 1).reshape(-1, 1)
```

- **维度情况：**
  - `obs_is_state=True`：
    - `batch["state"]` 原始维度：`[batch_size, seq_len, state_dim]`
    - 取除最后时间步后的序列为：`[batch_size, seq_len - 1, state_dim]`
    - reshape 后为：`[batch_size * (seq_len - 1), state_dim]`
  
  - `obs_is_state=False`：
    - `batch["obs"]` 原始维度：`[batch_size, seq_len, n_agents, obs_dim]`
    - 取除最后时间步后的序列为：`[batch_size, seq_len - 1, n_agents, obs_dim]`
    - reshape 后为：`[batch_size * (seq_len - 1) * n_agents, obs_dim]`

---

##### **2.3 `_build_obs` 方法**

- **代码片段：**
```python
if self.args.obs_is_state:
    state = batch["state"]
    if len(state.shape) == 3:
        state = state.unsqueeze(2).repeat(1, 1, self.n_agents, 1)
    inputs.append(state)
else:
    inputs.append(batch["obs"])
```

- **维度情况：**
  - `obs_is_state=True`：
    - `batch["state"]` 原始维度：`[batch_size, seq_len, state_dim]`
    - 若没有 n_agents 维度，扩展为：`[batch_size, seq_len, n_agents, state_dim]`
  
  - `obs_is_state=False`：
    - `batch["obs"]` 原始维度：`[batch_size, seq_len, n_agents, obs_dim]`

---

##### **2.4 `_cal_subgoal` 方法** 有维度差异

- **代码片段：**
```python
if self.args.obs_is_state:
    obs_for_vae = batch["state"][:, 1:]
else:
    obs_for_vae = batch["obs"][:, 1:]
obs_for_vae = obs_for_vae.reshape(-1, obs_for_vae.shape[-1])
```

- **维度情况：**
  - `obs_is_state=True`：
    - `batch["state"]` 原始维度：`[batch_size, seq_len, state_dim]`
    - 取除第一个时间步后的序列为：`[batch_size, seq_len - 1, state_dim]`
    - reshape 后为：`[batch_size * (seq_len - 1), state_dim]`
  
  - `obs_is_state=False`：
    - `batch["obs"]` 原始维度：`[batch_size, seq_len, n_agents, obs_dim]`
    - 取除第一个时间步后的序列为：`[batch_size, seq_len - 1, n_agents, obs_dim]`
    - reshape 后为：`[batch_size * (seq_len - 1) * n_agents, obs_dim]`

---

### **总结**

- **涉及到的所有方法：**
  - **om_controller：**
    - `_build_inputs`
  - **omg_am：**
    - `_build_inputs`
    - `_build_vae_inputs`    !!!!!!!!!!!!!!!!!!
    - `_build_obs`
    - `_cal_subgoal`   !!!!!!!!!!!!!!!!!!!!!!!!

- **维度差异：**
  - 当 `obs_is_state=True` 时：
    - 数据形状为 `[batch_size, seq_len, state_dim]`，通常在输入中需要扩展 n_agents 维度，变为 `[batch_size, seq_len, n_agents, state_dim]`
    - 最终 reshape 结果为 `[batch_size * (seq_len - 1), state_dim]`

  - 当 `obs_is_state=False` 时：
    - 数据形状为 `[batch_size, seq_len, n_agents, obs_dim]`
    - 最终 reshape 结果为 `[batch_size * (seq_len - 1) * n_agents, obs_dim]`

---

### **潜在问题**

- `obs_is_state` 为 `True` 和 `False` 时的处理逻辑不一致，导致后续操作中可能出现维度不匹配。
- 统一扩展为 `[batch_size, seq_len, n_agents, dim]` 格式可以减少维度不一致问题。

````ad-tip
你提出的两个情况是关键点。我们逐步分析 **不扩展** 和 **扩展 `n_agents`** 时的影响，并比较它们对最终 VAE 模型的影响。以下从 **数据传递**、**损失计算**、以及 **模型训练和推理** 三个方面进行讨论。

---

### **1. 情况 1：不扩展 `n_agents`**

#### **数据传递**：
- **`obs` 形状**：`[batch_size, max_t, state_dim]`
- **`mask` 形状**：`[batch_size, max_t, 1]`

  在 `_build_vae_inputs()` 中：
  ```python
  reshaped_obs = obs.reshape(-1, obs.shape[-1])  # Shape: [batch_size * max_t, state_dim]
  reshaped_mask = mask.reshape(-1, 1)            # Shape: [batch_size * max_t, 1]
  ```

#### **损失计算**：
- **重建损失**：
  ```python
  recon_loss = F.mse_loss(inputs * mask, recons * mask)
  ```
  - 输入和重建输出都使用展平后的形状 `[batch_size * max_t, state_dim]`。
  - `mask` 形状与 `inputs` 一致，因此能正常计算损失。

- **潜在变量的 KLD 损失**：
  ```python
  kld_loss = th.mean(-0.5 * mask * th.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1, keepdim=True))
  ```
  - `mu`, `log_var` 也是展平后的形状 `[batch_size * max_t, latent_dim]`，与 `mask` 匹配。

---

### **2. 情况 2：扩展 `n_agents`**

#### **数据传递**：
- **`obs` 形状**：扩展为 `[batch_size, max_t, n_agents, state_dim]`
- **`mask` 形状**：扩展为 `[batch_size, max_t, n_agents, 1]`

  在 `_build_vae_inputs()` 中：
  ```python
  reshaped_obs = obs.reshape(-1, obs.shape[-1])  # Shape: [batch_size * max_t * n_agents, state_dim]
  reshaped_mask = mask.reshape(-1, 1)            # Shape: [batch_size * max_t * n_agents, 1]
  ```

#### **损失计算**：
- **重建损失**：
  ```python
  recon_loss = F.mse_loss(inputs * mask, recons * mask)
  ```
  - `inputs`, `recons` 形状为 `[batch_size * max_t * n_agents, state_dim]`。
  - `mask` 形状与输入匹配，损失计算正常。

- **潜在变量的 KLD 损失**：
  ```python
  kld_loss = th.mean(-0.5 * mask * th.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1, keepdim=True))
  ```
  - `mu`, `log_var` 形状为 `[batch_size * max_t * n_agents, latent_dim]`，损失计算正常。

---

### **3. 两种情况的对比**

#### **数据传递差异**：
- **情况 1**：数据不考虑 `n_agents` 维度，VAE 的输入和输出均为全局状态。
- **情况 2**：扩展了 `n_agents` 维度，VAE 对每个代理独立处理输入数据。

#### **损失计算差异**：
- **情况 1**：
  - `mask` 只在时间步级别进行遮掩，损失计算没有考虑代理间的差异。
  - VAE 学到的潜在表示是全局状态的抽象，不区分具体代理。

- **情况 2**：
  - `mask` 对每个代理的数据都进行遮掩，损失计算更精确。
  - VAE 学到的潜在表示能更好地刻画每个代理的个体特征。

#### **对预训练结果的影响**：
- **情况 1**：
  - VAE 模型更偏向于全局状态的表示，可能在推理阶段无法准确生成针对单个代理的 `subgoal`。
  - 在多代理环境中，使用这种模型可能会导致策略网络无法正确解析 `subgoal`。

- **情况 2**：
  - VAE 能捕捉每个代理的特征，生成的 `subgoal` 更具针对性。
  - 预训练模型在实际使用时更符合多智能体环境的需求。

---

### **4. 结论和建议**

- **建议扩展 `n_agents` 维度**：  
  - 这样可以在预训练阶段捕捉到多智能体环境中的个体特征，避免在推理时出现 `subgoal` 表示不准确的问题。
  
- **如果不扩展 `n_agents` 维度**：  
  - 在全观测状态下，VAE 学到的表示偏向全局，可能不利于策略网络的决策效果。
  - 如果使用全局表示，后续策略网络可能需要额外处理每个代理的特征，增加复杂度。
````

### 关于其他模块如何处理 `build_inputs`

我们可以从代码中总结不同类型的 AM 和 Controller 对于 `build_inputs`（或类似方法）在处理 observation（`obs`）时的不同方式。下面逐一分析它们的处理逻辑和维度变化。

---

### **1. Base_AM**
```python
def _build_inputs(self, batch, t=None):
    bs = batch.batch_size
    max_t = batch.max_seq_length if t is None else 1
    ts = slice(None) if t is None else slice(t, t+1)
    inputs = []

    # observation
    inputs.append(batch["obs"][:, ts])

    inputs = th.cat([x.reshape(bs, max_t, self.n_agents, -1) for x in inputs], dim=-1)
    return inputs
```
- **输入内容**：只处理 `obs`，没有处理其他辅助信息。
- **处理方式**：  
  - 直接从 `batch["obs"]` 获取观测数据，提取时间片段 `ts`。
  - 将观测数据 **按 `batch_size`, `max_t`, `n_agents`, `feature_dim`** 维度进行 reshape 并拼接。
- **维度**：`[batch_size, max_t, n_agents, feature_dim]`
  
---

### **2. None_AM**
```python
def _build_inputs(self, batch, t=None):
    bs = batch.batch_size
    max_t = batch.max_seq_length if t is None else 1
    
    return th.zeros((bs, max_t, self.n_agents, 0), device=batch['obs'].device)
```
- **输入内容**：没有实际输入，仅返回一个全 0 张量。
- **处理方式**：  
  - 直接生成 **零张量**。
  - 张量维度与 `batch_size`, `max_t`, `n_agents` 对应，但没有特征维度。
  
- **维度**：`[batch_size, max_t, n_agents, 0]`

---

### **3. Basic_Controller**
```python
def _build_inputs(self, batch, t):
    bs = batch.batch_size
    inputs = []

    # Add observation
    inputs.append(batch["obs"][:, t])  # b1av

    # Add last action (if applicable)
    if self.args.obs_last_action:
        if t == 0:
            inputs.append(th.zeros_like(batch["actions_onehot"][:, t]))
        else:
            inputs.append(batch["actions_onehot"][:, t-1])

    # Add agent ID (if applicable)
    if self.args.obs_agent_id:
        inputs.append(th.eye(self.n_agents, device=batch.device).unsqueeze(0).expand(bs, -1, -1))

    inputs = th.cat([x.reshape(bs * self.n_agents, -1) for x in inputs], dim=1)
    return inputs
```
- **输入内容**：处理观测数据、上一步的动作、agent ID 信息。
- **处理方式**：  
  - 先获取时间步 `t` 的 `obs`。
  - 如果启用 `obs_last_action`，还会添加上一时间步的动作 `actions_onehot`。
  - 如果启用 `obs_agent_id`，还会加入 `n_agents` 的 one-hot 编码。
  - 所有输入拼接后，reshape 成 **[batch_size * n_agents, feature_dim]**。

- **维度**：`[batch_size * n_agents, feature_dim]`

---

### **4. OM_Controller**
```python
def _build_inputs(self, batch, t):
    bs = batch.batch_size

    # 如果启用 obs_is_state，则使用 state，否则使用 obs
    if self.args.obs_is_state:
        state = batch["state"]
        if len(state.shape) == 3:
            state = state.unsqueeze(2).repeat(1, 1, self.n_agents, 1)

    obs_inputs = []
    if self.args.obs_is_state:
        obs_inputs.append(state[:, t])
    else:
        obs_inputs.append(batch["obs"][:, t])
        # 添加其他信息（如 last action 和 agent ID）
```
- **输入内容**：处理 `state` 或 `obs`，以及可选的 `actions_onehot` 和 `agent_id` 信息。
- **处理方式**：
  - 如果启用 `obs_is_state`，会使用全局状态 `state`，并扩展到 `n_agents` 维度。
  - 否则直接使用 `obs`。
  - 同时还会拼接 last action 和 agent ID。

- **维度**：  
  - 如果 `obs_is_state=True`：`[batch_size, n_agents, feature_dim]`
  - 否则：`[batch_size, n_agents, feature_dim]`

---

### **5. OMG_AM**
```python
def _build_inputs(self, batch, t):
    bs = batch.batch_size
    max_t = batch.max_seq_length if t is None else 1

    # 使用 state 或 obs
    if self.args.obs_is_state:
        state = batch["state"]
        if len(state.shape) == 3:
            state = state.unsqueeze(2).repeat(1, 1, self.n_agents, 1)

    fc_inputs = []
    if self.args.obs_is_state:
        fc_inputs.append(state[:, t])
    else:
        fc_inputs.append(batch["obs"][:, t])

    # 构建条件输入 cond_inputs
    cond_inputs = []
    if self.args.obs_is_state:
        last_obs = th.cat([th.zeros_like(state[:, 0:1]), state[:, :-1]], dim=1)
        cond_inputs.append(last_obs[:, t])
    else:
        last_obs = th.cat([th.zeros_like(batch["obs"][:, 0:1]), batch["obs"][:, :-1]], dim=1)
        cond_inputs.append(last_obs[:, t])

    # 其他条件输入：动作、agent ID 等
```
- **输入内容**：处理 `obs` 或 `state`，以及条件输入（如上一时间步的 `obs`、动作等）。
- **处理方式**：
  - 根据 `obs_is_state` 决定使用 `state` 或 `obs`。
  - 同时构建条件输入（如 `last_obs`、上一时间步的动作等），用于 CVAE 推断。
  
- **维度**：
  - `fc_inputs`：`[batch_size, n_agents, feature_dim]`
  - `cond_inputs`：`[batch_size, n_agents, condition_dim]`

---

### **总结：**

9. **是否使用 `obs_is_state`**：
   - 仅在 `OM_Controller` 和 `OMG_AM` 中引入，目的是在某些场景下使用全局状态 `state` 作为输入，而不是局部观测 `obs`。

10. **不同模块的处理方式**：
   - `base_am`、`basic_controller` 直接使用 `obs` 作为输入。
   - `none_am` 返回空输入，不处理任何特征。
   - `OM_Controller` 和 `OMG_AM` 根据 `obs_is_state` 动态选择输入来源（`state` 或 `obs`）。

11. **维度处理**：
   - `base_am`、`none_am` 维度保持 **[batch_size, max_t, n_agents, feature_dim]**。
   - `basic_controller` 将输入 reshape 为 **[batch_size * n_agents, feature_dim]**。
   - `OM_Controller` 和 `OMG_AM` 在某些情况下扩展 `n_agents` 维度，但在 VAE 阶段的 `_build_vae_inputs` 方法中没有扩展 `n_agents`。

## Problem2
- [?] 

### 1_Answers


### 2_Answers



# Limitations
# Future Work
# FootNotes