---
åˆ›å»ºæ—¶é—´: 2026-ä¸€æœˆ-28æ—¥  æ˜ŸæœŸä¸‰, 8:32:32 æ™šä¸Š
---
[[HOP+è¿ç§»è‡³cleanrl]]


# Objectives
è°ƒç ”overcookedç¯å¢ƒæ˜¯å¦å¯ä»¥ç”¨æ¥æµ‹è¯•adaptationèƒ½åŠ›ï¼Œå³æ ¹æ®å¯¹æ‰‹è¡Œä¸ºçš„ä¸åŒï¼Œè‡ªèº«çš„è¡Œä¸ºéœ€è¦è°ƒæ•´

>å“ªäº›è®ºæ–‡ä½¿ç”¨è¿™ä¸ªç¯å¢ƒ
>ä¸€äº›adaptationä»»åŠ¡çš„æ–¹æ³•ä½¿ç”¨çš„ç±»ä¼¼ç¯å¢ƒï¼Œ æˆ–è€…åœ¨åŸç‰ˆOvercookedç¯å¢ƒä¸Šçš„æ”¹å˜
>schellingå›¾ï¼Ÿ $\Longrightarrow$ ç»¼è¿°
>


# å…³äºç¯å¢ƒ
## PO-Overcookedï¼ˆPartially Observable Overcookedï¼‰
>Fast Peer Adaptation with Context-aware Exploration

è®ºæ–‡æ˜ç¡®æŒ‡å‡ºå…¶åˆä½œç¯å¢ƒæ˜¯ PO-Overcookedï¼Œåœ¨ Carroll et al. (2019) çš„ Overcooked åŸºç¡€ä¸Šï¼Œç»“åˆ Charakorn et al. (2023) çš„å¤šèœè°±ç‰ˆæœ¬ï¼Œå¹¶åšäº†é¢å¤–ã€å…³é”®æ€§çš„æ”¹åŠ¨ï¼Œ
1. éƒ¨åˆ†å¯è§‚æµ‹ï¼ˆPartial Observabilityï¼‰æ˜¯æ ¸å¿ƒæ”¹åŠ¨
2. å¤šèœè°± + å¤šåŸæ–™ï¼ˆå¤æ‚åå¥½ç©ºé—´ï¼‰
	1. åŸæ–™æ•°ï¼š6 ç§(Tomato, Onion, Carrot, Lettuce, Potato, Broccoli)
	2. èœè°±æ•°ï¼š9 ç§
3. adaptation å®šä¹‰ä¸ºï¼š$Neps$ ä¸ª episode ä¸Šçš„æ€»å›æŠ¥æœ€å¤§åŒ–
$$\max ;\mathbb{E}\Big[\sum_{n=1}^{N_{\text{eps}}}\sum_{t=1}^{T_n} r^1_{n,t}\Big]$$
åœ¨ä¸€ä¸ªå›ºå®šä½†æœªçŸ¥ recipe preference çš„åˆä½œä¼™ä¼´å­˜åœ¨ä¸‹ï¼Œé€šè¿‡è·¨ episode çš„äº¤äº’è¯†åˆ«è¯¥åå¥½ï¼Œå¹¶ä¸å…¶åä½œå®Œæˆå¯¹åº” recipeï¼Œä»¥æœ€å¤§åŒ–è·¨ episode çš„ç´¯è®¡å›æŠ¥ã€‚



## multi-recipe variant
>Generating Diverse Cooperative Agents by Learning Incompatible Policiesï¼ˆICLR 2023ï¼‰

è®ºæ–‡åœ¨ Overcooked ä¸Šä¸æ˜¯ç”¨åŸç‰ˆï¼Œè€Œæ˜¯å®ç°äº†ä¸€ä¸ª multi-recipe variantï¼Œç”¨äºæµ‹è¯•â€œæ˜¯å¦èƒ½ç”Ÿæˆè¡Œä¸ºå¤šæ ·çš„åˆä½œ agent populationâ€
1. åŸæ–™æ•°ï¼š4 ç§ ;èœè°±æ•°ï¼š6 ç§
2. è§‚æµ‹ï¼šé•¿åº¦ 54 çš„ 1-D å‘é‡ï¼ˆä½ç½®/æœå‘ã€ç›¸å¯¹è·ç¦»ã€æ‰‹é‡Œæ‹¿çš„ä¸œè¥¿åŠå…¶çŠ¶æ€ã€ç›¸é‚» counter çš„å¸ƒå°”é‡ã€é¢å‰ç‰©ä½“ç±»å‹ä¸çŠ¶æ€ç­‰ï¼‰


players have to complete and serve one of the six pre-defined recipes as fast as possible, as opposed to delivering a single menu item repeatedly.

æŒ‡æ ‡: success rate


# å…³äºå¯¹æ‰‹
## å¸¦å™ªå£°çš„ã€åŸºäºåå¥½çš„ rule-based agent
>Fast Peer Adaptation with Context-aware Exploration

æ¯ä¸€ä¸ªå¯¹æ‰‹ç­–ç•¥ =(å›ºå®šèœè°±åå¥½ + ç¡®å®šæ€§å­ä»»åŠ¡è§„åˆ’ + å¯æ§éšæœºæ‰°åŠ¨),
å¹¶éä½¿ç”¨self-playçš„ç­–ç•¥:
$$Ïˆ = (recipe_{pref}, P_{nav}, P_{act})$$

## å¤šæ · partner åˆ†å¸ƒ
>Generating Diverse Cooperative Agents by Learning Incompatible Policiesï¼ˆICLR 2023ï¼‰

è¿™ç¯‡ä¸åš online adaptationï¼›å®ƒåšçš„æ˜¯â€œä¸º adaptation æä¾›å¤šæ · partner åˆ†å¸ƒ



ä¸™å“¥ï¼ŒğŸ®ï¼


# Insights

# Future Work
# FootNotes