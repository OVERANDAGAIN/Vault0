---
创建时间: 2026-一月-4日  星期日, 12:33:12 下午
---
[[(2019-05-24) Learning Latent Dynamics for Planning from Pixels]]

# Questions
![[Pasted image 20260104135240.png]]
- [?] 
我先把前两个答清楚；你第 3 点还没写出来（只写了个 “3.”），你补一句我再接着答。

---

## 1) prior / posterior 这两个名字从哪来？为什么这么叫？

它们来自 **贝叶斯推断** 的命名习惯：

* **Prior（先验）**：在“看到当前观测之前”，你对隐变量（latent state）$s_{t}$ 的信念分布。
* **Posterior（后验）**：在“看到当前观测之后”，你更新过的信念分布。

放到 PlaNet / RSSM 这种序列模型里，最典型的对应是：

* **prior（由动力学给出）**
  只用过去的状态和动作往前推：
  $$p(s_{t}\mid h_{t}) \quad \text{或} \quad p(s_{t}\mid s_{t-1}, a_{t-1})$$
  直觉：**不看 $o_{t}$，光靠“世界怎么演化”来猜 $s_{t}$。**

* **posterior（由推断/编码器给出）**
  看到当前观测后修正：
  $$q(s_{t}\mid h_{t}, o_{t}) \quad \text{（用 $q$ 表示变分近似后验）}$$
  直觉：**把真实 $o_{t}$ 当证据，把 $s_{t}$ 往更符合当前画面的方向“拉回去”。**

> 注意：这里常用 $q(\cdot)$ 表示“我们用神经网络做的后验近似”，因为真实的 $p(s_{t}\mid o_{\le t})$ 往往算不出来。

---

## 2) 开环 / 闭环是什么意思？（在这类 world model / planning 语境下）

一句话区分：

* **开环（open-loop）**：不利用中途新观测做反馈修正，一路“盲推/盲执行”。
* **闭环（closed-loop）**：每一步都用新观测（或新估计的状态）做反馈修正，边走边纠偏。

在 PlaNet 的图里，你可以用 $s_{i|j}$ 来直观看：

* $s_{3|1}$：只看到了 $o_{1}$，然后用动力学从 1 推到 3
  → **典型开环多步预测**（rolling out prior，不再用 $o_{2},o_{3}$ 纠错）

* $s_{3|3}$：看到了 $o_{1},o_{2},o_{3}$ 后对时刻 3 的估计
  → **闭环/有反馈的状态估计**（每步都用观测更新 posterior）

在控制/规划里也一样：

* **开环规划**：先算好一串动作 $a_{t:t+H-1}$，中途不重算；
* **闭环（MPC/滚动时域）**：每执行一步就用新观测更新 belief，再重新规划下一段动作序列。

---

把第 3 个问题补完整（比如“3. overshooting 到底在惩罚什么/为什么有效？”之类），我就按你想问的方向接着讲。


# Answers

## GPT_Answers


## DS_Answers


## Other_Answers


# Codes

```python

```


# FootNotes
