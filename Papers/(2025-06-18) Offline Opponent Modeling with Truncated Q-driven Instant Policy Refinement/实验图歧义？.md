---
创建时间: 2025-十一月-13日  星期四, 5:40:05 下午
---
[[(2025-06-18) Offline Opponent Modeling with Truncated Q-driven Instant Policy Refinement]]

# Questions

- [?] 我的意思是如果是自下而上，那么灰色的部分表示的自下而上的，当然是reward 向上提高。但是对于MS和PP这样的环境，表述不就反过来了吗？reward向下生成不就是奖励降低了吗，所以我对这里绘图的可读性表示怀疑。这里的问题应该是这样的，但是对于文中是否有这样的表述，我就不知道



![[Pasted image 20251113174040.png]]
# Answers:原图没有表现错，只是理解错了，斜线部分可以认为是改进大小


>We use ‘black error bars’ to represent the Standard Deviation (SD) of the original OOM policy’s performance and ‘grey error bars’ to represent the SD of the performance after applying TIPR.

所以黑色的bar表示原来的，棕色的表示应用了方法之后的

每个环境都是下面的是原方法，上面的是改进后的。所以都是改进








# Codes

```python

```


# FootNotes
