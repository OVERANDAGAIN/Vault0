#paper_summary 

# Inspiration



# Innovation
1. introduce <font color="#ff0000">Advantage Alignment</font> and PPA (Promixal Advantage Alignment)——two opponent shaping algorthms——based on policy gradient estimators
2. prove LOLA and LOQA perform<font color="#ff0000"> Advantage Alignment</font> 
3. extend REINFORCE-based opponent shaping to <font color="#ff0000">continuous action environments</font>——sota results
4. apply in social dilemma——sota results


# Background
1. Pareto-suboptimal Nash equilibra——Opponent Shaping
2. LOLA: an opponent shaping algorithm that influences the behavior of other agents —— by assuming they are naive learners —— taking gradients with respect to simulated parameter updates
3. Pareto-optimal strategy in the Coin Game d


# Problem



# Methodology
1. align the advantages of interacting agents, increasing the probability of mutually beneficial actions when their interaction has been positive.


# Evaluation
IPD/Coin Game/a continuous action variant of the Negotiation Game/Melting Pot's Commons Harvest Open


# Limitations



# Applications