---
created: 2024-12-18T20
updated: ...
åˆ›å»ºæ—¶é—´: 2025-ä¸‰æœˆ-3æ—¥  æ˜ŸæœŸä¸€, 9:49:33 ä¸Šåˆ
---
[[HOP_Overall]]



# Codes/Questions

- [?] 


```python
          self.r2_enable=config['ranked_reward']['enable']
            self.r2_buffer=None
            if self.r2_enable:
                self.r2_buffer=RankedRewardsBuffer(config['ranked_reward']["buffer_max_length"],config['ranked_reward']["percentile"])

```


# Answers

## Overall_Answers
è¿™é‡Œçš„ `r2` æŒ‡çš„æ˜¯ **Ranked Rewardï¼ˆæ’åå¥–åŠ±ï¼‰**ï¼Œç”¨äºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰ä¸­çš„**å¥–åŠ±å½’ä¸€åŒ–**æˆ–**å¥–åŠ±è°ƒæ•´**æœºåˆ¶ã€‚å…·ä½“è§£é‡Šå¦‚ä¸‹ï¼š

---

### **ä»£ç è§£æ**
```python
self.r2_enable = config['ranked_reward']['enable']
```
- ä» `config` é…ç½®æ–‡ä»¶ä¸­è·å– `ranked_reward` çš„ **enable** é€‰é¡¹ã€‚
- å¦‚æœè¯¥é€‰é¡¹ä¸º `True`ï¼Œè¡¨ç¤ºå¯ç”¨ **Ranked Reward** æœºåˆ¶ã€‚

```python
self.r2_buffer = None
if self.r2_enable:
    self.r2_buffer = RankedRewardsBuffer(
        config['ranked_reward']["buffer_max_length"],
        config['ranked_reward']["percentile"]
    )
```
- å¦‚æœ `r2_enable` ä¸º `True`ï¼š
  - åˆå§‹åŒ– `self.r2_buffer`ï¼Œä½¿ç”¨ `RankedRewardsBuffer` ç±»ã€‚
  - `buffer_max_length`ï¼šè¡¨ç¤º `RankedRewardsBuffer` ç»´æŠ¤çš„å¥–åŠ±å†å²é•¿åº¦ã€‚
  - `percentile`ï¼šç”¨äºè®¡ç®—å¥–åŠ±çš„**åˆ†ä½æ•°æ ‡å‡†åŒ–**ã€‚

---

### **Ranked Rewardï¼ˆæ’åå¥–åŠ±ï¼‰æ˜¯ä»€ä¹ˆï¼Ÿ**
Ranked Reward æ˜¯ä¸€ç§ **åŸºäºå¥–åŠ±çš„åŠ¨æ€å½’ä¸€åŒ–æœºåˆ¶**ï¼Œç”¨äºï¼š
1. **å‡å°‘å¥–åŠ±çš„å‰§çƒˆæ³¢åŠ¨**ï¼ˆé¿å…å¥–åŠ±å€¼èŒƒå›´è¿‡å¤§æˆ–è¿‡å°ï¼‰ã€‚
2. **ä¿ƒè¿›ç¨³å®šè®­ç»ƒ**ï¼ˆç‰¹åˆ«æ˜¯åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­ï¼‰ã€‚
3. **é˜²æ­¢å¥–åŠ±å¡Œé™·**ï¼ˆå³å¥–åŠ±ä¿¡å·è¿‡äºç¨€ç–æˆ–è¿‡åº¦æ”¾å¤§ï¼‰ã€‚

å…¶æ ¸å¿ƒæ€æƒ³ï¼š
- ç»´æŠ¤ä¸€ä¸ª **å¥–åŠ±ç¼“å†²åŒº** `RankedRewardsBuffer` æ¥å­˜å‚¨è¿‡å»çš„å¥–åŠ±å€¼ã€‚
- è®¡ç®— **å½“å‰å¥–åŠ±åœ¨å†å²å¥–åŠ±ä¸­çš„åˆ†ä½æ•°**ï¼Œå¹¶è¿›è¡Œå½’ä¸€åŒ–ï¼š
  $$R_{\text{norm}} = \frac{R - P_{low}}{P_{high} - P_{low}}$$
  å…¶ä¸­ï¼Œ$P_{low}$ å’Œ $P_{high}$ åˆ†åˆ«æ˜¯å¥–åŠ±åˆ†å¸ƒçš„ **ä½åˆ†ä½æ•°** å’Œ **é«˜åˆ†ä½æ•°**ã€‚

---

## 1_Answers
### `RankedRewardsBuffer` çš„ä½œç”¨åŠå…¶ä¸ºä»€ä¹ˆæ˜¯ Buffer å½¢å¼

#### **1. `RankedRewardsBuffer` çš„ä½œç”¨**
`RankedRewardsBuffer` ä¸»è¦ç”¨äº**å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­çš„å¥–åŠ±é‡æ ‡å®šï¼ˆreward rescalingï¼‰**ï¼Œå®ƒçš„ä½œç”¨æ˜¯ï¼š
- **å­˜å‚¨å†å²å¥–åŠ±**ï¼šç»´æŠ¤ä¸€ä¸ªå¥–åŠ±å†å²ç¼“å†²åŒºï¼ˆbufferï¼‰ï¼Œç”¨äºè®¡ç®—å¥–åŠ±åˆ†å¸ƒã€‚
- **åŸºäºå¥–åŠ±åˆ†ä½æ•°å½’ä¸€åŒ–å¥–åŠ±**ï¼šå½“æ–°å¥–åŠ± `reward` åˆ°æ¥æ—¶ï¼Œå®ƒä¼šå’Œç¼“å†²åŒºä¸­çš„å¥–åŠ±è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶æŒ‰ç…§è®¾å®šçš„åˆ†ä½æ•°ï¼ˆpercentileï¼‰è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å¾—å¥–åŠ±æ›´åŠ å¹³æ»‘ï¼Œå‡å°‘æç«¯å¥–åŠ±çš„å½±å“ã€‚
- **ç”¨äºè®­ç»ƒç¨³å®šæ€§**ï¼šå°¤å…¶åœ¨å¥–åŠ±ç¨€ç–æˆ–å°ºåº¦å˜åŒ–è¾ƒå¤§çš„ç¯å¢ƒä¸­ï¼Œç›´æ¥ä½¿ç”¨ç¯å¢ƒå¥–åŠ±å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚`RankedRewardsBuffer` é€šè¿‡ç›¸å¯¹å¥–åŠ±æ’åæ¥è®¡ç®—å½’ä¸€åŒ–å¥–åŠ±ï¼Œä»è€Œæå‡è®­ç»ƒç¨³å®šæ€§ã€‚

---

#### **2. `RankedRewardsBuffer` æ˜¯ Buffer çš„åŸå› **
`RankedRewardsBuffer` ä¹‹æ‰€ä»¥æ˜¯ä¸€ä¸ª**ç¼“å†²åŒºï¼ˆBufferï¼‰**ï¼Œæ˜¯å› ä¸ºå®ƒéœ€è¦**å­˜å‚¨å’Œæ›´æ–°ä¸€ç³»åˆ—å¥–åŠ±æ•°æ®**ï¼Œå¹¶åŸºäºè¿™äº›æ•°æ®è®¡ç®—æ–°çš„å¥–åŠ±ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒå…·æœ‰ä»¥ä¸‹ç¼“å†²åŒºçš„ç‰¹æ€§ï¼š

| **ç‰¹æ€§**        | **è§£é‡Š** |
|---------------|--------|
| **æ•°æ®å­˜å‚¨** | `self.buffer` ç»´æŠ¤äº†ä¸€ä¸ªå¥–åŠ±å­˜å‚¨é˜Ÿåˆ—ï¼Œæœ€å¤šå­˜ `buffer_max_length` ä¸ªå¥–åŠ±å€¼ |
| **æ•°æ®æ›´æ–°** | æ¯æ¬¡æ·»åŠ æ–°çš„å¥–åŠ±æ—¶ï¼Œå¦‚æœè¶…å‡ºæœ€å¤§é•¿åº¦ï¼Œä¼šåˆ é™¤æœ€æ—©çš„å¥–åŠ±ï¼ˆFIFOï¼‰ |
| **æ•°æ®é‡ç”¨** | è®¡ç®—å¥–åŠ±å½’ä¸€åŒ–æ—¶ï¼Œéœ€è¦ä½¿ç”¨è¿‡å»å­˜å‚¨çš„å¥–åŠ± |
| **æ»‘åŠ¨çª—å£** | `self.buffer` ä»¥å›ºå®šé•¿åº¦å­˜å‚¨æœ€è¿‘ `buffer_max_length` ä¸ªå¥–åŠ±ï¼Œç±»ä¼¼ç»éªŒå›æ”¾ï¼ˆReplay Bufferï¼‰ |

å…·ä½“åˆ†æä»£ç ï¼š

```python
class RankedRewardsBuffer:
    def __init__(self, buffer_max_length, percentile):
        self.buffer_max_length = buffer_max_length  # ç¼“å†²åŒºæœ€å¤§é•¿åº¦
        self.percentile = percentile  # è®¡ç®—å¥–åŠ±æ’åæ—¶çš„åˆ†ä½æ•°
        self.buffer = []  # å­˜å‚¨å†å²å¥–åŠ±
```
- `self.buffer` æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¥–åŠ±å€¼ã€‚
- `buffer_max_length` æ§åˆ¶ç¼“å†²åŒºå¤§å°ï¼Œé˜²æ­¢æ— é™å¢é•¿ã€‚

---

#### **3. `RankedRewardsBuffer` çš„æ ¸å¿ƒé€»è¾‘**
##### **ï¼ˆ1ï¼‰æ·»åŠ å¥–åŠ± `add_reward()`**
```python
def add_reward(self, reward):
    if len(self.buffer) < self.buffer_max_length:
        self.buffer.append(reward)
    else:
        self.buffer = self.buffer[1:] + [reward]
```
**é€»è¾‘åˆ†æ**
- å¦‚æœ `buffer` è¿˜æœªæ»¡ï¼Œåˆ™ç›´æ¥æ·»åŠ  `reward`ã€‚
- å¦‚æœ `buffer` å·²æ»¡ï¼Œåˆ™**ä¸¢å¼ƒæœ€æ—©çš„å¥–åŠ±**ï¼ˆå³ `self.buffer[1:]`ï¼‰ï¼Œç„¶åå°† `reward` æ·»åŠ åˆ°æœ«å°¾ã€‚
- è¿™ä¸ªé€»è¾‘ç±»ä¼¼äº**FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰é˜Ÿåˆ—**ï¼Œä¿è¯ç¼“å†²åŒºå§‹ç»ˆå­˜å‚¨æœ€è¿‘çš„ `buffer_max_length` ä¸ªå¥–åŠ±ã€‚

---

##### **ï¼ˆ2ï¼‰å¥–åŠ±å½’ä¸€åŒ– `normalize()`**
```python
def normalize(self, reward):
    reward_threshold = np.percentile(self.buffer, self.percentile)  # è®¡ç®—å¥–åŠ±çš„åˆ†ä½æ•°é˜ˆå€¼
    if reward < reward_threshold:
        return -1.0
    elif reward > reward_threshold:
        return 1.0
    elif reward == max(self.buffer):
        return 1.0
    else:
        return 2*np.random.randint(2)-1  # éšæœºè¿”å› -1 æˆ– 1
```
**é€»è¾‘åˆ†æ**
- **è®¡ç®—åˆ†ä½æ•°å¥–åŠ±é˜ˆå€¼**ï¼š`reward_threshold = np.percentile(self.buffer, self.percentile)`
  - `percentile=75` æ—¶ï¼Œæ„å‘³ç€ `reward_threshold` æ˜¯ **å†å²å¥–åŠ±æ•°æ®çš„ 75% ä½ç½®çš„å¥–åŠ±**ã€‚
- **å½’ä¸€åŒ–ç­–ç•¥**
  - å¦‚æœ `reward` **å°äº** é˜ˆå€¼ â†’ å½’ä¸€åŒ–ä¸º `-1.0`
  - å¦‚æœ `reward` **å¤§äº** é˜ˆå€¼ â†’ å½’ä¸€åŒ–ä¸º `1.0`
  - å¦‚æœ `reward` æ˜¯ `buffer` é‡Œæœ€å¤§çš„å¥–åŠ± â†’ å½’ä¸€åŒ–ä¸º `1.0`
  - **å¦åˆ™** éšæœºè¿”å› `-1` æˆ– `1`ï¼ˆ`2*np.random.randint(2)-1`ï¼‰

**ä¸ºä»€ä¹ˆè¿™æ ·åšï¼Ÿ**
- è¿™æ˜¯ä¸€ç§ **åŸºäºç›¸å¯¹å¥–åŠ±æ’åçš„å½’ä¸€åŒ–ç­–ç•¥**ï¼Œèƒ½å¤Ÿå¹³æ»‘å¥–åŠ±ä¿¡å·ï¼Œå‡å°‘å™ªå£°ï¼Œä½¿è®­ç»ƒæ›´åŠ ç¨³å®šã€‚
- é¿å…æç«¯å¥–åŠ±å¯¹è®­ç»ƒçš„å½±å“ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚

---

##### **ï¼ˆ3ï¼‰è·å–å’Œè®¾ç½®ç¼“å†²åŒºçŠ¶æ€**
```python
def get_state(self):
    return np.array(self.buffer)

def set_state(self, state):
    if state is not None:
        self.buffer = list(state)
```
- `get_state()` ç”¨äºè·å–å½“å‰ç¼“å†²åŒºæ•°æ®ï¼ˆé€šå¸¸ç”¨äºå­˜æ¡£æˆ–åŒæ­¥ï¼‰ã€‚
- `set_state()` å…è®¸æ¢å¤ä¹‹å‰å­˜å‚¨çš„ç¼“å†²åŒºçŠ¶æ€ã€‚

---

#### **4. `get_r2_env_wrapper()` çš„ä½œç”¨**
`get_r2_env_wrapper()` è´Ÿè´£åŒ…è£…ï¼ˆwrapï¼‰ç¯å¢ƒï¼Œä½¿å¾—å¼ºåŒ–å­¦ä¹ ç¯å¢ƒèƒ½å¤Ÿä½¿ç”¨ `RankedRewardsBuffer` è¿›è¡Œå¥–åŠ±å¤„ç†ã€‚

```python
class RankedRewardsEnvWrapper:
    def __init__(self, env_config):
        self.env = env_creator(env_config)
        self.action_space = self.env.action_space
        self.observation_space = self.env.observation_space
        max_buffer_length = r2_config["buffer_max_length"]
        percentile = r2_config["percentile"]
        self.r2_buffer = RankedRewardsBuffer(max_buffer_length, percentile)
        if r2_config["initialize_buffer"]:
            self._initialize_buffer(r2_config["num_init_rewards"])
```
**é€»è¾‘åˆ†æ**
- `self.env = env_creator(env_config)`ï¼šåˆ›å»ºåŸºç¡€ç¯å¢ƒã€‚
- `self.r2_buffer = RankedRewardsBuffer(...)`ï¼šåˆå§‹åŒ– `r2_buffer`ï¼Œç”¨äºå¥–åŠ±å¤„ç†ã€‚
- å¦‚æœ `initialize_buffer=True`ï¼Œåˆ™è°ƒç”¨ `_initialize_buffer()` é¢„å…ˆå¡«å…… `r2_buffer`ï¼Œä¿è¯å¥–åŠ±å½’ä¸€åŒ–è®¡ç®—çš„ç¨³å®šæ€§ã€‚

---

##### **ï¼ˆ1ï¼‰åˆå§‹åŒ–ç¼“å†²åŒº**
```python
def _initialize_buffer(self, num_init_rewards=100):
    for _ in range(num_init_rewards):
        obs = self.env.reset()
        done = False
        while not done:
            mask = obs["action_mask"]
            probs = mask / mask.sum()
            action = np.random.choice(np.arange(mask.shape[0]), p=probs)
            obs, reward, done, _ = self.env.step(action)
        self.r2_buffer.add_reward(reward)
```
- è¿è¡Œ `num_init_rewards` æ¬¡ **éšæœºç­–ç•¥** æ¥æ”¶é›†å¥–åŠ±å¹¶å­˜å‚¨åˆ° `r2_buffer` é‡Œï¼Œç¡®ä¿ç¼“å†²åŒºåˆå§‹çŠ¶æ€ç¨³å®šã€‚

---

##### **ï¼ˆ2ï¼‰ç¯å¢ƒ `step()` å¤„ç†**
```python
def step(self, action):
    obs, reward, done, info = self.env.step(action)
    if done:
        reward = self.r2_buffer.normalize(reward)
    return obs, reward, done, info
```
- **ä¿®æ”¹åŸå§‹ç¯å¢ƒå¥–åŠ±**ï¼š
  - åœ¨ç¯å¢ƒ `done` æ—¶ï¼Œå¯¹ `reward` è¿›è¡Œ `normalize()` å½’ä¸€åŒ–ã€‚
  - è¿™æ ·ï¼Œå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æ¥æ”¶åˆ°çš„å¥–åŠ±ä¸å†æ˜¯åŸå§‹å¥–åŠ±ï¼Œè€Œæ˜¯**ç›¸å¯¹å½’ä¸€åŒ–åçš„å¥–åŠ±**ã€‚

---

#### **5. `RankedRewardsBuffer` ä¸ºä»€ä¹ˆæ˜¯ Buffer**
1. **å®ƒå­˜å‚¨å†å²å¥–åŠ±æ•°æ®**ï¼ˆç¼“å†²åŒºçš„åŸºæœ¬ç‰¹æ€§ï¼‰ã€‚
2. **å®ƒå…·æœ‰å›ºå®šå®¹é‡ï¼Œä½¿ç”¨ FIFO æœºåˆ¶æ›´æ–°**ï¼ˆé¿å…æ— é™å¢é•¿ï¼‰ã€‚
3. **å®ƒè¢«ç”¨äºé‡‡æ ·è®¡ç®—å¥–åŠ±çš„åˆ†ä½æ•°**ï¼ˆä¸ç»éªŒå›æ”¾ç¼“å†²åŒºç±»ä¼¼ï¼‰ã€‚
4. **å®ƒç”¨äºå¥–åŠ±å½’ä¸€åŒ–**ï¼Œå‡å°‘å¥–åŠ±æ³¢åŠ¨ï¼Œæé«˜å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

---

### **æ€»ç»“**
- **`RankedRewardsBuffer` ä½œä¸ºä¸€ä¸ª Bufferï¼ˆç¼“å†²åŒºï¼‰ï¼Œå­˜å‚¨äº†è¿‡å»çš„å¥–åŠ±æ•°æ®**ï¼Œå¹¶é€šè¿‡ **åˆ†ä½æ•°å½’ä¸€åŒ–** æ¥è°ƒæ•´æ–°å¥–åŠ±ï¼Œä½¿è®­ç»ƒæ›´åŠ ç¨³å®šã€‚
- **FIFO æœºåˆ¶** ç¡®ä¿ç¼“å†²åŒºå§‹ç»ˆåŒ…å«æœ€è¿‘çš„å¥–åŠ±å†å²ï¼Œå¹¶åˆ é™¤æœ€æ—©çš„å¥–åŠ±ï¼Œç±»ä¼¼ç»éªŒå›æ”¾ï¼ˆReplay Bufferï¼‰ã€‚
- **åœ¨ `RankedRewardsEnvWrapper` ä¸­ï¼Œ`r2_buffer` ç”¨äºå¥–åŠ±é‡æ ‡å®š**ï¼Œç¡®ä¿å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“èƒ½å¤Ÿè·å¾—å¹³æ»‘çš„å¥–åŠ±ä¿¡å·ï¼Œè€Œä¸ä¼šå—åˆ°æç«¯å¥–åŠ±çš„å¹²æ‰°ã€‚

å¦‚æœä½ æœ‰è¿›ä¸€æ­¥çš„ç–‘é—®ï¼Œæ¬¢è¿ç»§ç»­è®¨è®ºï¼ğŸš€

## 2_Answers


## 3_Answers




# FootNotes
