---
创建时间: 2025-十月-8日  星期三, 9:40:54 晚上
---


[[Hierarchical Reinforcement Learning- A Survey and Open Research Challenges]]
p180
# Questions

- [?] 

Bisimulation: 
>state+reward?
>引用文献中提到了metrics ：关于衡量MDP中不同状态的距离；另外，与迁移学习有关


# Answers

```text
132. Larsen, K.G.; Skou, A. Bisimulation through probabilistic testing. Inf. Comput. 1991, 94, 1–28. [CrossRef] 
     
133. Ferns, N.; Panangaden, P.; Precup, D. Metrics for Finite Markov Decision Processes. In Proceedings of the Twentieth Conference on Uncertainty in Artificial Intelligence, Banff, AB, Canada, 9–11 July 2004. 

134. Castro, P.S.; Precup, D. Using bisimulation for policy transfer in MDPs. In Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence, Atlanta, GA, USA, 11–15 July 2010. 
     
135. Castro, P.S.; Precup, D. Automatic Construction of Temporally Extended Actions for MDPs Using Bisimulation Metrics. In Recent Advances in Reinforcement Learning; Series Title: Lecture Notes in Computer Science; Hutchison, D., Kanade, T., Kittler, J., Kleinberg, J.M., Mattern, F., Mitchell, J.C., Naor, M., Nierstrasz, O., Pandu Rangan, C., Steffen, B., Eds.; Springer: Berlin/Heidelberg, Germany, 2012; Volume 7188, pp. 140–152. [CrossRef]
```

## GPT_Answers


## DS_Answers


## Other_Answers


# Codes

```python

```


# FootNotes
