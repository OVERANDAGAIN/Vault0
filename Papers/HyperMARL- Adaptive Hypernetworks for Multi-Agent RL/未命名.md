[[Hyper-MARL]]

# Questions

- [?] 


# Answers

##  HyperMARL 是在哪些方法的基础上改进的？

主要改进对象是两类常见策略结构：

### 📌 1. **Full Parameter Sharing (FuPS)**：完全共享策略

* 所有智能体使用**同一个策略网络** $\pi_\theta$；
* 如果仅输入观测 $o_i$，则所有智能体是完全同质的；
* 为支持异质行为，通常加入智能体 ID，即形成 **FuPS + ID** 架构。

### 📌 2. **No Parameter Sharing (NoPS)**：完全不共享策略

* 每个 agent 都使用独立策略网络 $\pi_{\theta_i}(a_i|o_i)$；
* 容易实现行为特化，但**计算成本高、样本效率低**。

HyperMARL 的目标就是：**保持 FuPS 的效率，同时实现 NoPS 的行为多样性能力。**

---

##  原始方法的公式形式

###  FuPS（无 ID）策略梯度更新：

所有 agent 使用相同的策略 $\pi_\theta$，策略梯度如下：

$$
\nabla_\theta J(\theta) = \mathbb{E}_{h, a \sim \pi_\theta} \left[ \sum_{i=1}^n A(h, a) \nabla_\theta \log \pi_\theta(a_i | o_i) \right]
$$

这里的问题是：

* **所有智能体共享一个参数 $\theta$**；
* 无法区分不同智能体的行为需求；
* 一旦任务需要多样化行为，这种统一更新会相互干扰。

---

###  FuPS + ID（加上智能体ID）：

为缓解上述问题，给策略网络加入 agent ID（如 one-hot 编码）：

$$
\pi_\theta(a_i | o_i, id_i)
$$

此时的策略梯度变为：

$$
\nabla_\theta J(\theta) = \mathbb{E} \left[ \sum_{i=1}^n A(h, a) \nabla_\theta \log \pi_\theta(a_i | o_i, id_i) \right]
$$

问题是：

* $\theta$ 仍然是**全体共享的参数**；
* ID + 观测输入使得梯度具有**双重依赖**，导致不同智能体的更新互相冲突（梯度方向不一致）；
* 具体体现在：$\nabla_\theta \log \pi_\theta(a_i | o_i, id_i)$ 与 $\nabla_\theta \log \pi_\theta(a_j | o_j, id_j)$ 在参数 $\theta$ 上可能**方向相反**。

---

##  HyperMARL 改进？——结构性解耦梯度

HyperMARL 改为使用 **超网络**：

每个智能体的策略参数不是共享的，而是通过一个共享超网络生成的：

$$
\theta_i = h^\pi_\psi(e_i)
\quad \Rightarrow \quad \pi_{\theta_i}(a_i | o_i)
$$

对应的策略梯度为：

$$
\nabla_\psi J(\psi) = \sum_{i=1}^n \underbrace{\nabla_\psi h^\pi_\psi(e_i)}_{\text{agent-conditioned}} \cdot \underbrace{\mathbb{E}[A \cdot \nabla_{\theta_i} \log \pi_{\theta_i}(a_i|o_i)]}_{\text{trajectory-conditioned}}
$$

---

### ✅ 关键区别（vs FuPS+ID）

| 结构方面 | FuPS+ID                 | HyperMARL                          |
| ---- | ----------------------- | ---------------------------------- |
| 网络参数 | 所有 agent 共享同一个 $\theta$ | 每个 agent 的参数 $\theta_i$ 由共享超网络生成   |
| 输入形式 | $\pi_\theta(o_i, id_i)$ | $\pi_{h_\psi(e_i)}(o_i)$           |
| 梯度流向 | 所有梯度都更新同一个 $\theta$     | 每个梯度先对 $\theta_i$，再通过链式规则影响 $\psi$ |
| 梯度干扰 | 严重（梯度方向容易冲突）            | 低（agent ID 的 Jacobian 与观测解耦）       |

---

## ✅ 用图示说明

**FuPS+ID 更新路径：**

```
                θ (共享参数)
               /  |   \
      grad_i ↗  grad_j ↖ grad_k
o_i, id_i       o_j, id_j     ...
```

* 冲突点：grad\_i、grad\_j、grad\_k 同时作用于 θ

**HyperMARL 更新路径：**

```
        ψ (共享超网络参数)
       /       |         \
  h(e_i)     h(e_j)     h(e_k)
    ↓          ↓           ↓
 θ_i        θ_j         θ_k
  ↓           ↓            ↓
grad_i    grad_j     grad_k
```

* 优势：每条路径结构上“分离”，再统一回 ψ

---

## ✅ 总结归纳

| 对比点    | FuPS+ID              | HyperMARL         |
| ------ | -------------------- | ----------------- |
| 参数共享粒度 | 完全共享                 | 超网络共享、策略参数分离      |
| 行为特化支持 | 较弱，需手动调整 ID 编码和网络设计  | 强，自动特化            |
| 训练目标修改 | 通常需配合 diversity loss | 不修改标准 RL 目标       |
| 计算成本   | 高效                   | 稍高于 FuPS，远低于 NoPS |
| 梯度稳定性  | 差（冲突大）               | 好（解耦）             |

---



## DS_Answers


## Other_Answers


# Codes

```python

```


# FootNotes
