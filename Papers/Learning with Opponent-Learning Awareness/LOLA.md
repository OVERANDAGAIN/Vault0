#paper_summary 

# Inspiration



# Focus



# Innovation



# Theroy



# Background



# Related Work




# Methodology



# Evaluation
 1. infinitely repeated iterated prisoners’ dilemma
 2. round-robin tournament against other multi-agent learning algorithms 
 3. derive a policy gradient-based version of LOLA, applicable to a deep RL setting
 4. scale the policy gradient-based version of LOLA to the Coin Game
 5. We further remove agents’ access to the opponent agents’ policy parameters and replace with opponent modeling
 6.  briefly address the exploitability of LOLA agents $\Longrightarrow$ show that in the IPD both agents are incentivised to use LOLA, while higher order exploits show no further gain


# Results



# Limitations


# FootNotes
