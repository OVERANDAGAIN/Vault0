---
created: 2024-12-18T20
updated: ...
---
[[Autonomous Agents Modelling Other Agents-A Comprehensive Survey and Open Problems]]

# Questions

- [?] 


# 重点摘抄
4.1 策略重建（Policy Reconstruction）
4.1.1 条件动作频率（Conditional Action Frequencies）
>但单一分布无法捕捉依赖交互历史的复杂行为。要提升此方法的能力，关键在于基于历史中的某些信息对动作分布进行条件化。

此类基于条件频率的方法也被用于**不完全信息的扩展形式博弈**（如扑克）：

* 由于玩家拥有私有信息（如手牌）和公共信息（如桌面牌），决策需在“信息集”中进行，即玩家无法区分的状态集合。
* 可以为每个信息集设立独立的 Dirichlet 分布（Southey 等, 2005），并在每次观察到对方动作后更新该分布；
* 也可以基于博弈的纳什均衡解初始化这些分布，然后逐步向实际观察到的动作频率调整（Ganzfried 和 Sandholm, 2011）；
* Billings 等（2004）提出方法：基于完整动作序列来学习频率，并通过一系列越来越粗的抽象级别实现泛化。此外，引入衰减因子，使得新近观察具有更大权重。


### 5.4 决策关联性（Integration with Decision-Making）

对其他智能体的建模并非孤立目的，**其最终作用在于改进自身的决策过程**。因此，我们需要考察建模如何融入智能体的决策模块。常见的集成方式有：

1. **策略调整（Policy Shaping）**：

   * 根据模型预测的对方行为，优化自身策略；
   * 例如预测协作伙伴行为以实现更高效的任务协同。

2. **博弈推理（Game-Theoretic Reasoning）**：

   * 将对手建模结果作为输入，参与博弈均衡分析；
   * 应用于安全博弈、机制设计、策略学习等任务。

3. **规划辅助（Planning Guidance）**：

   * 在路径规划或计划生成中，利用建模结果规避冲突或生成协同策略；
   * 例如在人群导航、多机器人路径协同中。

4. **多模型融合（Model Ensemble in Decision-Making）**：

   * 同时维护多个候选对手模型，根据不同模型结果做联合决策；
   * 可提升鲁棒性，适应对手行为变化。

5. **不确定性评估（Uncertainty-Aware Action Selection）**：

   * 在模型置信度低时选择保守策略；
   * 或通过探索行为主动获取更多观察信息。





# Codes

```python

```


# FootNotes
