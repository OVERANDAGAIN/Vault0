[[The overfitted brain-Dreams evolved to assist generalization]]







---

大家好，我们先来看两张有趣的图片。
左边的是著名的“火星人脸”，右边是一颗钉子和锤子——但它好像露出了一副惊恐的表情。

看到这些画面时，我们的大脑会自动把它们识别成“脸”。
这是因为，大脑的首要任务是帮助我们生存。在进化过程中，人类发展出了极其敏锐的面部识别能力——哪怕只有几个简单的特征，比如两个黑点加一条线，我们也会迅速把它补全成一张脸。

这种现象被称为“空想性视错”（Pareidolia）。它的好处是，在原始环境中，你能第一时间发现潜在的威胁，比如捕食者的面孔或同类的情绪。
然而在现代社会，这个机制有时会“过度发挥”，让我们在无生命的物体上看到表情。换句话说，大脑有点“过拟合”了——它宁愿多识别几次假脸，也不能错过一次真的威胁。

---


---

这里我们先简单回顾一下机器学习中的“过拟合”——
在训练中，模型可能会把数据记得过于死板，连那些偶然的噪声也学了进去。这样虽然训练误差很低，但一到新数据上，表现就会大幅下降。

从图中可以看到：

* **过拟合**：模型线条过于曲折，几乎“追着”每个数据点跑；
* **正确拟合**：模型抓住了数据的整体趋势，泛化能力好；
* **欠拟合**：模型太简单，连主要规律都没学到。

如果我们把这个类比到大脑，**过拟合的大脑**就是在有限经验的基础上，过度提炼出一些在现实中并不总成立的模式，比如在随机图案里看出“脸”。

---



---

在机器学习中，我们已经看到，**过拟合**会让模型在熟悉的数据上表现出色，却在新数据上失灵。研究人员解决这一问题的方法之一，是在训练中引入**分布外（out-of-distribution）或随机化的数据**，帮助模型学会更普遍的规律。

那么，如果把这个思路类比到人类大脑呢？
Erik Hoel 在 **《The Overfitted Brain: Dreams evolved to assist generalization》** 一文中提出，**我们的脑也可能面临同样的问题**——每天接触的感官信息往往高度相似、重复，这就像模型反复看到同一类训练数据，容易导致“过拟合”，从而限制了对新情境的适应能力。

**OBH 假说**认为：
梦境就是大脑用来对抗这种过拟合的“数据增强”手段。
在睡眠中，大脑通过**制造奇特、跳跃、甚至违背现实逻辑的感官体验**，相当于引入了一批分布外数据，让神经系统获得更强的泛化能力——无论是感知还是认知，都能更灵活地应对新情况。

---



---

接下来我们先看一些关于梦的基本事实。

健康的人每晚都会做梦，而且做梦的次数和时长基本不受意志控制。大多数成年人每晚会经历 4 到 5 个梦，总时长大约 2 小时，每次持续 5 到 20 分钟。

有些人说自己从来不做梦，其实只是**不记得**而已。研究显示，即使是声称“从不做梦”的人，在快速眼动睡眠（REM）阶段也会出现与梦境相关的复杂行为，比如争吵、说话等，只是醒来后无法回忆梦的内容。

梦境可以发生在 REM 阶段，也可能出现在非快速眼动睡眠（NREM）阶段。整晚的睡眠会在浅睡、深睡与 REM 之间循环，平均一生中，我们会有将近 6 年的时间在做梦。

梦的内容千差万别，可能是愉快的、恐惧的，也可能完全怪诞。大多数人在颜色中做梦，也有少数人以黑白方式做梦。虽然科学界对“为什么做梦”还没有统一答案，但可以肯定的是，梦境是我们大脑日常活动的重要组成部分。

---



---

## **演讲文稿：从经典梦境理论到 OBH**

大家好，接下来我想带大家快速浏览一下几种在梦境研究中最常被提到的功能假说。

首先是**情绪调节说**。
这个理论认为，梦境的主要作用是调节情绪，比如缓解恐惧、维持情绪稳定。它的优势在于，一些研究确实发现情绪化的梦境与情绪恢复之间存在联系，尤其是在抑郁康复过程中。但问题是，大多数梦并不特别情绪化，而且这个理论很难解释梦境中那些稀疏、奇异、甚至毫无逻辑的内容。

第二个是**记忆巩固说**。
它认为梦境通过重放或整合记忆来帮助学习，这和我们知道的睡眠促进记忆的作用一致，也得到了部分神经影像学的支持。但现实是，大部分梦和具体的记忆无关，而且记忆重放更多发生在慢波睡眠，而非梦境最活跃的快速眼动期。它也解释不了梦境的幻觉化和故事化特征。

第三个是**选择性遗忘说**，也叫“反向学习”假说。
这个理论认为，梦境帮助我们删除无用的记忆或连接，类似于突触下调的过程。它在计算机模型里确实显示出一定优势，但它的重点是去除信息，而不是创造那些稀疏又奇怪的梦境画面。

还有像**现实问题演练说**，认为梦是虚拟训练场，用来演练应对现实中的挑战；以及**预测加工说**，认为梦是为了优化大脑的生成模型。但这些理论要么太依赖梦境内容与现实情境的直接对应，要么缺乏现象学上的支持，同样解释不了梦境的高稀疏性和高度奇异化。

**所以我们看到，这些理论各有亮点，但它们都有一个共同的不足：没办法同时解释梦境的稀疏性、奇异性和叙事性。**

在人工智能领域，我们很熟悉“过拟合”这个问题：当一个模型长时间训练在相似的数据上，就会失去对新情境的泛化能力。我们通常会用数据增强、加噪声等方法来缓解过拟合。

那么，如果大脑也会面对类似的风险呢？
每天我们接收到的感官信息，其实高度重复、结构相似，大脑会不会也需要一种机制，去打破这种单一化的输入，从而提升泛化能力？

这就引出了**过拟合大脑假说（OBH）**。它借鉴了机器学习中的防过拟合策略，把梦境看作是一种“内部生成的数据增强”，利用奇异、稀疏、叙事化的场景，让我们的认知模型在低风险环境下不断适应多样化的可能性。

---



---

## **P3. 大脑与DNN的共同挑战**

在人类大脑和深度神经网络（DNN）中，学习的核心都依赖于**在超高维参数空间中更新权重**来完成复杂任务。虽然两者在生物实现细节上有所不同，但它们在学习过程中面临着相似的瓶颈：**泛化（Generalization）与记忆（Memorization）之间的权衡**。

在DNN中，这种权衡最直观的表现是**过拟合**：当模型在训练集上表现越来越好，但在测试集上的表现开始下降时，说明它开始记住训练数据的细节而失去泛化能力。过拟合的风险会随着训练数据采样的**自相似性**或**偏倚性**增加而加剧。

DNN领域中，常用的解决方法是通过\*\*噪声注入（Noise Injection）\*\*来打破过度拟合，例如：

* **输入扰动**：在训练时有意破坏输入数据，使其不再过于自相似；
* **Dropout**：在训练中随机丢弃部分输入或中间节点，相当于引入数学意义上的噪声。

大脑同样面临这一问题。生物体的日常体验往往**高度重复且存在偏倚**，如果缺乏扰动机制，大脑同样可能过度拟合于有限的日常情境，降低对新环境的适应能力。

---

## **P4. OBH 核心观点**

“过拟合大脑假说”（Overfitted Brain Hypothesis, OBH）认为，**梦境是大脑实现“生物学噪声注入”的天然机制**。

具体来说，研究表明梦境的形成基于**皮层层级结构中的随机信号渗透**（stochastic percolation），并激活**默认模式网络**（Default Mode Network）。与感官驱动的清醒体验不同，这些信号多数是\*\*自上而下（top-down）\*\*生成的，也就是说梦境输入并非源自外部感官，而是源于大脑内部已有模型和表征的随机探索。

这种结构意味着梦境输入**有意被“破坏”**，在统计上偏离清醒时的真实感官输入，从而打破大脑日间经验的惯性模式。

---

## **P5. 梦境与过拟合防止**

白天，大脑不断从高度自相似的日常体验中学习，相当于对特定“训练集”进行拟合；夜晚，梦境则提供了一组**与训练集差异极大**的模拟体验。

这种昼夜交替的学习过程可类比为**模拟退火（Simulated Annealing）**：

* **白天**：拟合当前任务和环境模式；
* **夜晚**：通过梦境引入随机扰动，防止大脑陷入局部最优、提高泛化能力。

正是梦境中那种超越日常的奇异性、叙事性和幻觉感，使它们在统计特性上远离“日间训练集”，从而具备防止过拟合的功能。

---

## **P6. 梦境的三种特征与功能**

| 特征      | 神经来源                                     | 功能                     |
| ------- | ---------------------------------------- | ---------------------- |
| **稀疏性** | 自下而上输入的“Dropout”——梦境中几乎没有外部感官驱动，主要依赖反馈活动 | 避免过度依赖真实感官输入，增加表征的多样性  |
| **幻觉性** | 高层随机生成——信号源于皮层高层的随机探索                    | 打破日常经验的模式，生成类别跨越性的内容   |
| **叙事性** | 自上而下生成——大脑以事件和故事形式组织信息                   | 将随机内容整合为可理解的情节，便于巩固与泛化 |

从OBH的角度看，梦境的这三种现象并非副产物，而是经过进化优化、**专门用于最大化泛化能力**、减少单纯记忆的生物策略。

---

