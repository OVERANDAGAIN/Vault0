[[(2025-10-29) World Models as Reference Trajectories for Rapid Motor Adaptation]]

# 1.model_based algorithm
```
Roughly speaking, model-based approaches fall into three categories according to the way of model usage: (1) dynastyle methods (Sutton 1990; Luo et al. 2019; Zhou, Li, and Wang 2020; Janner et al. 2019), which use the model to generate imaginary samples as additional training data; (2) shooting algorithms (de Boer et al. 2005; Chua et al. 2018; Wang and Ba 2020), which use the model to plan to seek the optimal action sequence; (3) policy search with backpropagation (Nguyen and Widrow 1990; Fairbank and Alonso 2012; Heess et al. 2015; Clavera, Fu, and Abbeel 2020; Amos et al. 2021) through time, which exploits the model derivatives and computes the analytic policy gradient. Our work falls into the first category, i.e., the dyna-style algorithm, which has recently shown the potential to achieve high sample efficiency (Janner et al. 2019).
```
># (2022-06-28) Sample-Efficient Reinforcement Learning via Conservative Model-Based Actor-Critic





# Codes

```python

```


# FootNotes
