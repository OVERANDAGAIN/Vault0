---

mindmap-plugin: basic

---

# 单智能体强化学习（综述式思维导图）

## 基于价值的方法

### 动机：在高维/连续状态下逼近Q值函数

#### [DQN](https://arxiv.org/abs/1312.5602) ; Mnih et al., 2013

##### 改进方向：提升稳定性

* [Double DQN](https://arxiv.org/abs/1509.06461) ; van Hasselt et al., 2015
* [Dueling DQN](https://arxiv.org/abs/1511.06581) ; Wang et al., 2016

##### 改进方向：提升数据效率

* [Prioritized Replay](https://arxiv.org/abs/1511.05952) ; Schaul et al., 2015

## 基于策略的方法

### 动机：直接学习参数化策略而非值函数

#### [REINFORCE](https://link.springer.com/article/10.1007/BF00992696) ; Williams, 1992

##### 改进方向：降低方差、提升收敛性

* [Actor–Critic](https://papers.nips.cc/paper_files/paper/2000/hash/091d584fced301b442654dd8c23b3fc9-Abstract.html) ; Konda & Tsitsiklis, 2000

##### 改进方向：稳定更新过程

* [TRPO](https://arxiv.org/abs/1502.05477) ; Schulman et al., 2015
* [PPO](https://arxiv.org/abs/1707.06347) ; Schulman et al., 2017

## 连续动作控制

### 动机：处理无限动作空间、提升采样效率

#### [DDPG](https://arxiv.org/abs/1509.02971) ; Lillicrap et al., 2015

##### 改进方向：提升稳定性与鲁棒性

* [SAC](https://arxiv.org/abs/1801.01290) ; Haarnoja et al., 2018

## 模仿学习

### 动机：奖励信号缺失或难以设计

#### [Behavior Cloning](https://dl.acm.org/doi/10.1145/97243.97245) ; Pomerleau, 1989

#### [GAIL](https://arxiv.org/abs/1606.03476) ; Ho & Ermon, 2016

## 基于模型的方法

### 动机：通过环境模型降低真实交互需求

#### [MPC](https://www.sciencedirect.com/science/article/pii/S0005109804002766) ; Mayne, 2005

#### [PETS](https://arxiv.org/abs/1805.12114) ; Chua et al., 2018

#### [MBPO](https://arxiv.org/abs/1906.08253) ; Janner et al., 2019

## 离线强化学习

### 动机：无交互或危险场景下利用固定数据

#### [BCQ](https://arxiv.org/abs/1812.02900) ; Fujimoto et al., 2019

#### [CQL](https://arxiv.org/abs/2006.04779) ; Kumar et al., 2020

#### [IQL](https://arxiv.org/abs/2110.06169) ; Kostrikov et al., 2021

## 目标条件与泛化

### 动机：解决多任务、复合目标的泛化能力

#### [UVFA](https://arxiv.org/abs/1802.09464) ; Schaul et al., 2015

#### [HER](https://arxiv.org/abs/1707.01495) ; Andrychowicz et al., 2017

#### [Meta-RL (MAML)](https://arxiv.org/abs/1703.03400) ; Finn et al., 2017



# 多智能体合作学习综述（论文导向版）

## 合作范式

### 动机：多智能体目标关系不同

#### 纯合作（Pure Cooperation）

* 环境：simple-spread 等

#### 混合动机（Mixed-motivation）

* [Sequential Social Dilemmas (SSD)](https://arxiv.org/abs/1702.03037) ; Leibo et al., 2017

## 架构与训练方式

### 集中训练，分布式执行（CTDE）

#### [MADDPG](https://arxiv.org/abs/1706.02275) ; Lowe et al., 2017

#### [QMIX](https://arxiv.org/abs/1803.11485) ; Rashid et al., 2018

#### [QTRAN](https://arxiv.org/abs/1905.05408) ; Son et al., 2019

#### [COMA](https://arxiv.org/abs/1705.08926) ; Foerster et al., 2018

## 通信与信息共享

### 动机：通过通信提升协调性

#### [DIAL](https://arxiv.org/abs/1605.06676) ; Foerster et al., 2016

#### [CommNet](https://arxiv.org/abs/1605.07736) ; Sukhbaatar et al., 2016

#### [IC3Net](https://arxiv.org/abs/1810.03916) ; Singh et al., 2018

## 信号归因（Credit Assignment）

### 动机：解决个体贡献难以分辨的问题

#### [Counterfactual Multi-Agent Policy Gradients (COMA)](https://arxiv.org/abs/1705.08926) ; Foerster et al., 2018

## 伙伴建模与适应

### 动机：预测/适应他人策略

#### [LOLA](https://arxiv.org/abs/1709.04326) ; Foerster et al., 2017

#### Bayesian Theory of Mind (ToM-based MARL)

## 激励与社会机制

### 动机：促进合作与公平

#### [LIO (Learning with Intrinsic Social Influence)](https://arxiv.org/abs/1810.08647) ; Yang et al., 2018

#### [Social Influence](https://arxiv.org/abs/1810.08647) ; Jaques et al., 2019

#### Prosocial RL / Inequity Aversion（参见人类合作建模文献）

## 契约与规范

### 动机：通过机制设计约束个体

#### Contract-based MARL (早期经济学模型)

#### Norm-based Cooperation (CNM, 未形成单一论文代表)
